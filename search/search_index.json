{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"EXPL NIT-C","text":""},{"location":"#experimental-language-write-your-own-compiler","title":"EXPERIMENTAL LANGUAGE : WRITE YOUR OWN COMPILER","text":"<p>Source Code</p> <p></p> <p>The entire project code is hosted on Github https://github.com/silcnitc</p> <p>Release Version 1.0</p> <p>This project aims to develop an online self-sufficient educational platform to help undergraduate Computer Science students understand the functioning of a compiler for a simple procedural language by writing a small toy compiler themselves. (An object oriented extension for the language has been added subsequently.) The project will provide students with a roadmap  for the development process and guide them along the roadmap with supporting documentation. Using the step-by-step guidance offered by the roadmap, the students will be able to build the compiler under minimal expert supervision.</p> <p>The platform is designed assuming that the student has a basic knowledge of Data structures, Computer organization and a working proficiency of the C programming language. Being instructional in nature, this project tries to give some insight into the working of LEX, YACC and the usage of these tools to develop a compiler for an instructional language custom designed for the project - called ExpL (Experimental language). Brief theoretical explanations are provided on a need-to-do basis.</p> <p>If you wish to get started with the project directly, proceed to the Roadmap . If you wish to get a high level overview of the project, a brief outline is given next.</p> <p>If you wish to customize this project for your instructional requirements, proceed here.</p>"},{"location":"#overview-of-the-project","title":"Overview of the project","text":"<p>To design a compiler, one needs the following specifications:</p> <ol> <li> <p>The specification of the source programming language: The source language for this compiler is called the Experimental Language (ExpL), which is designed solely for instructional purposes. An informal specification of the source language is given here. The specification for an extension of the basic ExpL language with support for object oriented programming is given here.</p> </li> <li> <p>Application Binary Interface of the target platform: A compiler must generate a binary executable file that can be loaded and executed by an operating system running on a target machine. Normally, an OS system installation comes with an interface specification, explaining how binary executable files must be formatted to run on the system. This interface is called the Application Binary Interface (ABI). The ABI is dependent on both the OS and the machine architecture. The ABI for this project is that of the Experimental Operating System (ExpOS) running on the Experimental String Machine. [XSM]. The ABI specification is given here. (The simulator allows the target program to contain machine instructions in mnemonic form, avoiding translation to binary format).</p> </li> </ol> <p>A compiler takes a source language program as input and produces an executable target file formatted according to the requirements laid down by the ABI. Of course, the semantics of the program must be preserved by the translation process.</p> <p>The main intellectual complexity in understanding a compiler is that its inputs and outputs are programs \u2013 that is, a compiler's input data is a (source language) program and its output is a (target language) program. The task is to systematically map each construct in the source program to semantically equivalent constructs in the target language.</p> <p>A text book approach to compilation logically divides the process into several parts. The lexical elements of the input program are identified during a lexical analysis phase. The software tool LEX is used in this phase. The lexemes identified by the lexical analysis phase are passed to the next phase \u2013 called the syntax analysis phase - which checks the program against syntax errors. If the program is free of syntax errors, the next conceptual stage called the semantic analysis phase, checks for type and scope errors in the program. Once a program is found to be free of syntax and semantic errors, an intermediate representation of the source program called the abstract syntax tree representation is generated by the compiler. (In practice, syntax analysis, semantic analysis and abstract syntax tree construction happens together. The syntax directed translation scheme provided by the software tool YACC is used for completing these phases.) The sequence of phases starting with the lexical analysis of the source program to generation of abstract syntax tree representation is called the front end of the compiler.</p> <p></p> <p>The abstract syntax tree produced by the front end is the input to the back end phase which generates an assembly language program. Finally, a label translation phase is run to replace symbolic labels in the assembly language program with logical addresses (linking) and generate final target executable file.</p> <p>The road-map takes you through a \"spiral\" model of program development. First, a simple expression compiler is built. Static variables are then introduced to the expression compiler and control flow constructs are added. In the next step, support for string type is added to the language and semantic issues are addressed. Subroutines and run time allocation are introduced subsequently and finally support for user defined types and dynamic memory allocation is added. (A final phase of providing support for classes and subtype polymorphism has been added subsequently). In each of these steps, you will encounter lexical, syntax and semantic analysis, syntax tree construction and code generation. The tasks will be very simple during the initial stages and the complexity will grow gradually as more and more features are added to the language.</p> <p>Wish you good luck working through the roadmap.</p>"},{"location":"#customizing-the-project","title":"Customizing the Project","text":"<p>If you wish to adapt the project to your own instructional requirements, this is how we suggest you to proceed.</p> <p>Suppose your institution has the name ABC University, download the ExpL source and create your own Git repository \"explabc.github.io\". You can now modify the specification/simulator/ABI or any other component of this package, subject to the license conditions. You will have your version of ExpL in this way. We encourage you to do this as you will develop your own instructional system and a team of students who can help you with the administration of your Git repository. We recommend you to keep your repository in Git so that students elsewhere will also get the benefit of your contribution.</p>"},{"location":"Data_Structures/","title":"Data Structures for ExpL Compilation/Interpretation","text":""},{"location":"Data_Structures/#introduction","title":"INTRODUCTION","text":"<p>The compilation/interpretation of an ExpL program involves two phases. In the first phase (called the analysis phase), the source ExpL program is analyzed (lexical, syntax and semantic analysis are completed in this phase) and if the program is free of syntax and semantic errors, an intermediate representation of the source program called the abstract syntax tree is generated.</p> <p>This is followed by a second phase, whose functionality is different for a compiler and an interpreter.</p> <p>In the case of a compiler, the second phase (called the synthesis phase) recursively traverses the abstract syntax tree and generates target code.</p> <p>[Note: the abstract syntax tree representation is only one among several intermediete representations used in practical compilers. \u201cLower level\u201d intermediete representations like three address code are often more useful for applying code optimization algorithms. In our present experiment, we do not perform any code optimizations and hence the code generation phase will directly work with the abstract syntax tree.]</p> <p>In the case of interpretation, the second phase (called the execution phase) involves direct execution of the program by recursive evaluation of the abstract syntax tree.</p> <p>The description of data structures below assumes an interpreter is being designed. This choice has been made to avoid target machine dependency in the documentation.\u00a0 Notes/comments\u00a0 are added wherever appropriate explaining the modifications to be made to the data structures to implement a compiler.</p> <p>There are three basic data structures that are maintained during the analysis phase. These are the following:</p> <ol> <li>The global symbol table is used to store information about the global variables and functions in the program.</li> <li>For each function, a separate local symbol table is maintained to store the information about local variables and arguements of the function.</li> <li>Finally, the abstract syntax tree that is constructed as the outcome of the analysis phase is the third data structure.</li> </ol> <p>An abstract syntax tree is a tree representation of a program. It is a generalization of the tree representation for expressions (called the expression tree). For example, the arithmetic expression (3+5)*(5+9) is typically represented as an expression tree as below:</p> <p></p> <p>We can generalize this representation to come up with a tree representation for the whole sequence of statements of a ExpL function in a program. Each funcion in an ExpL program will be represented by an abstract syntax tree. Thus, the whole program will be a collection of abstract syntax trees, one for each function.</p> <p>In the following, the definitions node structures for each of the above data structures is discussed. The organization of data in these data structures is also discussed with illustrative examples.</p>"},{"location":"Data_Structures/#data-structures-for-analysis-phase","title":"DATA STRUCTURES FOR ANALYSIS PHASE","text":""},{"location":"Data_Structures/#type-table","title":"Type Table","text":"<p>The Type Table stores all the necessary information regarding the various user defined types in the source program. The compiler creates an entry in the Type Table for each user defined type. In addition to this, there are default entries created for primitive types (int, str) and special entries null, boolean and void for the internal purposes of the interpreter. The default and special entries are made beforehand whereas entries for user defined types are made as the Type Declaration Section of the source code is parsed.</p>"},{"location":"Data_Structures/#structure","title":"Structure","text":"<p>The structure of Type Table is as follows:</p> <p>The variable 'fields' is a pointer to the head of 'fieldlist'. Here 'fieldlist' stores the information regarding the different fields in the case of a user-defined type.</p>"},{"location":"Data_Structures/#associated-methods","title":"Associated Methods","text":"<ul> <li>void TypeTableCreate() : Function to initialise the type table entries with primitive types (int,str) and internal data types (boolean,null,void).</li> <li>struct Typetable* TLookup(char *name) : Search through the type table and return pointer to type table entry of type 'name'.</li> <li>struct Typetable* TInstall(char *name, struct Fieldlist *fields) : Creates a type table entry for the type of 'name' with given 'fields' and returns the pointer to the type table entry.</li> <li>void FInstall(char *name, struct Typetable *type) : Adds a fieldlist entry with given 'name' and 'type'.</li> <li>struct Fieldlist* FLookup(char *name, struct Fieldlist *list) : Searches for a field of given 'name' in the given 'fieldlist' (of some user-defined type) and returns a pointer to the matching entry.</li> </ul>"},{"location":"Data_Structures/#illustration","title":"Illustration","text":"<p>Let us consider the following sample code:</p> <ol> <li> <p>The type table is first created and initialised to contain the default entries for each of the primitive and internal datatypes. This is done through a call to the function TypeTableCreate() from main function before yyparse() is called to start parsing the code. After the execution of TypeTableCreate() , the type table will be as follows:  </p> <p></p> </li> <li> <p>As soon as the compiler encounters the declaration of a user defined type, it is installed into the type table. Subsequently the fields are attached to this type table entry. For instance, in the case of the user-defined type linkedlist, as soon as the name linkedlist is encountered, a type table entry with 'name' set to linkedlist and 'fields' set to NULL is created. Later, on finishing the complete parse of the type definition, the fieldlist is created and it is attached to the type table entry. NOTE : A type table entry is created as soon as the type name is seen. This is because a field of the type may be of same type (For example, just like next is of type linkedlist in the type definition of linkedlist). When the 'fieldlist' is created, the type of the field is set by looking up the type table.  </p> <p></p> </li> <li> <p>Similar actions are carried out for user-defined type marklist also.  </p> <p></p> </li> <li> <p>Once the type declaration section is completely parsed, the type table is fully created and will not be further modified or updated.</p> </li> </ol>"},{"location":"Data_Structures/#symbol-tables","title":"Symbol Tables","text":"<p>Symbol tables are used to store information pertaining to the variables and functions in a program.</p>"},{"location":"Data_Structures/#global-symbol-table","title":"Global Symbol Table","text":"<p>The global symbol table stores information pertaining to all the global variables and functions in an ExpL program.</p>"},{"location":"Data_Structures/#structure_1","title":"Structure","text":"<p>The structure of Global Symbol Table(GST) is as follows:</p> <p>\u271bNOTE: In the case of a compiler, fbinding must store the starting address of the function's code in memory. A call to the function must translate into an assembly level call to the function's code in memory. Hence, in this case fbining has to be an integer storing a memory address.</p> <p>Arglist is used to store information regarding the types and names of the arguements. ArgStruct has the following structure.</p> <p>Read about ASTNode here.</p>"},{"location":"Data_Structures/#associated-methods_1","title":"Associated Methods","text":"<ul> <li>struct Gsymbol* GInstall(char *name,struct Typetable *type, int size, struct ArgStruct *arglist) : Creates a Global Symbol object of given 'name', 'type', 'size' and 'argument list' and assigns a 'binding' to the variable.</li> <li>struct Gsymbol* GLookup(char *name) : Search for a GST entry with the given 'name', if exists, return pointer to GST entry else return NULL.</li> </ul>"},{"location":"Data_Structures/#illustration_1","title":"Illustration","text":"<p>Continuing with earlier example, let us add Global declaration section to it.</p> <ol> <li>As soon as the compiler encounters the global declaration of a variable or funtion, it is installed into Global Symbol Table. Subsequently, the arguments are attached to the entry in case of functions. Following is how GST looks when studentname is installed.</li> </ol> <p></p> <ol> <li>Similarly for rollno,average,findaverage(linkedlist marks), symbol table entries are formed and installed. The fbinding for a function is the abstract syntax tree of the function definition and is set only after complete parsing of the function definition.  </li> </ol> <p></p> <ol> <li>After this, the types for rollno,average and findaverage will be set and these objects are appended to the global symbol table. The final Global Symbol table looks as follows:  </li> </ol> <p></p>"},{"location":"Data_Structures/#local-symbol-table","title":"Local Symbol Table","text":"<p>In addition to the global symbol table, the ExpL compiler maintains a separate local symbol table for each function for storing information regarding the functions arguments and local variables. Each function has its own list of local variables. So each function has its own LST.</p>"},{"location":"Data_Structures/#structure_2","title":"Structure","text":""},{"location":"Data_Structures/#associated-methods_2","title":"Associated methods","text":"<ul> <li>struct Lsymbol* LInstall(char *name,struct Typetable *type) : Creates a local symbol tbale with given 'name' and 'type' and also sets its 'binding'.</li> <li>struct Lsymbol* LLookup(char *name) : search the LST and if any entry with given 'name' is found ,return the entry,else returns NULL.</li> </ul> <p>Arrays cannot be local variables, so we don't need to store the size of a variables. Also nested functions are not allowed in ExpL, so we don't require fbinding and arglist as in Gsymbol. The LST is formed for the Local Declaration Section in the same way GST was created for the Global declaration section.</p> <p>Memory is allocated for local variables of a function from a seperate memory area called the stack. Hence, the binding for a local variable is the relative address of the variable with respect to the base of the [Activation Record]. The [Base Pointer] points to the base of an activation record of a function. The binding is added to the Base Pointer to obtain the address of variable in stack. This will be explained in detail later.</p>"},{"location":"Data_Structures/#abstract-syntax-tree","title":"Abstract Syntax Tree","text":"<p>The machine independent front-end phase of a compiler constructs an intermediate representation of the source program called the Abstract Syntax Tree (AST). An interpretter will evaluate the AST whereas a compiler will run a machine dependent back-end to generate a target assembly language program. The following structure may be used to represent a node of the AST.</p> <p>The union Constant is used to store the value of an integer or sting constant.</p>"},{"location":"Data_Structures/#associated-methods_3","title":"Associated methods","text":"<ul> <li>struct ASTNode* TreeCreate (     struct Typetable *type,     int nodetype,     char *name,     union Constant value,     struct ASTNode *arglist,     struct ASTNode *ptr1,     struct ASTNode *ptr2,     struct ASTNode *ptr3     )     Creates a node with the fields set according to the arguements passed.</li> <li> <p>regindex evaluate(struct ASTNode *t)     Evaluation of an AST node results in a value. A compiler generates code for evaluating an AST node and assigns the result of evaluation to a register. An interpreter directly evaluates the AST node and simulates the compiler by storing the result in an array (called reg) and returning the index. We make use of the following structure to store the results of evaluation by an interpreter:</p> <p>In 'valstruct' the field 'valtype' can take one of the following values:</p> <ol> <li>EMPTY : Indicates that no value is stored in it.</li> <li>INT : Indicates that value stored in the union constant 'value' is an integer.</li> <li>STR : Indicates the value stored in the union constant 'value' is a string.</li> <li>H_INDEX : Indicates that valstruct stores the (integer) index of a location in the heap.</li> </ol> </li> </ul> <p>Follwing are the nodetypes that may appear while contructing the abstract syntax free for ExpL program:</p> <p>Nodetype</p> <p>Description</p> <p>LEAF</p> <p>For interger and string constants.</p> <p>ID</p> <p>For all variable literals.</p> <p>PLUS</p> <p>For arithmetic operator '+'. Attributes 'ptr1' and 'ptr2' of the 'ASTNode' are set to AST of left and right operands respectively and must be of type 'int'. 'ptr3' is set to NULL.</p> <p>MINUS</p> <p>For arithmetic operator '-'. Attributes 'ptr1' and 'ptr2' of the 'ASTNode' are set to AST of left and right operands respectively and must be of type 'int'. 'ptr3' is set to NULL.</p> <p>MUL</p> <p>For arithmetic operator '*'. Attributes 'ptr1' and 'ptr2' of the 'ASTNode' are set to AST of left and right operands respectively and must be of type 'int'.</p> <p>DIV</p> <p>For arithmetic operator '/'. Attributes 'ptr1' and 'ptr2' of the 'ASTNode' are set to AST of left and right operands respectively and must be of type 'int'.</p> <p>GT</p> <p>For relational operator '&gt;'. Attributes 'ptr1' and 'ptr2' of the 'ASTNode' are set to AST of left and right operands respectively and must be of type 'int'.</p> <p>LT</p> <p>For relational operator '&lt;'. Attributes 'ptr1' and 'ptr2' of the 'ASTNode' are set to AST of left and right operands respectively and must be of type 'int'.</p> <p>GE</p> <p>For relational operatot '&gt;='. Attributes 'ptr1' and 'ptr2' of the 'ASTNode' are set to AST of left and right operands respectively and must be of type 'int'.</p> <p>LE</p> <p>For relational operatot '&lt;='. Attributes 'ptr1' and 'ptr2' of the 'ASTNode' are set to AST of left and right operands respectively and must be of type 'int'.</p> <p>EQ</p> <p>For relational operator '=='. Attricutes 'ptr1' and 'ptr2' of the 'ASTNode' are set to AST of left and right operands respectively and both must be of same type.</p> <p>NE</p> <p>For relational operator '!='. Attricutes 'ptr1' and 'ptr2' of the 'ASTNode' are set to AST of left and right operands respectively and both must be of same type.</p> <p>IF</p> <p>For the conditional contruct 'if'. Attribute 'ptr1' of the 'ASTNode' is set to AST of the conditional logical expression, 'ptr2' is set to AST of list of statements that are executed when conditional expression evaluates to true and 'ptr3' is set to AST of list of statements that are to be executed when conditional expression is evalusted false.</p> <p>WHILE</p> <p>For conditional construct 'while'. Attribute 'ptr1' os 'ASTNode' is set to the conditional logical expression and 'ptr2' is set to AST of list of statements under the while construct.</p> <p>READ</p> <p>For input statement 'read'. Attribute 'ptr1' is set to AST of nodetype ID, which carries the information of the variable for which we are taking the input.</p> <p>WRITE</p> <p>For output statement 'write'. Attibute 'ptr1' is set to AST of the expression, whose value is to be written to the standard output.</p> <p>ASGN</p> <p>For assignment statement ( = ). Attribute 'ptr1' is set to AST of nodetype ID or FIELD and 'ptr2' is set to AST of expression whose value will be assigned to lvalue given by 'ptr1'. <p>SLIST</p> <p>To connect statements.</p> <p>BODY</p> <p>For body of a function.</p> <p>RET</p> <p>For return statement of a function.</p> <p>FUNCTION</p> <p>For function calls.</p> <p>PARAM</p> <p>For passing actual parameters during function calls.</p> <p>MAIN</p> <p>For main function.</p> <p>FIELD</p> <p>For user-defined types.</p>"},{"location":"Data_Structures/#illustration_2","title":"Illustration","text":"<p>Consider the following program</p> <p>1. Lets construct the abstract syntax tree step by step. The AST for conditional expression <code>n==1</code> (in line 9) will be as follows:</p> <p> </p> <p>2. Similarly we have AST fot <code>n==0</code> (in line 9) as follows.</p> <p></p> <p>3. Next consider the complete conditional expression <code>n==1 || n==0</code>.</p> <p></p> <p>4.Next we will form the AST for assignment statement <code>f = 1</code> (in line 10).</p> <p></p> <p>5. Next, lets consider the statement <code>f = n * factorial(n-1)</code> which consists of arthimetic expressions with operands '-','*' and an assignment statement.</p> <p>AST for <code>n-1</code> is as follows.</p> <p></p> <p>AST for <code>n * factorial(n-1)</code> is as follows.</p> <p></p> <p>AST for <code>f = n * factorial(n-1)</code> is as below.</p> <p></p> <p>6. Following is the AST for the if condition.</p> <p></p> <p>7. The AST for return statement is as folows</p> <p></p> <p>8. Finally the AST for the factorial function will be as follows.</p> <p></p>"},{"location":"Data_Structures/#data-structures-for-execution-phase","title":"DATA STRUCTURES FOR EXECUTION PHASE","text":"<p>Before explaining the data structures used for the execution phase, it is necessary to understand the requirements and the underlying theoretical concepts in some detail.</p>"},{"location":"Data_Structures/#the-storage-allocation-problem","title":"The storage allocation Problem","text":"<p>This part of the documentation primarily focuses on program interpretation.\u00a0 However, our interpreter will be somewhat mimicing the actions of a compiler and hence the reader will be able to easily adapt what is learned here to handle the synthesis phase of compilation by going through this documentation.</p> <p>An interpreter needs to \"execute\" the abstract syntax tree and hence the interpreter must arrange storage for run time data and subroutine invocations (function calls).</p> <p>A program contains global variables as well as variables that are local to functions, both requiring memory space. Of these, global variables are the simplest to handle because during the analysis phase we know how many global variables are there in the program (all global variables are declared) and how much space needs to be allocated for each of them (why?). Thus, the storage requirements of global variables are completely determined at compile time and they can be assigned memory addresses during the analysis phase itself. Such allocation is called static allocation. The binding field of the global symbol table entry for a variable stores a pointer (address) to the memory allocated to the variable. The symbol table information will be used during the execution phase to find out the location in memory where the variable is stored.</p> <p>[In the case of compilation, the memory addresses for each global variable in the target machine is determined during the analysis phase and are stored in the binding field of the symbol table.]</p> <p>As a point aside, the binding field of the symbol table entry for a function is set to hold a pointer to the abstract syntax tree of the function. This helps the evaluation phase to locate the corresponding abstract syntax tree whenever a function call is encountered during the execution phase.</p> <p>[In the case of a compiler, the the analysis phase will decide on the addresses in the code area of memory where the function's code is loaded. The address to which a call to the function must be directed to is stored in the binding field of the symbol table.]</p> <p>Variables which are local to functions demands more complicated allocation. This is because a function may be invoked several times and for each invocation, separate storage needs to be allocated for variables defined within the scope of the function (i.e., local variables and arguments).\u00a0 [Why?] Moreover, we do not know during the analysis phase how many times a function will be invoked during the execution phase.\u00a0 [Why?]</p> <p>To understand this, consider the factorial program below.</p> <p>The function factorial contains an argument n. Suppose the initial value of n input by the user at run time was 5, then factorial(n) with n=5 is invoked from the main. This function invokes factorial(n) with n=4. However, we need to retain the old value of n since the orginal factorial function must resume execution after the completion of factorial(4). Thus, we cannot statically assign a fixed memory address to the variable n. Instead, for each invocation of the function, we need to create a different memory space for storing the value of n. Moreover, the initial value of n given by the user is not known at compile time. Hence cannot determine at compile time the exact storage requirement. We will have to design the compiler/interpreter to allocate memory space as is necessary during run time.</p> <p>In addition to allocating storage for local variables and arguments, additional storage needs to be allocated at run time for each invocation of a function to store the return values of the call and control information like a pointer to the next instruction in the calling function (return address)].</p> <p>The classical solution to handling function invocation is to maintain a run time stack. Whenever a function is invoked during execution, an activation record is created in the run time stack with sufficient space for storing local variables, arguments, return values and return address and the stack grows. Upon return from the function, the activation record is popped out of the stack and the activation record of the calling program will be in the top of the stack. Thus, at each point during execution, the activation record of the currently executing function will be on the top of the stack. Such storage allocation is called stack based run time allocation.</p> <p>[Note: The semantics of ExpL makes stack based allocation possible. Primarily, this is possible because data stored in an activation record can be forgotten once the execution of the call is finished. There are languages like LISP which permit higher order functions where a stack based run time allocation is not possible. Languages which permit stack based run time allocation for function invocations are said to follow stack discipline.]</p> <p>Observe that for each function defined in an ExpL program, the amount of storage needed in its activation record is known during the analysis phase. [Why?] What is not known is how many activation records will have to be created in the stack as this is known only during execution time.</p> <p>In addition to allocating storage for global variables and variables local to functions, ExpL supports dynamic memory allocation through the alloc() function. The alloc() function allows a program to request for memory space at run time. Since the amount of memory requested is not known during the analysis phase (why?), static allocation is not possible in this case. Stack allocation also is ruled out because memory allocated by alloc() inside a function is not de-allocated when the function returns. Hence, a mechanism to dynamically allocate memory on demand at run time is required.</p> <p>The classical solution to this problem is to maintain an contiguous area of memory called the heap memory from which memory is allocated by alloc() on demand. Heap management algorithms like the fixed size allocator algorithm and the buddy system algorithm are explained in detail later in this documentation.</p> <p>Finally, intermediate values generated during program execution needs temporary storage. For example, while evaluating an expression (a+b)*(c+d), the values of the sub-expressions (a+b) and (c+d) might need temporary storage. In a compiler, the machine registers are used for temporary storage. Our interpreter will simulate the compiler by having an array of \u201cregisters\u201d for storing such temporary values. When a function invokes another function, the registers in current use will be pushed to the stack (activation record of the caller) so that the called function (callee) has the full set of registers free for its use. Upon return from the callee, the values pushed into the stack are restored to the registers before the caller resumes its execution.</p> <p>To summarize, we have four kinds of memory allocation \u2013 static, stack, heap and register (temporary). The data structures and algorithms necessary for implementing each of these are discussed below.</p>"},{"location":"Data_Structures/#the-memory-model","title":"The memory model","text":"<p>Our interpreter will simulate machine memory and registers by defining three memory arrays, named stack, heap and registers.</p> <p></p> <p>The basic unit of memory (called a memory word) is assumed to be able to store an integer or a string. This model is assumed because the primitive data types of ExpL are integer and string. The interpreter therefore defines the following memory structure:</p> <p>The interpreter works with three arrays of memory words, to implement temporary storage (registers), the run time stack and the heap. There will be no sperarate memory array for static data. Instead, the intial part of the stack will be used for storing static data.</p>"},{"location":"Data_Structures/#register-allocation","title":"Register Allocation","text":"<p>Register allocation is performed through two simple functions.</p> <ul> <li>int get_register(): Allocates a free register from the register pool reg[16] and returns the index of the register, returns -1 if no free register is available.</li> <li>int free_register(): Frees the last register that was allocated,returns 0 if success, returns -1 if the function is called with none of the registers being allocated.</li> </ul> <p>The interpreter invokes these functions in the course of evalaution of expressions to create temporary store.</p>"},{"location":"Data_Structures/#static-allocation","title":"Static Allocation","text":"<p>As noted previously, global variables are allocated statically. In our interpreter, the initial portion of the stack will be used for static allocation. The rest of the stack memory region will be used for run time allocation. The amount of static storage required is known from the variable declarations.</p>"},{"location":"Data_Structures/#run-time-stack-allocation","title":"Run Time Stack Allocation","text":"<p>During run-time, when an ExpL function is invoked, space has to be allocated for storing</p> <ul> <li>the arguments to the function,</li> <li>return value of the function,</li> <li>local variables declared in the function.</li> </ul> <p>For this, an activation record is created in the stack for each function call (and the stack grows). The activation record is also used to save the state (registers in use) of the invoking function and some control information (like the return address of the calling program in the case of a compiler).</p> <p>Each activation record has a base, and the base pointer (BP) is a variable (or a machine register in the case of a compiler) that points to the base of the current functions activation record. When one function invokes another, the base pointer value of the caller is pushed on to the stack and BP is set to point to the new activation record base. Upon return, the activation record is popped off the stack and old value of base pointer is restored. The stack pointer (SP) points to the top of the stack.</p> <p>The calling convension fixes in what order arguments to a function must be pushed by the caller to the called function, the place in the activation record where the return value is expected to be written by the callee etc. The structure of the activation record explained below will clarify the calling convension.</p> <p></p> <p>When a function is invoked, a part of the activation record is set up by the caller and the rest is set up after invocation of the function. Similarly, when a function returns, the callee and the caller are responsible for removing the parts they have set up.</p> <p>The following sequence of actions occur when a function A calls another function B.</p> <ol> <li>A pushes its machine state (registers in use) into the stack so that the registers are free for use in B.</li> <li>A pushes to arguments to B in the order they appear in the declaration.</li> <li>A pushes one empty space in the stack for B to place its return value.</li> <li>A invokes B. (In the case of a compiler, this results in generation of a CALL instruction which results in pushing the instruction pointer into the stack and transfer of control to B).</li> </ol> <p>Inside B, the following space allocations take place:</p> <ol> <li>B saves the BP value of A to the stack and sets its own BP to the location where the BP of A is stored.</li> <li>B allocates space for local variables (in the order in which they appear in the delcaration.</li> </ol> <p>This completes the activation record for B. If B later calls another function C, then it starts saving its registers, pushes arguments to C and so on.</p> <p>When B completes execution the following sequence of actions take place:</p> <ol> <li>B pops out the local variables.</li> <li>The old BP value is popped off and saved into BP.</li> <li>B returns (in the case of a compiler, this results in generation of a RET instruction which results in setting the instruction pointer to the value saved in the stack).</li> </ol> <p>On re-entry, A does the following:</p> <ol> <li>Retrieve the return value from stack and save it to a new register. This is the result of the function call.</li> <li>Pop off the arguments.</li> <li>Restore the saved register context.</li> </ol> <p>Consider the following example:</p> <ol> <li> <p>The global variables are allocated statically in the initial portion of the stack.</p> <p></p> </li> <li> <p>The main functions sets up stack locations for its local variables and calls the function factorial(3) after setting up a part of the callee's activation record.</p> <p> </p> </li> <li> <p>Factorial(3) saves the old Base pointer and sets up locations for its local variables.</p> <p></p> </li> <li> <p>Factorial(3) calls factorial(2) and the activation record of factorial(2) is setup similar to the above steps.</p> <p></p> </li> <li> <p>Activation record for factorial(1) (called by factorial(2)) is seup similarly.</p> <p></p> </li> <li> <p>factorial(1) calculates the result and returns it by setting the value at return value location and pops off it local variables and sets back the base pointer.</p> <p></p> </li> <li> <p>Similarly, factorial(2) calculates the steps and pops off its activation record till the result value after setting back the old base pointer.</p> <p></p> </li> <li> <p>Similarly, factorial(3) also calculates the result and returns it to the main function.</p> <p></p> </li> <li> <p>Main function calculates and sets the 'result' variable.</p> <p></p> </li> </ol>"},{"location":"Data_Structures/#stack","title":"Stack","text":"<p>The stack is used to store data structures called activation records that are generated during procedure calls. An activation record is used to store the information such as value of program counter and machine registers when a function call occurs. When control returns from the function call, the activation of the calling procedure can be restarted after restoring the relevant registers and setting program counter to the point immediately after the call. Also, data of objects whose lifetime are contained in that of an activation can be allocated on the stack along with other information associated with activation.</p>"},{"location":"Data_Structures/#structure_3","title":"Structure","text":"<p>So, for the implementation of the interpreter, we create a stack which is an array of memstruct. Memstruct has the following structure. NOTE : for compiler, the stack structure and functions supported functions depends and is taken care of by the target machine.</p> <p>The type field in memstruct can take the following values</p> <ol> <li>EMPTY : Indicates no value is stored in it.</li> <li>INT : Indicates that it stores an integer value.</li> <li>STR : Indicates that it stores a string value.</li> <li>H_INDEX : Indicates that valstruct stores the (integer) index of a location in the heap.</li> <li>SIZE : Indicates that this memstruct is the first index of the allocated block for a dynamically allocated variable, and it stores the size of the block allocated for the variable.</li> </ol>"},{"location":"Data_Structures/#associated-methods_4","title":"Associated methods","text":"<ul> <li>void push(struct valstruct *v) : pushes the values in valstruct to stack accordingly.</li> <li>struct valstruct* pop() : pops a value on top of the stack as a valstruct.</li> <li>void load(struct memstruct *m, struct valstruct *v) : loads the values in stack location pointed by m to the value structure v</li> <li>void store(struct memstruct *m,struct valstruct *v) : stores the values in value structure v to the stack location pointed by m.</li> </ul> <p>NOTE : valstruct and memstruct structures have been used here to keep the fine line between a value object and a object in the memory.</p>"},{"location":"Data_Structures/#heap-allocation","title":"Heap Allocation","text":"<p>A storage allocation decision can be static or dynamic. A decision is dynamic if it can be decided only while the program executes. In simple terms, consider the previous example, the size of the linkedlist marks is not known at the compile time, its size is only known at the run-time when we read in the count of subjects.</p> <p>In interpreter, for heap we will be using an memstruct array of size 1024.</p>"},{"location":"Data_Structures/#associated-methods_5","title":"Associated methods","text":"<ul> <li>void intialise() : To initialise the heap with required initial values.</li> <li>int alloc(int size) : allocates continuos locations of given size and returns the starting address of allocated block.</li> <li>int free(int addr) : frees the memory block starting with the given addr are erasing the data in that block and returns a value indicating the success and failure of free operation.</li> </ul>"},{"location":"Data_Structures/#allocation-algorithms","title":"Allocation algorithms","text":"<p>The two types of allocation-deallocation algorithms we will discuss here for heap management are fixed memory and buddy memory management.</p>"},{"location":"Data_Structures/#fixed-memory-allocation","title":"Fixed Memory Allocation","text":"<p>In this algorithm, the chunk size allocated is fixed. Lets call the fixed size as HB_SIZE, say 8. The heap is considered here as a list of blocks of HB_SIZE.</p> <p>The first block in the list is reserved. Initially, the first index of reserved block stores the index of first free block. The first index of every free block stores the index of next available free block. The last block stores -1 in the first index. This is how it looks initially(after the call to initialise function).</p> <p></p> <p>Following is the allocation algorithm.</p> <ol> <li>First index of reserved block is checked, let the value be v.</li> <li>If v is -1, return -1 indicating no free blocks are available.</li> <li>Else, allocate the free block at v, after copying the next free block index stored at v to the reserved block.Return v.</li> </ol> <p>Following is the pseudo code of the algorithm.</p> <p>Following is the deallocation algorithm.</p> <ol> <li>The arguement passed : starting address of the block(say s) to be deallocated</li> <li>The block s is cleared by setting all memstructs in the block to type EMPTY.</li> <li>The value in the first index of reserved block is copied to first index of block s.</li> <li>The first index of reserved block is set with starting address of block s.</li> </ol>"},{"location":"Data_Structures/#illustration_3","title":"Illustration","text":"<p>This section shows how the heap looks after each step of allocation or free. This is for the better understanding of the algorithms.</p> <ul> <li> <p>x = alloc();</p> <p></p> </li> </ul> <p>x is a memstruct in the run-time stack of type MEMSTRUCT_BIND with intval 8.</p> <ul> <li> <p>y = alloc();</p> <p></p> </li> <li> <p>z = alloc();</p> <p></p> </li> <li> <p>dealloc(x);</p> <p></p> </li> <li> <p>dealloc(z);</p> <p></p> </li> <li> <p>z = alloc();</p> <p></p> </li> </ul>"},{"location":"Data_Structures/#buddy-memory-allocation","title":"Buddy Memory Allocation","text":"<p>In this technique, memory is divided into partitions to try to satisfy a memory request as suitably as possible. This technique makes use of splitting memory into halves to give a best-fit.</p> <p>Every memory block in this technique has an order, a number ranging from 0 to a specified upper limit. The size of block of order n is 2n. So the blocks are exacly twice the size of blocks of one order lower. Power-of-two block sizes makes address computation simple, because all buddies are aligned on memory address boundaries that are powers of two. When a larger block is split, it is divided into two smaller blocks, and each smaller block becomes a unique buddy to the other. A split block can only be merged with its unique buddy block, which then reforms the larger block they were split from.</p> <p>Starting off, the size of the smallest possible block is determined, i.e. the smallest memory block that can be allocated. The smallest block size is then taken as the size of an order-0 block, so that all higher orders are expressed as power-of-two multiples of this size. In our implementation, we consider the smallest memory block size to be 8. So, the memory block sizes will be 8, 16, 32, 64, and so on. In our implementation, we take the heap of size 1024.</p> <p>In our implementation, we have a heap of size 1024. The smallest block size possible in the heap is 8 (order 0). The highest block size of 2n that is free is 1024.We maintain a free list for all possible block sizes. So we have freelists for sizes 8,16,32,64,128,256,512 and 1024, i.e, we maintain eight freelists.</p> <ul> <li>We have only one block of size 1024 and so the size of freelist for 1024 is 1(20).</li> <li>In the 1024 sized heap, we have two blocks of size 512. Note that, both blocks cannot be free at the same time. If both blocks are free, they will be merged to a free block of size 1024(whose information will be maintained in the freelist for blocks of 1024 size). So at a time, maximum number of blocks that are free of size 512 is 1 ( 20).</li> <li>Similarly in case of blocks of size 256, 1024 sized heap has 4 blocks of size 256 (say a,b,c and d in their respective order).a and b are buddies of each other, of which both cannot be free at a time due to merging, so only one of them can be free. Similarly in case of c and d, only one of them can be free. 1 + 1 , 2 ( 21) is the maximum size of free list for blocks of 256.</li> <li>Similarly, there are 8 blocks of 128 in 1024 (a,b,c,d,e,f,g and h). (a,b)(c,d)(e,f)(g,h) are buddy pairs and only one of each pair can be free. So the maximum size of freelist for blocks of 128 is 4 ( 22).</li> <li>Similarly, the maximum size of freelist for blocks of sizes 64,32,16 and 8 are 8 ( 23),16( 24),32( 25) and 64( 26) respectively.</li> </ul> <p>So, the size of the complete freelist is 20 + 20 + 21 + 22 + 23 + 24 + 25 +26 = 128.</p> <p>We will maintain the freelist inside the heap, So initially we won't have the complete heap of 1024 free. So we need not require a freelist for size 1024. We will store the complete freelist in a 128 sized block. Therefore, initially we have the first 128 block(0-127) of the heap reserved for freelist maintainence. Then we have a 128 sized free block(128-255), then a 256 block(256-511) and then a free block of 512 size(512-1023). Following is the diagrammatic representation of the heap initial status.</p> <p></p> <p>The free-list in the heap has to be initialised as above. Also, the first index of each allocated block through alloc function will store the size of allocated block. This is to figure out the size that has been allocated when the dealloc function is called for a variable, which provides only the starting address of the block that has been allocated.</p> <p>Following is the allocation algorithm : (argument : Request for a block of size 'A')</p> <ul> <li>Look for a memory slot of suitable size(i.e, the minimal 2k block that is larger or equal to that of the requested memory A + 1, a plus one as first index is used to store the size of block allocated), lets call the ceiled size as 'B'.<ol> <li>If found, the starting index of the allocated block is returned to the program after removing it from the freelist.</li> <li>If not, it tries to make a suitable memory slot by following the below steps<ol> <li>Split a the next larger suitable free memory slot into half.(Remove the next larger suitable free memory slot from it free list and add both the halves to the corresponding freelist).(Note : of there is no larger free memory slot - return -1 indicating that no free space is available).</li> <li>If the required size 'B' is reached, one of the halves is allocated to the program.</li> <li>Else go to the step a and repeat it until the memory slot of required size 'B' is found.</li> </ol> </li> </ol> </li> </ul> <p>Following is the deallocation algorithm (arguement : the starting address of the allocated block)</p> <ol> <li>Get the size, say 's' of the block from the first index of the block. Free the complete block with the help of size obtained by setting all the memstruct type to MEMSTRUCT_EMPTY.</li> <li>Check if the buddy of the block is free by checking the whether the buddy's starting address is present in the free list for blocks of size 's' .</li> <li>If the buddy is not free, add the current freed block to its free list.</li> <li>If the buddy is free, remove the buddy from the freelist and combine the two, and go back to step 2 to check for the buddy of merged block. Repeat this process until the upper limit is reached or buddy is not free.</li> </ol> <p>The psuedo code for alloc and dealloc functions is as follows :</p>"},{"location":"Data_Structures/#illustration_4","title":"Illustration","text":"<p>For a better understanding purpose, we will have a simple illustration of how heap memory looks like through a set of some allocations and deallocations.</p> <p>For illustration, we will have 64-sized heap and smallest block size as 8. So we free lists for sizes 8,16 and 32 of lengths 4 ,2 and 1. So we will use a 8-size block to store the free-list.</p> <ol> <li> <p>The heap looks initially as follows.</p> <p></p> </li> <li> <p>Request for memory of size 5. Lets call this request as A. The nearest 2^k value for 5 is 8. We search for a 8 sized free block. We have one such! Allocate it!</p> <p></p> </li> <li> <p>Next we will have a reuqest B of size 14.</p> <p> </p> </li> <li> <p>Now we have a request C of size 7.</p> <p></p> <p></p> <p></p> </li> <li> <p>Now, C releases its memory.</p> <p></p> <p></p> <p></p> </li> </ol>"},{"location":"abi/","title":"Application Binary Interface","text":""},{"location":"abi/#introduction","title":"Introduction","text":"<p>The ExpL compiler needs to translate a given source program and generate the target machine code into an executable file in a format which is recognized by the load module of the target operating system. Thus, in order to generate the executable, the following information needs to be made available to the compiler :</p> <ol> <li>The virtual machine model and the instruction set of the target machine.</li> <li>The (virtual) address space model available for the target program. Conventionally,     this address space is logically divided into regions like code, data, stack, heap etc.</li> <li>The format for the target file (executable format). The compiler typically passes     information regarding the sizes and address regions allocated to the code, data, stack,     text and heap regions to the loader by setting appropriate values in the header     of the executable file.</li> <li>Interfaces to OS (kernel) routines that needs to be invoked to get certain operations like     input/output done. This is specified     in the library interface documentation.</li> </ol> <p>These specifications depend not only on the target machine architecture, but also on the operating system upon which the target machine code must execute. Typically these specifications are collected together in the OS specification into a document called the Application Binary Interface (ABI).</p> <p>The following sections specify the ABI for the eXpOS operating system run on the XSM virtual machine model. The executable format is called the XEXE executable format.</p>"},{"location":"abi/#the-xsm-virtual-machine-model-and-instruction-set","title":"The XSM virtual machine model and instruction set","text":"<p>The virtual machine model provided to user level programs by the ExpOS on the machine is described here. The virtual machine model explains the \"view\" of the machine provided to the application by the operating system.</p> <p>The XSM virtual machine contains 20 general purpose registers (R0-R19) and three special registers  - Stack pointer (SP), Base pointer (BP) and the Instruction pointer (IP). The SP register is normally used to point to the top of the application program's stack. The BP register is used to point to the base of the activation record of the currently executing function. IP points to the next instruction in the user memory to be fetched and executed. The memory address space available to the application is of 5120 words starting at (virtual) address 0 and ending at (virtual) address 5119.</p> <p>The OS stipulates that this virtual address space must be divided into various regions called  library, code, heap and stack. These will be described in detail later. The virtual machine model  also allows the application to invoke traps to the operating system kernel for read, write and program termination (using the INT instruction). The details of the implementation of the kernel routines are hidden from the application and the application needs to know only the interface to invoke these routines. These interfaces will also be described later in this documentation.</p> <p>The following figure gives a high level picture of the XSM virtual machine model.</p> <p></p> <p>The XSM virtual machine instruction set specifies the set of assembly level instructions.  The compiler must translate the source ExpL program to a target program containing only these instructions. The assembly instructions allowed include Data Transfer Instructions, Arithmetic Instructions, Logical Instructions, Stack Instructions, Sub-routine instructions, Debug instructions and Software interrupts. The machine registers available to the target program are R0-R19, SP, BP and IP.</p>"},{"location":"abi/#data-transfer-instructions","title":"Data Transfer Instructions","text":"Addressing Type Syntax Semantics Register Adressing MOV Ri, Rj Copies the contents of register Rj to Ri Immediate Addressing MOV Ri, INTEGER/STRING Copies the INTEGER/STRING to the register Ri Register Indirect Addressing MOV Ri, [Rj] Copy contents of memory location pointed by Rj to register Ri. MOV [Ri], Rj Copy contents of Rj to the location whose address is in Ri Direct Addressing MOV [LOC], Rj Copy contents of Rj to the memory address LOC MOV Rj, [LOC] Copy contents of the memory location LOC to the register Rj"},{"location":"abi/#arithmetic-instructions","title":"Arithmetic Instructions","text":"<p>Arithmetic Instructions perform arithmetic operations on registers containing integers. If the register contains a non-integer value, an exception (illegal instruction) is raised.</p> Instruction Syntax Semantics ADD, SUB, MUL, DIV and MOD OP Ri, Rj The result of Ri op Rj is stored in Ri OP Ri, INTEGER The result of Ri op INTEGER is stored in Ri INR, DCR OP Ri Increments/Decrements the value of register Ri by 1 <p>For all the above instructions, Ri/Rj may be any register except IP.</p>"},{"location":"abi/#logical-instructions","title":"Logical Instructions","text":"<p>Logical instructions are used for comparing values in registers. Strings can also be compared according to the lexicographic ordering of ASCII. If one of the operands is a string, the other operand will also be considered as a string. The logical instructions are LT, GT, EQ, NE, GE and LE.</p> Type Syntax Semantics LT, GT, EQ, NE, GE, LE OP Ri, Rj Stores 1 in Ri if the value stored in Ri is less than/greater than/equal to/not equal to/greater than or equal to/less than or equal to that in Rj. Ri is set to 0 otherwise"},{"location":"abi/#branching-instructions","title":"Branching Instructions","text":"<p>Branching is achieved by changing the value of the IP to the word address of the target instruction specified by <code>target_address</code>.</p> Type Syntax Semantics JZ JZ Ri, target_address Jumps to target_address if the contents of Ri is zero JNZ JNZ Ri, target_address Jumps to target_address if the contents of Ri is not zero JMP JMP target_address Unconditional jump to target_address"},{"location":"abi/#stack-instructions","title":"Stack Instructions","text":"Type Syntax Semantics PUSH PUSH Ri Increment SP by 1 and copy contents of Ri to the location pointed to by SP POP POP Ri Copy contents of the location pointed to by SP into Ri and decrement SP by 1 <p>For both these instructions Ri may be any register except IP.</p>"},{"location":"abi/#subroutine-instructions","title":"Subroutine Instructions","text":"<p>The CALL instruction copies the address of the next instruction to be fetched(this value must be <code>IP + 2</code> since each instruction is two memory words) on to location <code>SP + 1</code>. It also increments SP by one and transfers control to the instruction specified by the <code>target_address</code>. The <code>RET</code> instruction restores the IP value stored at location pointed by SP, decrements SP by one and continues execution fetching the next instruction pointed to by IP</p> Type Syntax Semantics CALL CALL target_address/ Register Increments SP by 1, transfers IP + 2 to location pointed to by SP and jumps to instruction specified by target_address(or register containing the target address) RET RET Sets IP to the value pointed to by SP and decrements SP"},{"location":"abi/#debug-instruction","title":"Debug Instruction","text":"<p>Syntax : BRKP Semantics : The machine when run in debug mode invokes the debugger when this intruction is executed. This instruction can be used for debugging system code.</p>"},{"location":"abi/#software-interrupt","title":"Software Interrupt","text":"<p>Syntax : INT n Semantics : Generates an interrupt to the kernel with the interrupt number (n between 4 to 18) as an argument. The interrupt numbers relevant to the present project are given below.</p> System Call Interrupt Routine Number Read 6 Write 7 Exit 10"},{"location":"abi/#the-virtual-address-space-model","title":"The virtual address space model","text":"<p>The (virtual) address space of any eXpOS process is logically divided into four parts namely Library, Heap, Code and Stack.</p> <p></p> <p>The Library contains routines for implementing dynamic memory allocation functions <code>Alloc()</code>, <code>Free()</code> and <code>Initialize()</code> as well as the input output functions <code>Read()</code> and <code>Write()</code>. The eXpOS loader links the library routines at load time when a program is loaded into the memory for execution. The compiler can therefore assume that the library code will be \"there\" at run-time and hence need not generate the code for implementing the library. The compiler however must generate code to invoke the correct library routines with appropriate arguments while translating the high level functions Alloc(), Free(), Initialize(), Read() and Write(). The ABI specifies how this must be done. Among these, Alloc(), Free() and Initialize() are implemented as part of the library itself. The library will re-direct Read() and Write() to low level OS system calls. (One of the advanced stages of the ExpL project will ask you to implement the library itself.) The ABI stipulates that eXpOS will load the library between addresses 0 and 1023 of the address space. Note that since each XSM instruction takes up two memory words, the library can be of size at most 512 instructions.</p> <p>Heap is the portion of the address space reserved as the memory pool from which dynamic memory  allocation is done by the allocator routine (Alloc() function) of the library. The memory region between addresses 1024 and 2047 is reserved for the heap. The routine <code>Initialize()</code> will intialize  the data structures associated with the memory allocator, Alloc() will allocate memory and Free() will de-allocate a previously allocated memory block. A discussion on dynamic memory allocation and de-allocation can be found here.</p> <p>The Code region contains the target assembly language program generated by the compiler.  The OS loader loads the contents of an XEXE executable file  into this region (between memory addresses 2048 and 4095) of the address space. The loader expects that the first eight words of the XEXE executable file contains a header. The header contains instructions to the loader like the address of the first instruction to be executed (the loader will initalize the instruction pointer to this value before execution) and so on. The total size of the  code section (including the 8 word header) cannot exceed 2048 words. Since each XSM instruction  occupies two words in the memory, the maximum number of assembly instructions permitted in any target program generated by the compiler shall be 1020. Given an ExpL program as input, the job of the compiler is to generate an XEXE executable file containing the header and the  target assembly language program.</p> <p>Stack is the space reserved for the runtime stack of a program. Parameters and local variables associated with functions in a program are allocated in the stack. In the XSM architecture,  the stack grows upwards. The eXpOS ABI stipulates that the maximum stack size is 1024 words. Global variables must be allocated in the stack as the eXpOS ABI does not support a separate  Data region. The ABI stipulates that the compiler must allocate stack in the region between memory addresses 4095 and 5119 in the address space of the program.  A discussion on how the compiler must allocate variables in the stack can be found here.</p>"},{"location":"abi/#xexe-executable-file-format","title":"XEXE executable file format","text":"<p>The compiler must generate target code into a file in the format specified below so that the eXpOS loader recognizes the format and load the program into memory for execution correctly. Each executable file contains a header in which the compiler adds information like the initial value to be given to the stack pointer in the virtual address space, initial value of the instruction  pointer etc, the starting (virtual) addresses and sizes of various memory regions like text, stack, heap etc.</p> <p>Executable files in eXpOS must be in the XEXE format as eXpOS executes only files of such format. An XEXE executable file in eXpOS consists of two parts:</p> <ul> <li>Header</li> <li>Code</li> </ul> <p></p> <p>The maximum size of the file (including the header) is limited by 2048 words.</p> <p>The first eight words of an executable file are reserved for the header which describes the features of file. The structure of the header is :</p> <p></p> <p>XMAGIC is a number indicating the type of executable file. All XEXE files will have  magic number 0. For more on Magic Number, click here.</p> <p>Entry point contains the virtual address in memory of the first instruction to be executed (entry point) of the program after the OS loader has loaded it. During loading,  the instruction pointer must be initialized to this address.</p> <p>Text Size, Data Size, Heap Size and Stack size indicates the sizes of Text, Data, Heap and  Stack regions to be allocated by the OS loader when the file is loaded for execution.</p> <p>Note : The present eXpOS virtual address space model requires that the data and stack must be in  the same memory area and must be managed by the compiler / application program (this means that the program must contain the code to initialize the value of the stack pointer). The value of Data Size field is ignored. Moreover, the eXpOS loader sets the size of text region to 2048 words and stack region to 1024 words in memory irrespective of the values present in the header.</p> <p>If the Runtime Library must be included when the file is loaded, the Library Flag is set to 1 in the executable file. If this flag is not set then neither memory is allocated for the heap nor the library linked to the address space of the process at execution time.</p> <p>In summary, the eXpOS loader maps an executable file into its virtual address according to the following table :</p> Region Start Address End Address Library 0 1023 Heap 1024 2047 Code 2048 4095 Stack  4096 5119 <p> The Stack Pointer is not initialised to the address 4096 by the eXpOS loader.</p>"},{"location":"abi/#the-library-interface","title":"The library interface","text":"<p>The library provides a uniform interface through which an application program can invoke dynamic memory allocation / de-allocation routines (Alloc(), Free() and Initialize()), input - output routines (Read() and Write()) and program exit (Exit()). Thus, while translating a high level ExpL program containing calls to the above functions, a compiler needs to be concerned only about how to translate these high level function calls to the corresponding library function calls.</p> <p></p> <p>The ABI stipulates that all calls to the library functions must be translated by the compiler to a CALL to virtual address 0, with an appropriate function code that identifies the service requested  (Alloc(), Free(), Initalize(), Read(), Write() or Exit()). This is because the library is linked  to virtual address 0 of the address space of a process by the OS loader. A call to the library  requires four arguments (a function code to identify the service and three arguments) to be passed  through the stack. The library will invoke the corresponding low level system call / memory managemen t routine and returns to the user program the return value of the system call / memory management routine through the stack. The figure above shows the contents of the stack immediately before a call to this library routine.</p>"},{"location":"abi/#invoking-a-library-module","title":"Invoking a library module","text":"<pre><code>PUSH Function_Code  // Push Function Code\nPUSH Argument_1     // Push argument 1 to the stack\nPUSH Argument_2     // Push argument 2 to the stack\nPUSH Argument_3     // Push argument 3 to the stack\nPUSH R0             // Push an empty space for RETURN VALUE\nCALL 0              // Pass the control to virtual address 0.\n                    // (eXpOS loader links the library to virtual address 0)\n</code></pre> <p>A library module invocation using the high level application programmer's interface of a programming language like ExpL must be translated by the compiler to a set of machine instructions as given above.</p> <p>Following are the library functions and details relevant for ExpL Compilation:</p> Library Function Function Code Argument 1 Argument 2 Argument 3 Return Values Read \"Read\" -1 Buffer (int/str)  - 0 - Success -1 - File Descriptor given is invalid -2 - Read error Write  \"Write\" -2 Data  - 0 - Success -1 - File Descriptor given is invalid Exit \"Exit\" - - - - Initialize \"Heapset\" - - - 0 - Success -1 - Failure Alloc \"Alloc\" Size (int) - - Address in the heap allocated (int)  -1 - No allocation Free \"Free\" Pointer (int) - - 0 - Success -1 - Failure <p>Note</p> <p> The Read() library function expects a memory address from (or to) which read is performed.</p> <p>Note</p> <p> The Write() library function expects Data (final value to be printed) as argument.</p>"},{"location":"abi/#after-return-from-the-library-module","title":"After return from the library module","text":"<p>The following machine instructions are present after the CALL instruction in the ExpL compiled machine code given in the previous step.</p> <pre><code>POP Ri           // Pop and save the return value into some register Ri\nPOP Rj           // Pop and discard argument 3\nPOP Rj           // Pop and discard argument 2\nPOP Rj           // Pop and discard argument 1\nPOP Rj           // Pop and discard the function code\n                 // Now the stack is popped back to the state before call\n</code></pre> <p>The machine code shown above is executed upon return from the library call and pops out the values that were pushed before the call. The function code and arguments were inputs to the library module and hence they may be discarded now. The return value which is stored in the stack by the system call must be popped out and saved to some register. This value will be the only relevant information after return from the call.</p> <p>Note: The eXpOS library interface permits many more functions (interfaces to eXpOS system calls). Since these functions are not relevant for the implementation of the ExpL specification here, those details are left out. The full details of eXpOS library are given here.</p>"},{"location":"abi/#low-level-system-call-interface","title":"Low Level System Call Interface","text":"<p>The ExpL library file library.lib contains assembly instructions to implement the library  functions <code>Alloc()</code>, <code>Free()</code> and <code>Initialize()</code>. For the input/output functions Read()/Write() as well as the program exit system call Exit(), the library code invokes the corresponding ExpOS  system calls for console read/write/exit. Thus, the library simply converts the library call to a  low level call to the operating system. This is because console input/ouput functions are implemented at the OS level.</p> <p>In order to implement the library, one must know the low level system call interface to the  operating system so that the input/ouput calls to the library can be correctly translated to  the corresponding low level OS system calls. This section specifices the low level OS interface provided by the ExpOS Operating System running on the XSM machine architecture. The interface describes the software interrupt instruction (trap) corresponding to the consolve input/output system calls and the calling conventions for passing arguments and extracting return values of the system call through the application program's stack. This part is architecture as well as operating system dependent.</p>"},{"location":"abi/#system-calls","title":"System Calls","text":"<p>For an application program, there are two stages in executing a system call:</p> <ol> <li>Before the system call : The calling application must set up the arguments in the (user)     stack before executing the trap instruction.</li> <li>After the system call : The return value of the system call must be extracted from the stack.</li> </ol>"},{"location":"abi/#invoking-a-system-call","title":"Invoking a system call","text":"<p>A user program invokes a system call by first pushing the system call number and then the arguments into the stack and then invoking the INT machine instruction corresponding to the system call. The eXpOS ABI stipulates that the number of arguments pushed into the stack is fixed at three.</p> <pre><code>PUSH System_Call_Number     // Push system call number\nPUSH Argument_1             // Push argument 1 to the stack\nPUSH Argument_2             // Push argument 2 to the stack\nPUSH Argument_3             // Push argument 3 to the stack\nPUSH R0                     // Push an empty space for RETURN VALUE\nINT number                  // Invoke the corresponding INT instruction.\n                            // The number can be any number between 4 and 18\n</code></pre> <p>The ExpL library must translate Read() and Write() calls to a set of machine instructions  (see the instructions to the right). These are the stack operations that must be performed by the user program before the INT instruction is executed.</p> <p></p> <p>The arguments must be pushed into the stack in such a way that the last argument comes on the top. An additional push instruction ('PUSH R0') is inserted to have an empty space in the stack for the return value. The system call implementation stores the return value in this space. The system call number must be pushed to the stack before the call because the interrupt routine needs this value  to identify the system call. The figure to the left shows the data stored in stack just before an  INT instruction.</p> <p></p> <p>The INT instruction in XSM will push the value of IP + 2 on to the stack. This is the address of the instruction immediately following the INT instruction in the calling program. Each instruction  is 2 words, hence IP is incremented by 2. Upon execution of the IRET instruction from the system call, execution resumes from this value of IP. The INT instruction changes mode from User mode to Kernel mode and passes control to the Interrupt Routine corresponding to the system call. The figure to the right shows the contents of the stack immediately after the execution of the INT instruction.</p>"},{"location":"abi/#after-return-from-the-system-call","title":"After return from the system call","text":"<p>The IRET instruction transfers control back to the instruction that immediately follows the  INT instruction. The following machine instructions are present after the INT instruction in  the ExpL compiled machine code given in the previous step.</p> <pre><code>POP Ri           // Pop and save the return value into some register Ri\nPOP Rj           // Pop and discard argument 3\nPOP Rj           // Pop and discard argument 2\nPOP Rj           // Pop and discard argument 1\nPOP Rj           // Pop and discard the system call number\n                 // Now the stack is popped back to the state before call\n</code></pre> <p>The machine code to the left pops the values from the stack. The system call number and arguments were inputs to the system call and hence they may be discarded now. The return value which is stored in the stack by the system call is fetched and used by the user program by popping out  to some register.</p>"},{"location":"abi/#system-calls-and-their-translation","title":"System calls and their translation","text":"<p>Associated with each system call, there is a system call number and interrupt routine number.  The system call number is used to identify a system call. The interrupt routine number denotes the number of the interrupt routine which handles the system call.</p> System Call System Call Number Interrupt Routine Number Argument 1 Argument 2 Argument 3 Return Values Read 7 6 -1 Buffer (int/str)  - 0 - Success -1 - File Descriptor given is invalid -2 - Read error Write 5 7 -2 Data  - 0 - Success -1 - File Descriptor given is invalid Exit 10 10 - - - - <p>Note</p> <p> The Read() library function expects a memory address from (or to) which read is performed.</p> <p>Note</p> <p> The Write() library function expects Data (final value to be printed) as argument.</p>"},{"location":"attribute/","title":"ATTRIBUTE SYNTHESIS","text":""},{"location":"attribute/#introduction-to-attributes","title":"Introduction to attributes","text":"<p>In the last section of the YACC documentation we noted that it is possible to pass values associated with tokens from yylex() to yyparse(). We had described the term 'attribute' as a value associated with a token. YACC uses yylval to facilitate passing values from the lexical analyzer to the parser. In this document we will explore attribute values for non-terminals and how these attributes are handled by YACC internally. We will also be exploring the usage of YYSTYPE to define custom attribute types.</p> <p>yylval is a global variable of the default return type YYSTYPE declared by YACC in y.tab.c. In the YACC documentation, we had seen an example which illustrates the passing of attributes from yylex() to yyparse(). If the programmer were to use LEX to generate yylex(), then the attributes will have to be passed to yyparse() in a similar fashion i.e, using yylval (as shown below). In the LEX program, the yylex() simply returns the token by its name while the associated attribute is assigned to yylval which can be accessed by yyparse(). Note that, for LEX to return a token, the token must be declared in the declarations section of the YACC program. The following example is a LEX program which returns a token DIGIT when it finds a string matching the \"number\" pattern.</p> <pre><code>%{\n\n #include \"y.tab.h\"\n #include&lt;stdlib.h\\&gt;\n #include&lt;stdio.h\\&gt;\n\n%}\n\n number  \\[0-9\\]+\n\n%%\n\n {number} {\n                    yylval = atoi(yytext);\n                    return DIGIT;\n       }\n\n .  return \\*yytext;\n\n%%\n</code></pre> <p>In this example, we want to return the token DIGIT when an integer is found in the input stream. In addition to the token, we need to pass the value found in the input stream to yyparse(). The lexeme found in the input stream is a string which contains the integer found. atoi() is a built-in function of the type int defined in the stdlib.h header file. We use atoi() to obtain the integer equivalent of the lexeme found. The obtained integer value is then assigned to yylval.</p> <p>The following code segment is a YACC program which declares the token DIGIT. Recall that the following program must be run with a -d flag to the yacc command. This flag is used to create the y.tab.h file which facilitates a one way communication from YACC to LEX i.e., it is used to communicate the tokens declared in the YACC program to the LEX program. Let us refer to the task of LEX obtaining the token declarations from YACC as LEX importing the declarations. The y.tab.h file contains declarations of all the tokens in the YACC program. Note that the LEX program above includes the y.tab.h file in the auxiliary declarations section to import the declarations.</p> <pre><code>%{\n#include &lt;stdio.h\\&gt;\n%}\n\n%token DIGIT\n\n%%\n\nstart : expr '\\\\n'  {printf(\"\\\\nComplete\");exit(1);}\n    ;\n\nexpr:  expr '+' expr  {printf(\"+ \");}\n    | expr '\\*' expr  {printf(\"\\* \");}\n    | '(' expr ')'\n    | DIGIT   {printf(\"%d \",$1);}\n    ;\n\n%%\n\nyyerror()\n{\n    printf(\"Error\");\n}\n\nmain()\n{\n    yyparse();\n    return 1;\n}\n</code></pre>"},{"location":"attribute/#non-terminal-attributes","title":"Non-terminal attributes","text":"<p>In addition to values associated with terminal symbols, YACC also allows values to be associated with non-terminals. We extend our notion of an attribute to: \"An attribute is a value associated with a terminal or non-terminal grammar symbol\". The attribute of a grammar symbol in a production can be referred to in the actions section of a rule using a special YACC syntax: $1 for the first symbol in the body of a production, $2 for the second symbol, $3 for the third and so on. For example consider the following example of a YACC rule.</p> <p><pre><code>X: B C D\n</code></pre>  The value of a symbol 'B' can be referred to by $1, value of 'B' can be referred to by $2 and value of symbol 'C' can be referred to by $3. It is also possible to assign a value to the non-terminal which occurs as the head of a rule's production using $$. A value can be assigned to the symbol X using $$. Let's call these the attribute stack variables.</p> <p>Consider the problem of displaying two numbers in an input stream if they occur as a pair separated by a comma. Also suppose that the numbers must be displayed ONLY after a pair is found. Let us look at a YACC program that solves the problem.</p> <pre><code>pair: number ',' number  { printf(\"pair(%d,%d),$1,$3\"); }\n ;\nnumber: DIGIT   { $$=$1; }\n ;\n</code></pre> <p>In the program segment, the first rule displays the value of the 'number' symbols when found as a pair in the input stream. The action of the rule refers to the value of the first number symbol as $1 and and the second number as $3. (Note that $2 refers to the literal token ',' which does not have any value associated with it). Since 'number' is a non-terminal, its attribute cannot be set by yylex(). Recall that every non-terminal symbol in the CFG must have a corresponding production with the non-terminal as the head. The attribute value of a non-terminal is set by the action of the rule which contains the corresponding production. In the example, the value of the non-terminal 'number' is set by the rule:</p> <pre><code>number: DIGIT   { $$=$1; }\n</code></pre> <p>The action of the rule sets the value of 'number' (reffered to using $$) to the value of DIGIT (referred to using $1).</p> <p>Sample I/O:</p> <pre><code>I: 2,5\nO: pair(2,5)\n\nI: 3,5,7\nO: syntax error\n</code></pre>"},{"location":"attribute/#attribute-stack","title":"Attribute Stack","text":"<p>YACC maintains a parse stack to achieve shift-reduce parsing. The parse stack contains grammar symbols (both terminal and non-terminal symbols) representing the current configuration of the parser. Similar to the parse stack, YACC also maintains an attribute stack to maintain the values of the grammar symbols in the parse stack. The attribute stack is synchronous with the parse stack. Synchronous because the i'th value on the attribute stack will be the attribute of the i'th symbol on the parse stack.</p> <p>Recall that when a token has been identified by LEX in the input stream, it stores the token's value in yylval. When a token is shifted to the parse stack, the value of yylval is pushed on to the attribute stack. Similarly, during a reduction when a non-terminal replaces a production handle on top of the stack, the attributes of the grammar symbols of the handle are popped from the stack and the attribute value of the non-terminal (head of the production) is pushed on to the attribute stack. The following example is a complete YACC program that evaluates an expression.</p> <pre><code>%{\n#include &lt;stdio.h\\&gt;\nint result;\n%}\n\n%token DIGIT\n\n%left '+'\n%left '\\*'\n\n%%\n\nstart : expr '\\\\n'  {result = $1; exit(1);}\n    ;\n\nexpr:  expr '+' expr  {$$ = $1 + $2;}\n    | expr '\\*' expr  {$$ = $1 \\* $3;}\n    | '(' expr ')'   {$$ = $2;}\n    | DIGIT   {$$ = $1;}\n    ;\n\n%%\n\nyyerror()\n{\n    printf(\"Error\");\n}\n\nmain()\n{\n    yyparse();\n    printf(\"Expression value = %d\",result);\n    return 1;\n}\n</code></pre> <p>Sample I/O:</p> <pre><code>I: 2+3\\*(4+5)\nO: 29\n</code></pre> <p>Consider the two productions from the example.</p> <pre><code>expr:  expr '+' expr  {$$ = $1 + $2;}\nexpr:  DIGIT   {$$ = $1;}\n</code></pre> <p>When the input 2+3*(4+5) is fed to the parser, yylex() reads the first character and finds a matching token DIGIT. yylex() returns DIGIT and asigns the value 2 to yylval. When yylex() has returned, yyparse() pushes DIGIT to the parse stack and the value of yylval to the attribute stack. $1, $2, $3 etc., refers to the attribute values on top of the stack before a reduction takes place. $$ refers to the attribute value of the non-terminal which is the head of the production which contains the handle. When the non-terminal is pushed on to the parse stack, the value of $$ is pushed on to the attribute stack. $$ refers to the symbol on top of the stack after a reduction has taken place. The following table shows the configuration of the parse stack and the attribute stack at every step of the parsing process. Assume that whenever yylex() returns a token with no attribute, yyparse() pushes a '.' to the attribute stack.</p> PARSE STACK ATTRIBUTE STACK I/P BUFFER PARSER-ACTION EXECUTED 2 + 3 *(4 + 5) $ _ DIGIT 2 + 3* ( 4 + 5 ) $ SHIFT expr 2 + 3 *( 4 + 5 ) $ REDUCE expr + 2 . 3* ( 4 + 5 ) $ SHIFT expr + DIGIT 2 . 3 *( 4 + 5 ) $ SHIFT expr + expr 2 . 3 * ( 4 + 5) $ REDUCE expr + expr * 2 . 3 . ( 4 + 5 ) $ SHIFT expr + expr* ( 2 . 3 . . 4 + 5 ) $ SHIFT expr + expr *( DIGIT 2 . 3 . . 4 + 5 ) $ SHIFT expr + expr* ( expr 2 . 3 . . 4  + 5 ) $ REDUCE expr + expr *( expr + 2 . 3 . . 4 . 5 ) $ SHIFT expr + expr* ( expr + DIGIT 2 . 3 . . 4 . 5 ) $ SHIFT expr + expr *( expr + expr  2 . 3 . . 4 . 5 ) $ REDUCE expr + expr* ( expr 2 . 3 . . 9 ) $ REDUCE expr + expr *( expr ) 2 . 3 . . 9 . $ SHIFT expr + expr* expr 2 . 3 . 9 $ REDUCE expr + expr  2 . 27 $ REDUCE expr 29 $ REDUCE $expr 29 $ ACCEPT"},{"location":"attribute/#yystype","title":"YYSTYPE","text":"<p>Attributes of terminals can be passed from yylex() to yyparse() and attributes of a non-terminal can be synthesized. An attribute of a non-terminal grammar symbol is said to synthesized if it has been calculated from the attribute values of it's children in the parse tree. A synthesized attribute is an attribute of a non-terminal than has been calculated using the attribute values of the symbols in the handle that it replaces. An example of synthesized attribute:</p> <pre><code>Z: X   { printf(\"Result=%d\",$1);}\nX: A '+' B  { $$ = $1 + $3; }\n</code></pre> <p>The attribute value of X is a synthesized attribute as it has been calculated using the attribute values of the symbols in the handle that it replaces. The attribute stack consists of attributes of token and synthesized attributes. The attribute stack is of the type YYSTYPE i.e, all the stack variables are of the type YYSTYPE. For example, in the above production, $$,$1 and $3 are all of the type YYSTYPE. YYSTYPE is a YACC-defined data type. yylval is declared by YACC to be of the type YYSTYPE. By default YACC defines YYSTYPE to be the type int. It means that, by default only integer valued attributes can be passed from yylex() to yyparse() and only integer attributes can be synthesized. If we were to attempt to assign any other value to yylval or any of the attribute stack variables, a type error would be flagged on compiling y.tab.c using gcc.</p> <p>This default type definition of YYSTYPE can overriden with any built-in or userdefined data type. For example if we wanted to print the prefix form of an expression:</p> <pre><code>expr: expr OP expr { printf(\"%c %c %c\",$2,$1,$3);}\n</code></pre> <p>The type of YYSTYPE can be overriden manually as shown below. This line has to be added to the declarations section of the YACC program. This may be used (not recommended) to change the type of all the attributes from int to some other type.</p> <pre><code>typedef char YYSTYPE;\n</code></pre> <p>But inorder to have multiple custom attribute values, YACC offers a useful feature called %union to customize the type of YYSTYPE. %union is useful when we require to have different tokens of different types. For example if we wanted some tokens to be of the type int and some tokens to be of the type char. The following code segment can be added to declarations section of the YACC program to achieve that.</p> <pre><code>/* YACC Auxiliary declarations*/\n\n/* YACC Declarations*/\n%union\n{\n char character;\n int integer;\n};\n\n%token &lt;character&gt; OP\n%token &lt;integer&gt; NUMBER\n\n%%\nexpr: expr OP expr { printf(\"%c %d %d\",$2,$1,$3);}\n  | DIGIT {$$=$1;}\n  ;\n%%\n/* Auxiliary functions */\n</code></pre> <p>Note that the type of the attribute of each token must be mentioned when the token is being declared using the following syntax.</p> <pre><code>%token &lt;type&gt; tokenname\n</code></pre> <p><code>type</code> must be declared under %union prior to use in the declaration of a token. If the type of a token is not explicitly mentioned, no attribute value can be assigned to the token i.e, it is assumed to be of type void.</p>"},{"location":"attribute/#references","title":"References","text":"<p>For further details on the topics covered in this document, the reader may refer to the following :</p> <ul> <li>http://epaperpress.com/lexandyacc/pry1.html</li> <li>http://www.sci.brooklyn.cuny.edu/~zhou/teaching/cis707/attr/tsld003.htm</li> <li>https://cs.nyu.edu/~gottlieb/courses/2000s/2008-09-fall/compilers/lectures/lecture-08.html</li> <li>http://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools</li> <li>Compilers : Principles,Techniques and Tools by Alfred V.Aho, Monica S. Lam, Ravi Sethi and Jeffrey D.Ulman .</li> <li>Modern Compiler Implementation in C by Andrew W.Appel</li> <li>Flex &amp; Bison by John Levine</li> <li>http://dinosaur.compilertools.net/</li> </ul>"},{"location":"codegen/","title":"Code Generation","text":""},{"location":"codegen/#introduction","title":"Introduction","text":"<p>In Code Generation step, the ExpL compiler converts the intermediate representation (the abstract syntax tree) of the ExpL program to a machine code that can be readily executed by the XSM machine.</p> <pre><code>int codeGen(struct ASTNode *t, file *targetfile)\n</code></pre> <p>The codeGen() function takes as input a pointer to the root of an abstract syntax tree and a pointer to a file to which the target code has to be written. The codeGen() function generates assembly code corresponding to the program represented by the AST. The codeGen() function essentially invokes itself recursively to generate assembly code for the subtrees. The result of evaluation is a value which is stored in a register. The codeGen() function returns the register number that would contain the evaluated value when the assembly code is executed. (when no value results in evaluating a tree node, there is no register allocated to store the value and -1 is returned by codeGen() indicating this fact).</p>"},{"location":"codegen/#implementation","title":"Implementation","text":"<p><code>codeGen()</code> function recursively generates code for each nodetype. Firstly, the code is generated for the first subtree, 'ptr1' (if not NULL) and it's value is stored in say register Ri by calling the codeGen() function with pointer to AST 'ptr1'. Similarly, code is generated for second and third subtrees 'ptr2' and 'ptr3' and results are in registers say Rj and Rk. Finally, using the registers Ri, Rj and Rk, code is generated for the current node.</p> <p>Lets consider the nodetype PLUS. PLUS has two operands which are represented by subtrees 'ptr1' and 'ptr2'. Code for 'ptr1' and 'ptr2' is generated by the following instructions.</p> <pre><code>i = codeGen(t-&gt;ptr1);\nj = codeGen(t-&gt;ptr2);\n</code></pre> <p>Finally, the value to the current node is evaluated and saved to register Ri and Rj is freed.</p> <pre><code>fprintf(); //Add this during implementation\nfree_register(j);\n</code></pre> <p>Following is how code is generated for the nodetype 'while'. Note that, the labels generated here are psuedo addresses. We will deal about replacing the labels with actual address in the label translation documentation.</p> <p>We have two subtrees for 'while' nodetype. 'ptr1' representing the conditional expression in while statement and 'ptr2' representing the body of while statement.</p> <ol> <li>Get two labels using get_label() function and write down the first label, say 'LL1' to the intermediate code, so that we can identify where exactly the code for while starts.</li> <li>Then, the code for conditional expresssion represented by 'ptr1' is generated and value stored into a register, say Ri.</li> <li>Next, we would check the value in Ri, if its zero, i.e, conditional expression has evaluated to false, we would jump to the end of the while code. So, the next instruction is to check if Ri is zero and jump on to second label, say LL2 where the code to the body of while statement ends.</li> <li>If the value in register Ri is not zero, i.e, the conditional expression evaluted to true, the we would execute the body of while. Therefore, after the above steps code for 'ptr2' is generated and at the end of it, the jump statement to the first label, LL1 is given, so that, the conditional expression can be evalauted again and the decision whether to execute the body of while is made.</li> <li>Finally the second label is given,so that we can mark the end of while statement.</li> </ol> <p>For the code generation for functions, the activities are given here.</p> <p>For making library calls, follow the steps given in the invoking a library module section in Application Binary Interface documentation.</p>"},{"location":"codegen/#illustration","title":"Illustration","text":"<p>Consider the ExpL program given below.</p> <pre><code>decl\n    int a;\nenddecl\nint main(){\n    decl\n        int b;\n    enddecl\n    begin\n        a = 1;\n        b = 2;\n        while(a &lt; 10) do\n            b = b + 1;\n            a = a + 2;\n        endwhile;\n        return 1;\n    end\n}\n</code></pre> <p>The XSM instructions for the above while code (lines 11-12) will be as follows:</p> <pre><code>L0:\nMOV R0,[4096]\nMOV R1,10\nLT R0,R1\nJZ R0,L1\nMOV R1,BP\nMOV R0,1\nADD R1,R0\nMOV R0,[R1]\nMOV R1,1\nADD R0,R1\nMOV R2,BP\nMOV R1,1\nADD R2,R1\nMOV [R2],R0\nMOV R0,[4096]\nMOV R1,2\nADD R0,R1\nMOV [4096],R0\nJMP L0\nL1:\n</code></pre>"},{"location":"data-structures/","title":"Compile Time Data Structures","text":""},{"location":"data-structures/#introduction","title":"Introduction","text":"<p>The compilation of an ExpL program involves two phases. In the first phase (called the analysis phase), the source ExpL program is analyzed (lexical, syntax and semantic analysis are completed in this phase) and if the program is free of syntax and semantic errors, an intermediate representation of the source program called the abstract syntax tree is generated.</p> <p>This is followed by a second phase, the second phase (called the synthesis phase) recursively traverses the abstract syntax tree and generates target code.</p> <p>Note</p> <p>In the case of an interpreter, the second phase (called the execution phase) involves direct execution of the program by recursive evaluation of the abstract syntax tree.</p> <p>Note</p> <p>The abstract syntax tree representation is only one among several intermediate representations used in practical compilers. \u201cLower level\u201d intermediete representations like three address code are often more useful for applying code optimization algorithms. In our present experiment, we do not perform any code optimizations and hence the code generation phase will directly work with the abstract syntax tree.</p> <p>There are four basic data structures that are maintained during the analysis phase. These are the following:</p> <ol> <li>The Type table is used to store information regarding the primitive and user-defined types in the program.</li> <li>The global symbol table is used to store information about the global variables and functions in the program.</li> <li>For each function, a separate local symbol table is maintained to store the information about local variables and arguments of the function.</li> <li>Finally, the abstract syntax tree is constructed as the outcome of the analysis phase.</li> </ol> <p>An abstract syntax tree is a tree representation of a program. It is a generalization of the tree representation for expressions (called the expression tree). For example, the arithmetic expression (3+5)*(5+9) is typically represented as an expression tree as below:</p> <p></p> <p>We can generalize this representation to come up with a tree representation for the whole sequence of statements of a ExpL function in a program. Each funcion in an ExpL program will be represented by an abstract syntax tree. Thus, the whole program will be a collection of abstract syntax trees, one for each function. As a very simple example, consider the three program statements:  </p> <pre><code>a = b+c;\nd = a-b;\nc = a+d;\n</code></pre> <p>A syntax tree representation for the three statements above would look as below:</p> <p></p> <p>Note</p> <p>The memory addresses assigned to each variable in the figure above (100-103) has been chosen arbitrary. The Application Binary Interface specifies the valid range of addresses that a compiler can allocate for variables. For instance, the ExpOS ABI requires that addresses must be in the range 4096 to 5119.</p> <p>Whenever a variable occurs in the syntax tree representation, it is convenient to maintain a pointer to the symbol table entry of the variable as shown in the figure. Note that since there are multiple symbol tables (global and local), the reference maintained for each variable must be to the right symbol table containing the variable entry.</p> <p>In the following, the definitions node structures for each of the above data structures is discussed. The organization of data in these data structures is also discussed with illustrative examples.</p>"},{"location":"data-structures/#analysis-phase-data-structures","title":"Analysis Phase Data Structures","text":""},{"location":"data-structures/#type-table","title":"TYPE TABLE","text":"<p>The Type Table stores all the necessary information regarding the various user defined types in the source program. The compiler creates ...Read more</p>"},{"location":"data-structures/#global-symbol-table","title":"GLOBAL SYMBOL TABLE","text":"<p>Symbol tables are used to store information pertaining to the variables and functions in a program. The global symbol table stores information pertaining to ...Read more</p>"},{"location":"data-structures/#local-symbol-table","title":"LOCAL SYMBOL TABLE","text":"<p>In addition to the global symbol table, the ExpL compiler maintains a separate local symbol table for each function for storing information regarding ...Read more</p>"},{"location":"data-structures/#abstract-syntax-tree","title":"ABSTRACT SYNTAX TREE","text":"<p>The machine independent front-end phase of a compiler constructs an intermediate representation of the source program called the Abstract Syntax Tree (AST). An interpreter will evaluate ...Read more</p>"},{"location":"docker-setup/","title":"Docker based setup","text":""},{"location":"docker-setup/#install-and-setup-docker-on-host-machine","title":"Install and setup Docker on host machine","text":"<p>Follow the instructions available here to install docker on your machine.</p> <p>You could also go through the  Docker quick start quide  to know more about Docker .</p> <p>Warning</p> <p>The following has not been tested on Windows.</p> <p>If you encounter any issues/ has suggestions raise an issue here</p>"},{"location":"docker-setup/#setting-up","title":"Setting up","text":"<p>We'll assume the following directory structure</p> <pre><code>.\n\u251c\u2500\u2500 Dockerfile\n\u2514\u2500\u2500 workdir/ # &lt;- user files will be stored here and mapped to container\n</code></pre> <p>We'll store the user written code in <code>workdir</code> and map the same into the container.</p> <p>We can create the structure using the below commands</p> Windows (Powershell) <pre><code>cd &lt;your directory&gt;\nNew-Item Dockerfile\nNew-Item -path workdir -ItemType directory\n</code></pre> Unix / Linux <pre><code>cd &lt;your directory&gt;\ntouch Dockerfile\nmkdir workdir\n</code></pre> <p>The contents of <code>Dockerfile</code> are given below</p> <pre><code>FROM ubuntu:20.04\n\nRUN apt-get update \\\n    &amp;&amp; apt-get install -y bison flex libreadline-dev libc6-dev libfl-dev wget vim make gcc curl git build-essential\n\nRUN useradd -m expl\nUSER expl\n\nRUN cd /home/expl \\\n    &amp;&amp; git clone https://github.com/silcnitc/xsm_expl.git  \\\n    &amp;&amp; cd ./xsm_expl \\\n    &amp;&amp; make\n\nWORKDIR /home/expl/xsm_expl\n</code></pre> <p>The given <code>Dockerfile</code> will setup an expl environment as specified in Installation Page</p>"},{"location":"docker-setup/#building-the-container-image","title":"Building the container image","text":"<p>We'll now build the container image using the <code>Dockerfile</code></p> <pre><code>docker build -t expl:ubuntu20.04 .\n</code></pre>"},{"location":"docker-setup/#start-the-container-instance","title":"Start the container instance","text":"<p>We'll start an instance of Container and map the local folder <code>workdir</code> into <code>/home/expl/workdir</code> directory of container.</p> Windows (PowerShell) <pre><code>docker run -v ${PWD}/workdir:/home/expl/xsm_expl/workdir -d --name expl -i expl:ubuntu20.04\n</code></pre> Unix / Linux <pre><code>docker run -v $PWD/workdir:/home/expl/xsm_expl/workdir -d --name expl -i expl:ubuntu20.04 \n</code></pre> <p>We now have a container instance running in background with the name <code>expl</code> and required volume mounts</p>"},{"location":"docker-setup/#connecting-to-the-container","title":"Connecting to the container","text":"<p>We can connect to the container instance using the following commands</p> <pre><code>docker start expl # if the container instance is not already running\n\ndocker exec -it expl /bin/bash # to get a bash shell inside the container\n</code></pre> <p>After connecting to the container you can use <code>xfs-interface</code>, and <code>xsm</code> binaries as mentioned in Installation Page</p>"},{"location":"documentation/","title":"Documentation","text":"<ul> <li>Using <code>lex</code></li> <li>Using <code>YACC</code></li> <li>Using <code>YACC</code> with <code>lex</code></li> <li>Using <code>GDB</code></li> <li>ExPL Specification</li> <li>ExpL Grammar Outline</li> <li>OExpL Specification</li> <li>OExpL Grammar Outline</li> <li>Compile Time Data Structures for ExpL</li> <li>Compile Time Data Structures for OExpL</li> <li>Run Time Data Structures for ExpL</li> <li>Run Time Data Structures for OExpL</li> <li>Code Generation</li> <li>Label Translation (./Linking)</li> <li>Application Binary Interface</li> <li>Library Implementation</li> <li>XSM Simulator Installation.</li> <li>XSM Simulator Usage Instructions.</li> <li>XSM Execution Environment Tutorial.</li> <li>ExpL Test Programs.</li> <li>OExpL Test Programs.</li> </ul>"},{"location":"ex1/","title":"YACC Examples","text":""},{"location":"ex1/#yacc-program","title":"YACC Program","text":"<p>in2post.y</p> <pre><code>%{\n    #include &lt;stdio.h&gt;\n%}\n%token DIGIT PLUS STAR\n%%\nstart : expr '\\\\n'           {printf(\"\\\\nComplete\");exit(1);}\n    ;\nexpr:  expr PLUS expr        {printf(\"+ \");}\n    | expr STAR expr     {printf(\"\\* \");}\n    | '(' expr ')'\n    | DIGIT             {printf(\"%d \",$1);}\n    ;\n%%\n\n\nyyerror()\n{\n    printf(\"Error\");\n}\nmain()\n{\n    yyparse();\n    return 1;\n}\n</code></pre>"},{"location":"ex1/#lex-program","title":"LEX Program","text":"<p>in2post.l</p> <pre><code>%{\n    #include &lt;stdio.h&gt;\n    #include \"y.tab.h\"\n%}\n%%\n[0-9]+ return DIGIT;\n'+' return PLUS;\n'*' return STAR;\n'(' return \\*yytext;\n')' return \\*yytext;\n%%\nyywrap()\n{\n    return 1;\n}\n</code></pre>"},{"location":"expl/","title":"ExpL Specification","text":""},{"location":"expl/#introduction","title":"Introduction","text":"<p>ExpL (Experimental language) is the language for which we will build a compiler in this course. This document provides an informal specification for the language.</p>"},{"location":"expl/#supported-data-types","title":"Supported Data Types","text":""},{"location":"expl/#primitive-data-types","title":"Primitive data types","text":"<p>Integer : An integer type variable is declared using the keyword int. Example :</p> <pre><code>                        int a, b, c;  /\\* Declares variables a, b, c of type integer \\*/\n</code></pre> <p>String : A string is a sequence of alphanumeric characters. A string type variable is declared using the keyword str. Example :</p> <pre><code>                          str mystring;   /\\*  Declares a variable mystring of type string.  \\*/\n</code></pre> <p>Boolean : ExpL does not permit boolean variables. But logical expressions like (a &lt; b) or (a==b) and (a&lt; 5) are supported and are considered to be of type boolean.</p>"},{"location":"expl/#composite-data-types","title":"Composite data types","text":"<p>Arrays</p> <p>Arrays can be of integer or string types only. Only single-dimensional arrays are allowed. Arrays are statically allocated.</p> <p>Example :</p> <pre><code>                          int a\\[10\\];            /\\* array a indexed a\\[0\\],a\\[1\\],..a\\[9\\], can store 10 integers\\*/\n                          str stringlist\\[10\\];   /\\* stringlist is an array of 10 strings \\*/\n</code></pre> <p>User-defined types</p> <p>ExpL allows user defined data types. The (member) fields of a user defined type may be of type a) integer, b) string, c) a previously defined user defined type or d) the type that is currently being defined.</p> <p>Note : ExpL specifies that the store for variables of user defined types shall be dynamically allocated. Hence the programmer has to call the library function alloc() to allocate memory for variables of user defined types. User defined types take default value NULL unless allocated or assigned otherwise. Store allocated for a variable of a user defined type is de-allocated using the free() library function.</p> <p>Example : A user defined type, mytype is defined as:</p> <pre><code>                          mytype\n                          {\n                            \u00a0int a;\n                            \u00a0str b;\n                          }\n</code></pre> <p>a variable of type mytype is declared as:</p> <pre><code>                          mytype var1, var2;\n</code></pre> <p>Storage for the variable is allocated as:</p> <pre><code>                          var = alloc();   /\\* Note:  Access without allocation can lead to run time errors \\*/\n</code></pre> <p>Its fields may be accessed as:</p> <pre><code>                          var.a = 10;     /\\*  the \u201c.\u201d symbol is used to access member fields \\*/\n</code></pre> <p>The memory allocated may be freed as:</p> <pre><code>                          retval = free(var);\n</code></pre> <p>Note : The ExpL compiler may internally represent var like a pointer variable. The library function alloc may be designed so as to allocate memory and return a pointer to the allocated memory. The returned pointer is stored in var. (Library functions are explained in detail later on.)</p>"},{"location":"expl/#general-program-structure","title":"General Program Structure","text":"<p>An ExpL program consists of the following sections:</p> <ul> <li>Type Definitions - Optional (for user defined types)</li> <li>Global Declarations - for global variables, arrays and functions</li> <li>Function Definitions and the main Function Definition .</li> </ul> <p>The following subsections explain each program section.</p>"},{"location":"expl/#type-definitions","title":"Type Definitions","text":"<p>All user-defined types in a program must be defined in the type definition section. The Type Definition section starts with the keyword type and ends with the keyword endtype.</p> <p>Example</p>"},{"location":"expl/#global-declarations","title":"Global Declarations","text":"<p>The global declaration part of an ExpL program begins with the keyword decl and ends with the keyword enddecl. All global variables, arrays and functions in a program must be declared in this section.</p> <p>Global variables may be of type integer, string, a user defined type, an integer array, a string array. The variables declared globally must be allocated statically by the compiler. Global variables are visible throughout the program unless suppressed by a redeclaration within the scope of some function. Array type variables can be declared only globally. Only single dimensional arrays are allowed. Variables cannot be assigned values during the declaration phase.</p> <p>For every function except the special main function defined in an ExpL program, there must be a declaration. A function declaration should specify the name of the function, the name and type of each of its arguments and the return type of the function. A function can have integer/string/user defined type arguments. The return type of a function also can be integer/string/user-defined type. ExpL enforces call-by-value semantics for integer and string parameters and call-by-reference for user-defined types. (A variable of a user defined type typically stores a reference to its store.) Arrays cannot be passed as arguments. If a global variable name appears as an argument of a function, then within the scope of the function, the new declaration will be valid and the global declaration is suppressed. Different functions may have arguments of the same name. However, the same name cannot be given to two or more arguments in a function. The general form of declarations is as follows:</p> <pre><code>                        type VarName1, VarName2 ;    /\\* variable declarations \\*/\n                        rettype FunctionName (ParameterList);    /\\*  A function declaration \\*/\n                        type VarName\\[ArraySize\\];    /\\* An array declaration \\*/\n</code></pre> <p>Note : Declarations for variables/functions of the same type can be combined as shown in the following example.</p> <p>Example :</p> <pre><code>                        decl   /\\* Please note the use of \",\" and \";\" \\*/\n                        \u00a0\u00a0int x,y,a\\[10\\],b\\[20\\];       /\\* x,y are integers, a,b are integer arrays \\*/\n                        \u00a0\u00a0str t, q\\[10\\], f3(str x);   /\\*variable, array and a functions declared together\\*/\n                        \u00a0\u00a0mytype m, fun(mytype t);   /\\* myptype must be  a user defined type \\*/\n                        \u00a0\u00a0/\\*  The argument and the return value of fun are references to mytype \\*/\n                        enddecl\n</code></pre> <p>Declaring functions at the beginning avoids the forward reference problem and facilitates single pass compilation. If a variable/function is declared multiple times, a compilation error should result.</p>"},{"location":"expl/#function-definitions-and-the-main-function","title":"Function Definitions and the Main Function","text":"<p>All globally declared variables are visible inside a function, unless suppressed by a re-declaration within the function. Variables declared inside a function are invisible outside. The general form of a function definition is given below:</p> <pre><code>                        &lt; Type &gt; FunctionName(ArgumentList)\n                        {\n                        \u00a0\u00a0Local Declarations\n                        \u00a0\u00a0Function Body\n                        }\n</code></pre> <p>The names and types of the arguments and return value of each function definition should match exactly (name equivalence) with the corresponding declaration. Every declared function must have exactly one definition. The compiler should report error otherwise.</p> <p>The syntax of local declarations and definitions are similar to those of global declarations except that arrays and functions cannot be declared inside a function. Local variables are visible only within the scope of the function where they are declared. The scope of a parameter is limited to the function. Static scope rules apply. A function can have a user defined type as its return type. Similarly, parameters to a function can be of user defined types.</p> <p>The main() function, by specification, must be a zero argument function of return type integer. It must be defined immediately after declaration section, before all other functions are defined. Program execution begins from the body of the main function. The main function must not be declared. The definition part of main should be given in the same format as any other function.</p> <p>The Body of a function is a collection of statements embedded within the keywords begin and end.</p> <p>Example : The following is an example for a simple function definition.</p> <pre><code>                        int fun(int a,int b)\n                        {\n                        \u00a0\u00a0decl\n                        \u00a0\u00a0\u00a0\u00a0int c,d;\n                        \u00a0\u00a0enddecl\n                        \u00a0\u00a0begin\n                        \u00a0\u00a0\u00a0\u00a0c = a + b;\n                        \u00a0\u00a0\u00a0\u00a0d = a - b;\n                        \u00a0\u00a0\u00a0\u00a0write(c);\n                        \u00a0\u00a0\u00a0\u00a0write(d);\n                        \u00a0\u00a0\u00a0\u00a0return c;\n                        \u00a0\u00a0end\n                        }\n</code></pre> <p>Local Variables and parameters should be allocated space in the run-time stack of the function. The language supports recursion.</p> <p>Each statement should end with a \u2018;\u2019 which is called the statement terminator.</p> <p>There are seven types of statements in ExpL. They are:</p> <ol> <li>Assignment Statement</li> <li>Conditional Statement</li> <li>Iterative statement</li> <li>Return statement</li> <li>Input/Output statements</li> <li>Break statement</li> <li>Continue statement</li> </ol> <p>The next section discusses statements and expressions in ExpL.</p>"},{"location":"expl/#statements-and-expressions","title":"Statements and Expressions","text":"<p>Before taking up statements, we should look at the different kinds of constants and expressions in the language. ExpL has four kinds of expressions, a) Arithmetic expressions, b) String expressions, c) Logical expressions and d) Expressions that evaluate to user defined types.</p>"},{"location":"expl/#constants","title":"Constants","text":"<p>Any numerical value (Example: 234) is an integer constant. A quoted string (Example: \u201chello\u201d) is a string constant. ExpL allows a special constant NULL whose type is void. It is assumed that string constants contain only alphanumeric characters (and no special characters).</p>"},{"location":"expl/#arithmetic-and-string-expressions","title":"Arithmetic and String Expressions","text":"<p>Any integer(or string) constant/variable is a valid arithmetic (or string) expression, provided the scope rules are not violated. ExpL treats a function returning integer (or string) as an integer expression (or string expression) and the value of a function is its return value.</p> <p>ExpL provides five arithmetic operators, viz., +, -, *, / (Integer Division) and % (Modulo operator) through which arithmetic expressions may be combined. Expression syntax and semantics are similar to standard practice in programming languages and normal rules of precedence, associativity and paranthesization apply. ExpL is strongly typed and any type mismatch or scope violation must be reported at compile time.</p> <p>Examples : 5, a[a[5+x]]+x , (f2() + b[x] + 5), sum + listObject.data , a[listObject.data] + f2(listObject) * 8 etc. are arithmetic expressions, provided type and scope rules are not violated. Note that the function f2() must have return type int for the expression to be valid.</p>"},{"location":"expl/#logical-expressions","title":"Logical Expressions","text":"<p>Logical expressions may be formed by combining arithmetic expressions using relational operators. The relational operators supported by ExpL are &lt;, &gt;, &lt;=, &gt;=, ==, and !=. Again standard syntax and semantic conventions apply. Logical expressions may be combined using logical operators and, or and not.</p> <p>The relational operators &lt;, &gt;, &lt;=, &gt;=, ==, and != can be used between two variables of type string, two string constants or a string constant and a variable of type string. Comparison will be performed for lexicographic ordering.</p> <p>Variables of user defined types can only be checked for equality/inequality using the ==/!= operator.</p> <p>Example : ((x==y)==a[3]) is not valid ExpL expression because (x==y) is a logical expression, while a[3] must be a variable of type integer/string. The \"==\" operator can be applied only between expressions of the same type.</p> <p>(\u201chello\u201d==a and \"hello\" &lt; a) are a valid logical expressions provided, a is a variable of string type. (p==q) is a valid logical expression provided p and q are variables of the same type.</p> <p>SetOne.name == \"a\", SetOne.total &gt;= SetTwo.total are valid only if SetOne is a user defined type with a field 'name' of type string and another field 'total' of type integer.</p>"},{"location":"expl/#expressions-of-user-defined-types","title":"Expressions of user defined types","text":"<p>Any variable of a user defined type or invocation of a function whose return type is a user defined type is considered as an expression of the corresponding user defined type.</p>"},{"location":"expl/#assignment-statement","title":"Assignment Statement","text":"<p>The general syntax of the assignment statement is :</p> <pre><code>                          Lvalue = Rvalue;\n</code></pre> <p>The possible Lvalues are variables or indexed array variables. If the Lvalue has type integer (or string) , the Rvalue must be an arithmetic (or string) expression. If the Lvalue is a user defined variable, then the Rvalue must either be an expression of the same type, or the special constant NULL, or an invocation of the function alloc() (to be explained later).</p> <p>Example : q[3]= \u201chello\u201d ; t= \u201cworld\u201d ; are both valid assignments to string variables provided q is declared as an array of type string and t is declared as a variable of type string. x=y; is valid if x and y are of the same type and scope rules are not violated.</p> <p>In an assignment x=y where x and y are of a primitive type (integer or string), the value inside the location indicated by y is copied into the location indicated by x. On the other hand, if x and y are variables of a user defined type, the assignment only makes both x and y refer to the same memory object. This is because a variable of a user defined type stores a reference to its store allocated using alloc().</p>"},{"location":"expl/#conditional-statement","title":"Conditional Statement","text":"<p>The ExpL conditional statement has the following syntax:</p> <pre><code>                        if &lt; Logical Expression &gt; then\n                        \u00a0Statements\n                        else\n                        \u00a0Statements\n                        endif;\n</code></pre> <p>The else part is optional. The statements inside an if-block may be conditional, iterative, assignment, input/output, break or continue statements, but not the return statement.</p>"},{"location":"expl/#iterative-statement","title":"Iterative Statement","text":"<p>The eXpL iterative statement has the following syntax:</p> <pre><code>                        while &lt; Logical Expression &gt; do\n                         \u00a0 Statements\n                        endwhile;\n</code></pre> <p>Standard conventions apply in this case too. The statements inside a while-block may be conditional, iterative, assignment, input/output, break or continue statements, but not the return statement.</p>"},{"location":"expl/#return-statement","title":"Return Statement","text":"<p>The body of each function (including main) should have exactly one return statement and it should be the last statement in the body. The syntax is:</p> <pre><code>                      return &lt; Expression\\* &gt; ; /\\* The type of the expression should match with the return type of the function\\*/\n                      Note\\* : As an exception to the rule above, the expression returned by a function whose return type is a user defined type can be the constant NULL.\n</code></pre> <p>If the return type of the function does not match the type of the expression/variable returned, a compilation error should occur. The return type of a function can be of type int , str or user-defined type. The return type of main is integer by specification</p> <p>.</p>"},{"location":"expl/#inputoutput-statements","title":"Input/Output statements","text":"<p>Using read statement, we can read a string or an integer into a variable of type string or integer respectively from the standard input. The syntax of the input statement is as follows :</p> <pre><code>                              read( &lt; variable &gt; );\n</code></pre> <p>Using the write statement, we can write the value of an integer or string type variable or the value of an arithmetic expression to the standard output. The output statement is as follows :</p> <pre><code>                              write( &lt; expr &gt; );\n</code></pre>"},{"location":"expl/#break-and-continue-statements","title":"Break and Continue Statements","text":"<p>A break; statement inside an iterative block tranfers control to the end of the block. A continue; inside a conditional/iterative block transfers control to the beginning of the block. These statements do nothing if not inside any conditional/iterative statement.</p> <p>The next section briefly discusses the library functions for dynamic memory allocation.</p>"},{"location":"expl/#breakpoint-statement","title":"Breakpoint Statement","text":"<p>This statement results in the ExpL compiler setting a break point in the program. This feature is useful for debugging.</p> <pre><code>                                breakpoint;\n</code></pre>"},{"location":"expl/#dynamic-memory-allocation","title":"Dynamic memory allocation","text":"<p>The library functions initialize(), alloc() and free() are used as follows:</p> <pre><code>                      intialize(); /\\* To Intialise the heap. \\*/\n                      t = alloc(); /\\* Allocates contiguous locations in the heap, t must be a user defined variable \\*/\n                      retval = free(t);  /\\* Free the allocated block , t must be a user defined variable \\*/\n</code></pre> <p>Intialize() must be invoked before any allocation is made and it resets the heap to default values. A call to alloc() allocates contiguous memory locations in the heap memory (memory reserved for dynamic memory allocation) and returns the address of the starting location. The Expl compiler sets the variable (of a user defined type) on the left of the assignment to store this memory address. A call to free() deallocates contiguous memory locations in the heap memory that is referenced by the user defined type variable. The function free() returns NULL on successful deallocation. Otherwise, the value of t is unchanged by a call to free(). All unallocated user defined variables are set to the predefined constant NULL.</p>"},{"location":"expl/#parameter-passing","title":"Parameter passing","text":"<p>Functions can take any number of arguments and must return a single value. The arguments and return values may be of integer, string or user defined types.</p> <p>Arguments to functions are passed by value. This means that changes to made to the values of an argument inside a function will not be visible outside the function.</p> <p>However, if a variable is of a user defined type, after allocation using the Alloc() function, the variable stores the memory address of the actual data in heap memory where the data associated with the variable is stored. ExpL specification allows the data to be modified using the variable. If the data stored variable is changed with in a function, the change will be visible globally. This is because heap memory is globally visible.</p> <p>The scope rules are illustrated by the following example.</p>"},{"location":"expl/#appendix","title":"Appendix","text":""},{"location":"expl/#keywords","title":"Keywords","text":"<p>The following are the reserved keywords in ExpL and it cannot be used as identifiers.</p> <p>read</p> <p>write</p> <p>if</p> <p>then</p> <p>else</p> <p>begin</p> <p>initialize</p> <p>endif</p> <p>do</p> <p>endwhile</p> <p>break</p> <p>while</p> <p>end</p> <p>int</p> <p>str</p> <p>return</p> <p>decl</p> <p>enddecl</p> <p>alloc</p> <p>type</p> <p>endtype</p> <p>NULL</p> <p>continue</p> <p>main</p> <p>free</p>"},{"location":"expl/#operators-and-delimiters","title":"Operators and Delimiters","text":"<p>The following are the operators and delimiters in ExpL</p> <p>&gt;</p> <p>&lt;</p> <p>&gt;=</p> <p>&lt;=</p> <p>!=</p> <p>\\==</p> <p>(</p> <p>)</p> <p>{</p> <p>}</p> <p>[</p> <p>]</p> <p>/</p> <p>;</p> <p>*</p> <p>\\=</p> <p>+</p> <p>-</p> <p>%</p> <p>AND</p> <p>NOT</p> <p>OR</p> <p>.</p>"},{"location":"expl/#identifiers","title":"Identifiers","text":"<p>Identifiers are names of variables and user-defined functions. Identifiers should start with an letter, and may contain both letters and digits. Special characters are not allowed in identifiers.</p> <p>letter -&gt; [a-z]|[A-Z]</p> <p>digit -&gt; [0-9]</p> <p>identifier -&gt; (letter)(letter | digit)*</p>"},{"location":"explusagespec/","title":"Expl Usage specification for Compiler Lab","text":"<pre><code>expl filename.expl =&gt; filename.xsm\n</code></pre> <p>About the usage of above command</p> <pre><code>expl filename.expl =&gt; filename.xsm\n</code></pre>"},{"location":"gdb-files/","title":"GDB Input Files","text":""},{"location":"gdb-files/#lexl-file","title":"lex.l file","text":"<pre><code>%{\n  #include  \"y.tab.h\"\n  #include \"tree.h\"\n  void yyerror(char *);\n\n%}\n\n\nalpha   [a-zA-Z]\n\n%%\n\n{alpha}+  {yylval.p = createTree(yytext, NULL, NULL); return ID;}\n\"+\"       {return PLUS;}\n\"-\"       {return MINUS;}\n\"*\"       {return MUL;}\n\"/\"       {return DIV;}\n[()]      {return *yytext;}\n[ \\t\\n]           {}\n.               {yyerror(\"invalid character\\n\");}\n\n\n%%\n\nint yywrap(void) {\n  return 1;\n}\n</code></pre>"},{"location":"gdb-files/#parsery-file","title":"parser.y file","text":"<pre><code>%{\n  //#define YYSTYPE tnode*\n  #include &lt;stdio.h&gt;\n  #include &lt;stdlib.h&gt;\n  #include \"tree.h\"\n  #include \"tree.c\"\n  extern struct tnode* idptr;\n  int yylex(void);\n  extern FILE *yyin;\n  extern char* yytext;\n%}\n\n%union{\n  struct tnode* p;\n}\n\n%token &lt;p&gt; ID\n\n%type &lt;p&gt; expr\n\n%left PLUS MINUS\n%left MUL DIV\n%%\n\n\nProgram :  expr    {infixtoprefix($1);printf(\"\\n\");free($1);}\n        ;\n\nexpr :  expr PLUS expr  {$$ = createTree(\"+\",$1, $3);}\n     | expr MINUS expr  {$$ = createTree(\"-\",$1, $3);}\n     | expr MUL expr  {$$ = createTree(\"*\",$1, $3);}\n     | expr DIV expr  {$$ = createTree(\"/\",$1, $3);}\n     | '(' expr ')'  {$$ = $2;}\n     | ID      {$$=$1;}\n     ;\n\n%%\n\nvoid yyerror(char const *s)\n{\n    printf(\"yyerror '%s' and '%s'\",s,yytext);\n}\n\n\nint main(int argc, char*argv[]) {\n  if (argc &gt; 1) {\n      FILE *fp = fopen(argv[1],\"r\");\n      if (fp) {\n        yyin = fp;\n      }\n  }\n  yyparse();\n  return 0;\n}\n</code></pre>"},{"location":"gdb-files/#inputtxt-file","title":"input.txt file","text":"<pre><code>abc+(bcd-efg)*hij\n</code></pre>"},{"location":"gdb-files/#treeh-file","title":"tree.h file","text":"<p>This is the header file for tree.c file</p> <pre><code>// node structure\ntypedef struct tnode {\n  char *symbol;\n  struct tnode *left, *right;\n} tnode;\n\n// prints the prefix expressions\nvoid infixtoprefix(struct tnode* root);\n\n/*Create  tnode*/\nstruct tnode* createTree(char *symbol, struct tnode* left, struct tnode* right);\n</code></pre>"},{"location":"gdb-files/#treec-file","title":"tree.c file","text":"<p>This file contains the helper functions for the yacc file, like the createTree(), infixtoprefix() etc.</p> <p>The yacc file imports the tree.c file and tree.h file</p> <pre><code>#include &lt;string.h&gt;\n\nstruct tnode* createTree(char *symbol, struct tnode* left, struct tnode* right) {\n  struct tnode *k = (struct tnode*)malloc(sizeof(struct tnode));\n  k-&gt;symbol = strdup(symbol);\n  k-&gt;left = left;\n  k-&gt;right = right;\n  return k;\n\n}\n\nvoid infixtoprefix (struct tnode* root) {\n  if (root != NULL) {\n    printf(\"%s \", root-&gt;symbol);\n    infixtoprefix(root-&gt;left);\n    infixtoprefix(root-&gt;right);\n  }\n}\n</code></pre>"},{"location":"gdb/","title":"GNU Debugger (GDB)","text":""},{"location":"gdb/#introduction","title":"Introduction","text":"<p>A debugger is a program that runs other programs, allowing the user to exercise control over these programs, and to examine variables when problems arise. GDB allows you to run the program up to a certain point, then stop and print out the values of certain variables at that point, or step through the program one line at a time and print out the values of each variable after executing each line.</p> <p>Errors like segmentation faults may be easier to find with the help of gdb.</p> <p>GDB allows you to:-</p> <ul> <li>Pause and continue its execution</li> <li>Set \"break points\" or conditions where the execution pauses so you can look at its state (the value of the variables at that point).</li> <li>View and \"watch\" variable values</li> <li>Step through the program line-by-line (or instruction by instruction)</li> </ul>"},{"location":"gdb/#installation","title":"Installation","text":"<p>Before you install GDB, check whether you have already installed it.</p> <pre><code>gdb -help\n</code></pre> <p>If you have already installed GDB, then it will display all the available options within your GDB, Else if the terminal says \"command not found\", then you can proceed with the installation process.</p> Ubuntu <pre><code>sudo apt-get update\nsudo apt-get install gdb\n</code></pre> Fedora <pre><code>yum install gdb\n</code></pre> <p>Now you can confirm the installation of GDB by executing the command <code>gdb -help</code> again.</p>"},{"location":"gdb/#demo","title":"Demo","text":"<p>let us demonstrate an use case</p> <p>let us say we want to convert an infix expression to prefix expression</p> <p>This is our lex file lex.l</p> <p>This is our yacc file parser.y</p> <p>This is our input file input.txt</p> <p>This is our tree.c file tree.c, this contains the helper functions like the infixtoprefix(), createTree() etc.</p> <p>This is our tree.h file tree.h</p> <p>Input : <code>abc+(bcd-efg)*hij</code></p> <p>Expected Output : <code>+ abc * - bcd efg hij</code></p> <p>We know that we have to construct a infix expression tree by parsing the input string, and then we can do a preorder traversal on that tree to get the prefix. Here, let us see how we can use GDB to verify whether our expression tree / syntax tree is constructed properly.</p> <p>We know that by manual drawing, the expected expression tree structure is as follows:-</p> <p></p> <p>Now let us start our gnu debugger</p> <p>First we genreate our lexical anaylser from our rules in our lex file lex.l</p> <pre><code>lex lex.l\n</code></pre> <p>This generates our lex.yy.c, the lexical analyser file.</p> <p>Then we generate our parser from our grammar in our yacc file parser.y</p> <pre><code>yacc -d parser.y\n</code></pre> <p>This genererates our y.tab.c, the parser file.</p> <p>To run the program using gdb, we need to compile the lexical analyser and the parser using the <code>-g</code> flag of gcc, so that we can see the functions and variables names during the execution of the program in the gdb environment. The <code>-g</code> flag preserves the symbol table information generated during compilation of the source program in the target file enabling the debugger to display variable/function names associated with addresses in the program during debugging.</p> <pre><code>gcc -g lex.yy.c y.tab.c\n</code></pre> <p>Now, an executable file a.out would be generated.</p> <p>Now we can execute the a.out file with passing our input file input.txt to it.</p> <p>In GDB, we use <code>--args</code> flag, if we have to pass any parameters.</p> <pre><code>gdb --args a.out input.txt\n</code></pre> <p>Now our GDB is up.</p> <p>layout src - Opens a Graphical user interface, where you can view the part of the code currently executing along with the code line numbers</p> <p><code>(gdb) layout src</code></p> <p>break - You can pass a function name or line number as an argument to this command. It will set a break point corresponding to that line number or function. So that when we run the gdb, it halts at the break point, and then we can move incrementally (step by step) exploring the variables and the execution flow.</p> <p>Here we can use the break command to halt at the start of the execution of the infixtoprefix function, to examine the working of the function in detail.</p> <p><code>(gdb) break infixtoprefix</code></p> <p>run - It runs the program until it encounters one of the break points.</p> <p><code>(gdb) run</code></p> <p>Now, we would have stopped at the start of the execution of the function infixtoprefix infixtoprefix</p> <p>next or n - To move to the next line in the local scope, it is basically a step over function, i.e it do not enter any function code.</p> <p><code>(gdb) next</code></p> <p>Now, let us print the symbol stored at the root of the tree, and also view a snapshot of the gdb GUI, after executing the above instructions.</p> <p><code>(gdb) print root-&gt;symbol</code></p> <p></p> <p>print - you can use this to print the value of the variables at that point.</p> <p>In the above image we can see that the command layout src gave us the graphical user interface which allows us to see the code segment currently executing while debugging.</p> <p>The break statement helped us to reach the interested target function, so that from there we can proceed step by step exploring the contents.</p> <p>Now let us verify whether we have constructed our expression tree correctly</p> <pre><code>(gdb) print root\n\n$1 = (struct tnode\\*) 0x5555555638f0\n\n(gdb) print root-&gt;symbol\n\n$2 = 0x55555555afe6 \"+\"\n\n(gdb) continue\n</code></pre> <p></p> <p>root is the pointer to the nodes in the tree, initially root would be pointing at the root of the syntax tree.</p> <p>When we print out the content in the node, pointed by root, using GDB, we get the output as \"+\" as expected.</p> <p>The right side of the image is just to show where the pointer root is pointing at currently in the syntax tree, and we are constructing that tree only from the information that we are gettig through print statements in our gdb.</p> <p>As the root node is perfect, we are safe to proceed in checking the values of the remaining nodes.</p> <p>continue - To run until you encounter next breakpoint</p> <p>Since the infixtoprefix function is a pre-order traversal of the tree, the function would be recursively called again with the left child of the root node.</p> <p>Since, we have executed the \"continue\" statement, the gdb will be executing the code, and halt again only when it reaches the start of the function again, this time due to the recursive call with the left child of root node. This is because we have set a break point at the start of the infixtoprefix function.</p> <pre><code>(gdb) next\n\n(gdb) print root\n\n$1 = (struct tnode\\*) 0x555555563710\n\n(gdb) print root-&gt;symbol\n\n$2 = 0x55555555636f0 \"abc\"\n\n(gdb) continue\n</code></pre> <p></p> <p>\"next\" command is used to enter inside the function</p> <p>Now, same as before we print out the content of the current node, and then we execute the \"continue\" statement to reach the next node.</p> <p>Here we found \"abc\" to the left of \"+\" node as expected</p> <p>Moving on to the left node of the current node</p> <pre><code>(gdb) next\n\n(gdb) print root\n\n$1 = (struct tnode\\*) 0x0\n\n(gdb) continue\n</code></pre> <p></p> <p>We have reached the Null node represented by 0x0 in hexadecimal</p> <p>Now we move to the right node, following the pre-order</p> <pre><code>(gdb) next\n\n(gdb) print root\n\n$1 = (struct tnode\\*) 0x0\n\n(gdb) continue\n</code></pre> <p></p> <p>This helps us to infer that \"abc\" node is a leaf node</p> <p>Continuing the preorder traversal</p> <pre><code>(gdb) next\n\n(gdb) print root\n\n$1 = (struct tnode\\*) 0x555555563711\n\n(gdb) print root-&gt;symbol\n\n$2 = 0x55555555636f0 \"\\*\"\n\n(gdb) continue\n</code></pre> <p></p> <p>As expected we found \"*\" to the right of \"+\" node</p> <pre><code>(gdb) next\n\n(gdb) print root\n\n$1 = (struct tnode\\*) 0x555555563720\n\n(gdb) print root-&gt;symbol\n\n$2 = 0x55555555636f1 \"-\"\n\n(gdb) continue\n</code></pre> <p></p> <p>As expected we found \"-\" to the left of \"+\" node</p> <p>Continuing the same steps, we will find node \"bcd\" to the left of \"-\" node, and as expected it turns out to be a leaf node</p> <p>When we move right from the current node \"-\"</p> <pre><code>(gdb) next\n\n(gdb) print root\n\n$1 = (struct tnode\\*) 0x55555556371b\n\n(gdb) print root-&gt;symbol\n\n$2 = 0x55555555636f6 \"efg\"\n\n(gdb) continue\n</code></pre> <p></p> <p>As expected we found \"efg\" to the right of \"-\" node</p> <p>Further continuing the debugging, we will discover node \"efg\" to be a leaf node</p> <p>Now, when we move right from node \"*\"</p> <pre><code>(gdb) next\n\n(gdb) print root\n\n$1 = (struct tnode\\*) 0x5555555637c0\n\n(gdb) print root-&gt;symbol\n\n$2 = 0x55555555636c2 \"hij\"\n\n(gdb) continue\n</code></pre> <p></p> <p>As expected we found \"hij\" to the right of \"*\" node</p> <p>Further continuing the debugging, we will find the Null node to the left of \"hij\" node</p> <p>Now, when we move right from node \"hij\"</p> <pre><code>(gdb) next\n\n(gdb) print root\n\n$1 = (struct tnode\\*) 0x0\n\n(gdb) continue\n</code></pre> <p></p> <p>Now the program exits, as we have traversed every node of the expression tree via GDB, and verified the contents of all the nodes, and the expression tree is just as expected.</p> <p>An alternate way is to set a watchpoint</p> <p>watch - You can use a watchpoint to stop execution whenever the value of an expression changes, without having to predict a particular place where this may happen.</p> <p><code>(gdb) watch root</code></p> <p>GDB will monitor the value of the root pointer, and whenever the value of the variable \"root\" changes (when root points to a different node), gdb halts the execution, and prints the old value and the new value of the \"root\" variable.</p>"},{"location":"gdb/#infinte-loop","title":"Infinte Loop","text":"<p>One of the most critical use cases for GDB arises when we encounter a segmentation fault or an infinite loop. These issues become increasingly common as the syntax tree grows more complex in later stages. In such situations, using GDB to debug the syntax tree, verify its contents, and identify what went wrong is invaluable. It can save a significant amount of time and effort in troubleshooting these complex errors.</p> <p>In this example, we can see an infinite loop, for the problem infix to prefix problem. let us see how we can use GDB to find the error in the construction of the express tree / syntax tree.</p> <p></p> <p>let us print the contents of the tree</p> <pre><code>(gdb) print root-&gt;right-&gt;symbol\n\n$3 = 0x55555555637f7 \"\\*\"\n\n(gdb) print root-&gt;right-&gt;left-&gt;symbol\n\n$4 = 0x55555555631f1 \"-\"\n\n(gdb) print root-&gt;right-&gt;left-&gt;left-&gt;symbol\n\n$5 = 0x55555555635f2 \"bcd\"\n\n(gdb) print root-&gt;right-&gt;left-&gt;right-&gt;symbol\n\n$6 = 0x55555555631f9 \"efg\"\n\n(gdb) print root-&gt;right-&gt;right-&gt;symbol\n\n$7 = 0x55555555636f0 \"hij\"\n\n(gdb) print root-&gt;right-&gt;right-&gt;left\n\n$8 = (struct tnode\\*) 0x0\n</code></pre> <p></p> <p>Everything seems fine so far, let us now verify the contents to the right of node \"hij\".</p> <pre><code>(gdb) print root-&gt;right-&gt;right-&gt;right\n\n$1 = (struct tnode\\*) 0x5555555637f0\n\n(gdb) print root-&gt;right-&gt;symbol\n\n$2 = 0x55555555637f7 \"\\*\"\n</code></pre> <p>Now, we are not sure whether this node \"*\" is a new node to the right of node \"hij\" OR it is the same node which is a right of node \"+\", and node \"hij\" is making a cyclic loop with this node.</p> <p></p> <p></p> <p></p> <p>Next, we check whether they are different nodes as shown in the image in the left or it is the same node as in the image shown in the right.</p> <pre><code>(gdb) print root-&gt;right == root-&gt;right-&gt;right-&gt;right\n\n$11 = 1\n</code></pre> <p>Now, we do find that both the node \"*\" is actually the same node, and this cyclic loop was actually the cause of our infinite loop. These checkings could be done in minutes to find the source of the error and thus saving a lot of time for you.</p> <p>Now, we will remove the loop, and check whether our program runs smoothly now.</p> <pre><code>(gdb) set root-&gt;right-&gt;right-&gt;right = 0x0\n\n(gdb) clear infixtoprefix\n\n(gdb) continue\n\nDeleted breakpoint 1 continuing.\n\nInferior 1 (process 10496) exited normally\\]\n</code></pre> <p>Now, we have removed the cyclic loop, and set the right child of node \"hij\" as NULL, as it was supposed to be. Then when we resume our program, we can see that \"(process 10496) exited normally\", which confirms the fact that our program does not have an additional errors, and the only error was the cyclic loop, and we need to remove it.</p> <p>set var - This command is used to modify the current value of a varible, and to see it's effect. An example would be \"set var my_sum_var=100\"</p> <p>In the above image, we can see that, we have used the \"set\" command to change the value of the pointer root-&gt;right-&gt;right-&gt;right to NULL, this actually helped us to check whether this modification helps in solving our infinite loop problem, which it does in this case.</p> <p>GDB, thus, helps us to save a lot of time in debugging.</p>"},{"location":"gdb/#some-of-the-important-gdb-commands-are-","title":"Some of the important GDB commands are :-","text":"<ul> <li>layout src - Opens a Graphical user interface, where you can view the part of the code currently executing along with the code line numbers</li> <li>start - It starts debugging from top, and gives control to user</li> <li>break - You can pass a function name or line number as an argument to this command. It will set a break point corresponding to that line number or function. So that when we run the gdb, it halts at the break point, and then we can move incrementally (step by step) exploring the variables and the execution flow.</li> <li>continue - To run until you encounter next breakpoint</li> <li>run - It runs the program until it encounters one of the break points.</li> <li>next or n - To move to the next line in the immediate scope, it is basically a step over function, i.e it do not enter any function code.</li> <li>step or s - To step into the function, so that we can look into the details of the currently executing function</li> <li>print - you can use this to print the value of the variables at that point.</li> <li>set var - This command is used to modify the current value of a varible, and to see it's effect. An example would be \"set var my_sum_var=100\"</li> <li>quit - To stop the debugging process</li> <li>refresh - To restart the debugging process from the top.</li> <li>clear - This command is used to clear the set breakpoints, an example could be \"clear my_func\"</li> <li>backtrace full - This is a useful command when you encounter a segmentation fault. A backtrace is a summary of how your program got where it is. It shows one line per frame, for many frames, starting with the currently executing frame (frame zero), followed by its caller (frame one), and on up the stack.</li> <li>watch - You can use a watchpoint to stop execution whenever the value of an expression changes, without having to predict a particular place where this may happen.</li> <li>rwatch - Set a watchpoint that will break when the value of expr is read by the program.</li> <li>awatch - Set a watchpoint that will break when expr is either read from or written into by the program.</li> <li>info watch - This command prints a list of watch points</li> <li>info break - This command prints a list of break points</li> <li>list - Lists the source code (10 lines around the PC)</li> <li>dele {val} To delete the set watch points or break points.</li> <li>x {var_name} - It shows the memory location where this variable is stored and the value stored in that address, both in hexadecimal.</li> <li>quit - To stop the debugging process</li> </ul>"},{"location":"gdb/#some-important-commands-in-detail-","title":"Some important commands in detail:-","text":"<ul> <li>Run</li> </ul> <p><code>(gdb) run</code></p> <p>If it has no serious problems (i.e. the normal program didn\u2019t get a segmentation fault, etc.), the program should run fine here too.   If the program did have issues, then you (should) get some useful information like the line number where it crashed, and parameters to the function that caused the error.</p> <ul> <li>Break</li> </ul> <p><code>(gdb) break my_file_1.c:5</code></p> <p>This sets a breakpoint at line 5, of my_file_1.c. Now, if the program ever reaches that location when running, the program will pause and prompt you for another command.</p> <p>You can set as many breakpoints as you want, and the program should stop execution if it reaches any of them.</p> <p>Typing \u201cstep\u201d or \u201cnext\u201d a lot of times can be tedious. If you just press ENTER, gdb will repeat the same command you just gave it. You can do this a bunch of times.</p> <ul> <li>Watch</li> </ul> <p><code>(gdb) watch my_var</code></p> <p>Whereas breakpoints interrupt the program at a particular line or function, watchpoints act on variables. They pause the program whenever a watched variable\u2019s value is modified. In the above example, whenever my_var\u2019s value is modified, the program will interrupt and print out the old and new values.</p> <ul> <li>Conditional Breakpoints   Breakpoints by themselves may seem too tedious. You have to keep stepping, and stepping, and stepping. . .</li> </ul> <p>Once we develop an idea for what the error could be (like dereferencing a NULL pointer, or going past the bounds of an array), we probably only care if such an event happens; we don\u2019t want to break at each iteration regardless</p> <p>So ideally, we\u2019d like to condition on a particular requirement (or set of requirements). Using conditional breakpoints allow us to accomplish this goal. . .</p> <p>Just like regular breakpoints, except that you get to specify some criterion that must be met for the breakpoint to trigger. We use the same break command as before:</p> <p><code>(gdb) break my_file_1.c:5 if i &gt;= SIZE_OF_ARRAY</code></p> <p>This command sets a breakpoint at line 5 of file my_file_1.c, which triggers only if the variable i is greater than or equal to the size of the array (which probably is bad if line 5 does something like array[i]). Conditional breakpoints can most likely avoid all the unnecessary stepping, etc.</p> <ul> <li>Pointer Operations   See the value (memory address) of the pointer:</li> </ul> <p><code>(gdb) print struct_pointer</code></p> <p>See a particular field of the struct the pointer is referencing:</p> <p><code>(gdb) print struct_pointer-&gt;name</code></p> <p>You can also use the dereference (*) and dot (.) operators in place of the arrow operator (-&gt;):</p> <p><code>(gdb) print \\*struct_pointer</code></p> <p>See the entire contents of the struct the pointer references</p> <p><code>(gdb) print (\\*struct_pointer).name</code></p> <p>You can also follow pointers iteratively, like in a linked list:</p> <p><code>(gdb) print list_prt-&gt;next-&gt;next-&gt;next-&gt;data</code></p>"},{"location":"gdb/#references","title":"References","text":"<p>For further details on the topics covered in this document, the reader may refer to the following :</p> <ol> <li>Debugging: GDB Tutorial (Video)</li> <li>GNU GDB Tutorial</li> </ol>"},{"location":"grammar-outline/","title":"Annotated ExpL Grammar outline","text":"<p>An outline for the ExpL grammar is given here. Calls to functions that update the symbol table, type table and the abstract syntax tree data structures are indicated as semantic actions at certain places.</p> 1. Program TypeDefBlock <pre><code>TypeDefBlock  : TYPE TypeDefList ENDTYPE\n              |\n              ;\n\nTypeDefList   : TypeDefList TypeDef\n              | TypeDef\n              ;\n\nTypeDef       : ID '{' FieldDeclList '}'   { Tptr = TInstall(tname,size,$3); }\n              ;\n\nFieldDeclList : FieldDeclList FieldDecl\n              | FieldDecl\n              ;\n\nFieldDecl    : TypeName ID ';'\n\nTypeName     : INT\n             | STR\n             | ID       //TypeName for user-defined types\n             ;\n</code></pre> GDeclBlock <pre><code>GDeclBlock : DECL GDeclList ENDDECL\n           |\n           ;\n\nGDeclList  : GDecList GDecl\n           | GDecl\n           ;\n\nGDecl      : TypeName Gidlist ';'\n           ;\n\nGidlist    : Gidlist ',' Gid\n           |   Gid\n           ;\n\nGid        :   ID                      { GInstall(varname,ttableptr, 1, NULL); }\n           |   ID '(' ParamList ')'      { GInstall(varname,ttableptr, 0, $3);   }\n           |   ID '[' NUM ']'          { GInstall(varname,ttableptr, $3, NULL);   }\n           ;\n\nParamList    :  ParamList ',' Param  { AppendParamlist($1,$2);}\n           |  Param\n           |  //There can be functions with no parameters\n           ;\n\nParam        : TypeName ID { CreateParamlist($1,$2); }\n           ;\n</code></pre> <p>Note</p> <ol> <li>The second argument to the function Ginstall() must be a pointer to a type table entry.</li> <li>The functions CreateParamlist() and AppendParamlist() help to create a linked list     containing the types and names of parameters specified in an ExpL function declaration. Design of these functions is left to you.</li> </ol> FDefBlock <pre><code>FDefList  : FDefBlock\n          | FDefList FDefBlock\n          ;\nFDefBlock : TypeName ID '(' ParamList ')' '{' LdeclBlock Body '}'  { GUpdate($2-&gt;name,$1,$4,$7,$8); }\n          ;\n\nBody      : BEGIN Slist Retstmt END\n          ;\n\nSlist     : Slist Stmt\n          |\n          ;\n\nStmt      : ID ASGN Expr ';'\n          | ....\n          | IF '(' Expr ')' THEN Slist ELSE Slist ENDIF ';'\n          | ...\n          | ID ASGN ALLOC'(' ')' ';'\n          | FIELD ASGN ALLOC'(' ')' ';'\n          | FREE '(' ID ')' ';'\n          | FREE '(' FIELD ')' ';'\n          | READ '(' ID ')' ';'\n          | READ '(' FIELD ')' ';'\n          | WRITE '(' Expr ')' ';'\n          ;\n\nFIELD     : ID '.' ID\n          | FIELD '.' ID\n          ;\n\nExpr      : Expr PLUS Expr   { $$ = TreeCreate(TLookup(\"int\"),NODETYPE_PLUS,NULL,(union Constant){},NULL,$1,$3,NULL); }\n          | ....\n          | '(' Expr ')'\n          | NUM\n          | ID\n          | ID '[' Expr ']'\n          | FIELD\n          | ID '(' ArgList ')'  {\n                                gtemp = GLookup($1-&gt;name);\n                                if(gtemp == NULL){\n                                    yyerror(\"Yacc : Undefined function\");exit(1);\n                                }\n                                $$ = TreeCreate(gtemp-&gt;type,NODETYPE_FUNCTION,$1-&gt;name,(union Constant){},$3,NULL,NULL,NULL);\n                                $$-&gt;Gentry = gtemp;\n                              }\n          ;\n</code></pre> MainBlock <pre><code>MainBlock : INT MAIN '(' ')' '{' LdeclBlock Body '}'\n                                {\n                                    type = TLookup(\"int\");\n                                    gtemp = GInstall(\"MAIN\",type,0,NULL);\n                                    //...Some more work to be done\n                                }\n          ;\n</code></pre>"},{"location":"help/","title":"Help","text":"<p>ExpL user's forum is made available to all the users for any queries during the process of development of the compiler.</p> <p>The google forum can be found here.</p>"},{"location":"install/","title":"Installation","text":"<p>If these instructions do not work, you can try the  Docker based setup. </p>"},{"location":"install/#install-lex","title":"Install LEX","text":"Ubuntu <pre><code>sudo apt-get update\nsudo apt-get install flex\n</code></pre> Fedora <pre><code>sudo dnf install flex\n</code></pre>"},{"location":"install/#install-yacc","title":"Install YACC","text":"Ubuntu <pre><code>sudo apt-get update\nsudo apt-get install bison\n</code></pre> Fedora <pre><code>sudo dnf install bison byacc\n</code></pre>"},{"location":"install/#install-xsm-machine-simulator","title":"Install XSM Machine Simulator","text":"<p>The compiler's target code needs to be run on a simulator and the installation steps are given below.</p> <p>Let us install XSM</p>"},{"location":"install/#step-1","title":"Step 1","text":"<p>Clone the XSM Simulator from the official repository to your computer</p> <pre><code>git clone https://github.com/silcnitc/xsm_expl.git\n</code></pre>"},{"location":"install/#step-2","title":"Step 2","text":"<p>Navigate into the folder <code>xsm_expl</code> through the terminal. <pre><code>cd xsm_expl\n</code></pre></p> <p>Do the following steps:</p> <ol> <li> <p>Type <code>make</code>.</p> <p>You may get some warnings and they can be ignored. If you get any fatal error, then install the following dependencies and try running <code>make</code> again :</p> Ubuntu <pre><code>sudo apt-get install libreadline-dev\nsudo apt-get install libc6-dev\n</code></pre> Fedora <pre><code>sudo dnf install readline-devel\n</code></pre> <p>If any other dependencies are missing (this depends on your system configuration), you have to install the missing dependencies and run <code>make</code> again.</p> <p>Optional</p> <p>While running <code>./xsm</code> after Step 2 if you get this error: <pre><code>/usr/bin/ld: cannot find -ll collect2: error: ld returned 1 exit status\n</code></pre> Then you need to install:</p> Ubuntu <pre><code>sudo apt-get install libfl-dev\n</code></pre> Fedora <pre><code>sudo dnf install flex-devel\n</code></pre> <p>and edit the <code>Makefile</code> of <code>xsm_dev</code> folder, to proceed find the line where <code>-ll</code> is used as option and update it to <code>-lfl</code> to use the <code>flex</code> library we installed above. Now you can run <code>make</code> again after navigating into the folder <code>xsm_expl</code> through the terminal.</p> </li> <li> <p>Type <code>cd ../xfs-interface/</code> and type <code>./init</code>.</p> </li> <li>(Optional) Add this line <code>#!/usr/bin/env bash</code> as first line to the <code>xsm</code> file in <code>xsm_expl</code> folder.     This step is for those who don't have bash or sh as their \"default shell\" and therefore may be using other customizable shells like <code>zsh</code>, etc as their default shell.     You can check your default shell by using <code>echo $SHELL</code> in terminal.</li> </ol> <p>The usage instructions for the XSM simulator can be found here.</p> <p>Please report installation errors to kmurali@nitc.ac.in</p>"},{"location":"label-translation/","title":"Label Translation (Linking*)","text":""},{"location":"label-translation/#introduction","title":"Introduction","text":"<p>Labels are generated when the compiler translates the high level program constructs such as if-then-else, while-do and function calls into target machine code. Labels are needed because the target address of a JUMP instruction may not be known at the time of generating code (Why?). However these labels must be replaced with target addresses in the final target code. Thus the compiler designer needs to write a program to replace all the labels in the program with the correct memory addresses eventually. This conversion is called Label translation.</p> <p>The input to the label translator program is the machine code with labels (generated by <code>codeGen()</code>). The output is the target machine code with the labels replaced with corresponding addresses.</p> <p>The main idea behind label translation is to execute the following two steps.  </p> <ol> <li>The input ( machine code with labels ) is parsed and a table in which the labels are mapped with their corresponding addresses is created.</li> <li>Parse the input again and replace all the labels with their corresponding addresses by looking into the table created above.</li> </ol> <p>Note</p> <p>In real systems, the compiler generates an object file which contains labels for functions as well as variables. The object file is processed by a separate software module called the linker which converts the object file into an excutable file. The advantage of this scheme is that a huge program could be divided into different stand alone source modules, each compiled seperately and finally linked together. A change in one module does not require recompilation of other modules and only the linking phase needs to be run again. In this project, we keep the linking task as a part of the compilation itself as ExpL does not allow a program to be compiled into several object modules.</p> <p>In the ExpL project, variable addresses are resolved before reaching the Label translation phase by the compiler itself. Hence the labels remaining will correspond to  </p> <ol> <li>The label of the first instruction to be executed (MAIN:),</li> <li>Labels placed at the beginning of assembly instructions to which there is some JMP/JZ/JNZ from somewhere.</li> <li>Labels placed at the beginning of functions. (The compiler translates a call to the function with a CALL instruction with this label).</li> </ol>"},{"location":"label-translation/#illustration","title":"Illustration","text":"<p>The above procedure is demonstrated with the help of a program snippet.</p> <pre><code>decl\n int fact(int n);\nenddecl\n\nint fact(int n)\n{\n decl\n  int f;\n enddecl\n begin\n  if(n&lt;=1) then\n   f=1;\n  else\n   f=n*fact(n-1);\n  endif;\n  return f;\n end\n}\n\nint main()\n{\n decl\n  int n,m,res;\n enddecl\n begin\n  read(n);\n  while( n &gt;= 1 ) do\n   read(m);\n   res = fact(m);\n   write(res);\n   n = n-1;\n  endwhile;\n  return 0;\n end\n}\n</code></pre> <p>The code generated after the <code>codeGen()</code> phase is shown in the figure 1 ( It consists of labels ).</p> <p>In the machine code generated after codegen section, labels occur in two different ways.  </p> <ol> <li> <p>Label declarations in which labels are followed by semicolon (:).</p> <p>Examples : F0: is a label for the instruction at address 2066, L0: for 2102, L1: for 2162 and MAIN: for 2186 as in figure1</p> </li> <li> <p>Instructions which contain labels in them namely, JMP, JZ, JNZ and CALL.</p> <p>Examples : JMP L1 at address 2100, JZ R0,L3 at address 2248, CALL MAIN at address 2062 etc., as in figure1.</p> </li> </ol> <p>Now, the label translation procedure can be explained with the help of an example label F0 from the figure1.  </p> <p>First \"F0:\" needs to be recognized as a label and the memory address of the label occurence need to be stored in a table called the Label-Address Table. In the above example, the address corresponding to F0: is 2066. We need to parse the entire machine code to identify all the labels in the program and store all the (label, address) pairs in the Label-Address table. We can remove the label F0: (and other labels) from the program once the corresponding (label,address) pair is entered into the label-address table.</p> <p>The next task is to replace labels occuring in instructions with the addresses of the labels from the label-address table. Refering to the figure1, there are two instructions that use the label F0: CALL F0 occuring at address 2136 and CALL F0 occuring at address 2302. We will replace the labels in these instructions with the address of F0 (2066) by looking up the label-address table. Thus, after translation, both these instructions will translate to CALL 2066 as shown in figure2.</p> <p>The label translator program needs to parse the entire machine code two times. In the first parse we identify all the label declarations and the memory addresses in the label-address table. The table constructed after the first parse of the above code is shown below.</p> <p></p> <p>In the second parse, we remove the label declarations and replace the labels in instructions like JUMP, CALL etc. with the corresponding memory address from the label-address table.</p> <p>The target code after the label translation is shown in the figure 2.</p>"},{"location":"label-translation/#fig1","title":"Figure 1: Assembly Code Before Label Translation","text":"<pre>\n        \n        <code>\n2048 : 0\n2049 : 2056\n2050 : 0\n2051 : 0\n2052 : 0\n2053 : 0\n2054 : 0\n2055 : 0\n2056 : MOV SP,4095\n2058 : MOV BP,4096\n2060 : PUSH R0\n2062 : CALL MAIN\n2064 : INT 10\n       F0:\n2066 : PUSH BP\n2068 : MOV BP,SP\n2070 : PUSH R0\n2072 : MOV R1,BP\n2074 : MOV R2,2\n2076 : SUB R1,R2\n2078 : MOV R2,1\n2080 : SUB R1,R2\n2082 : MOV R0,[R1]\n2084 : MOV R1,1\n2086 : LE R0,R1\n2088 : JZ R0,L0\n2090 : MOV R0,1\n2092 : MOV R2,BP\n2094 : MOV R1,1\n2096 : ADD R2,R1\n2098 : MOV [R2],R0\n2100 : JMP L1\n       L0:\n2102 : MOV R1,BP\n2104 : MOV R2,2\n2106 : SUB R1,R2\n2108 : MOV R2,1\n2110 : SUB R1,R2\n2112 : MOV R0,[R1]\n2114 : PUSH R0\n2116 : MOV R1,BP\n2118 : MOV R2,2\n2120 : SUB R1,R2\n2122 : MOV R2,1\n2124 : SUB R1,R2\n2126 : MOV R0,[R1]\n2128 : MOV R1,1\n2130 : SUB R0,R1\n2132 : PUSH R0\n2134 : PUSH R0\n2136 : CALL F0\n2138 : POP R0\n2140 : POP R0\n2142 : POP R0\n2144 : MOV R1,3\n2146 : MOV R2,SP\n2148 : ADD R2,R1\n2150 : MOV R1,[R2]\n2152 : MUL R0,R1\n2154 : MOV R2,BP\n2156 : MOV R1,1\n2158 : ADD R2,R1\n2160 : MOV [R2],R0\n       L1:\n2162 : MOV R1,BP\n2164 : MOV R0,1\n2166 : ADD R1,R0\n2168 : MOV R0,[R1]\n2170 : MOV R1,BP\n2172 : MOV R2,2\n2174 : SUB R1,R2\n2176 : MOV [R1],R0\n2178 : POP R0\n2180 : MOV BP,[SP]\n2182 : POP R0\n2184 : RET\n       MAIN:\n2186 : PUSH BP\n2188 : MOV BP,SP\n2190 : PUSH R0\n2192 : PUSH R0\n2194 : PUSH R0\n2196 : MOV R1,BP\n2198 : MOV R0,1\n2200 : ADD R1,R0\n2202 : PUSH R0\n2204 : PUSH R1\n2206 : MOV R0,\"Read\"\n2208 : PUSH R0\n2210 : MOV R0,-1\n2212 : PUSH R0\n2214 : PUSH R1\n2216 : PUSH R0\n2218 : PUSH R0\n2220 : CALL 0\n2222 : POP R0\n2224 : POP R0\n2226 : POP R0\n2228 : POP R0\n2230 : POP R0\n2232 : POP R0\n2234 : POP R0\n       L2:\n2236 : MOV R1,BP\n2238 : MOV R0,1\n2240 : ADD R1,R0\n2242 : MOV R0,[R1]\n2244 : MOV R1,1\n2246 : GE R0,R1\n2248 : JZ R0,L3\n2250 : MOV R1,BP\n2252 : MOV R0,2\n2254 : ADD R1,R0\n2256 : PUSH R0\n2258 : PUSH R1\n2260 : MOV R0,\"Read\"\n2262 : PUSH R0\n2264 : MOV R0,-1\n2266 : PUSH R0\n2268 : PUSH R1\n2270 : PUSH R0\n2272 : PUSH R0\n2274 : CALL 0\n2276 : POP R0\n2278 : POP R0\n2280 : POP R0\n2282 : POP R0\n2284 : POP R0\n2286 : POP R0\n2288 : POP R0\n2290 : MOV R1,BP\n2292 : MOV R0,2\n2294 : ADD R1,R0\n2296 : MOV R0,[R1]\n2298 : PUSH R0\n2300 : PUSH R0\n2302 : CALL F0\n2304 : POP R0\n2306 : POP R0\n2308 : MOV R0,2\n2310 : MOV R1,SP\n2312 : ADD R1,R0\n2314 : MOV R0,[R1]\n2316 : MOV R2,BP\n2318 : MOV R1,3\n2320 : ADD R2,R1\n2322 : MOV [R2],R0\n2324 : MOV R1,BP\n2326 : MOV R0,3\n2328 : ADD R1,R0\n2330 : MOV R0,[R1]\n2332 : MOV [2042],R0\n2334 : PUSH R0\n2336 : MOV R0,\"Write\"\n2338 : PUSH R0\n2340 : MOV R0,-2\n2342 : PUSH R0\n2344 : MOV R0,2042\n2346 : PUSH R0\n2348 : PUSH R0\n2350 : PUSH R0\n2352 : CALL 0\n2354 : POP R0\n2356 : POP R0\n2358 : POP R0\n2360 : POP R0\n2362 : POP R0\n2364 : POP R0\n2366 : MOV R1,BP\n2368 : MOV R0,1\n2370 : ADD R1,R0\n2372 : MOV R0,[R1]\n2374 : MOV R1,1\n2376 : SUB R0,R1\n2378 : MOV R2,BP\n2380 : MOV R1,1\n2382 : ADD R2,R1\n2384 : MOV [R2],R0\n2386 : JMP L2\n       L3:\n2388 : MOV R0,0\n2390 : MOV R1,BP\n2392 : MOV R2,2\n2394 : SUB R1,R2\n2396 : MOV [R1],R0\n2398 : POP R0\n2400 : POP R0\n2402 : POP R0\n2404 : MOV BP,[SP]\n2406 : POP R0\n2408 : RET\n        </code>\n    </pre>"},{"location":"label-translation/#fig2","title":"Figure 2: Assembly Code after Label Translation","text":"<pre>\n        \n        <code>\n2048 : 0\n2049 : 2056\n2050 : 0\n2051 : 0\n2052 : 0\n2053 : 0\n2054 : 0\n2055 : 0\n2056 : MOV SP,4095\n2058 : MOV BP,4096\n2060 : PUSH R0\n2062 : CALL 2186\n2064 : INT 10\n2066 : PUSH BP\n2068 : MOV BP,SP\n2070 : PUSH R0\n2072 : MOV R1,BP\n2074 : MOV R2,2\n2076 : SUB R1,R2\n2078 : MOV R2,1\n2080 : SUB R1,R2\n2082 : MOV R0,[R1]\n2084 : MOV R1,1\n2086 : LE R0,R1\n2088 : JZ R0,2102\n2090 : MOV R0,1\n2092 : MOV R2,BP\n2094 : MOV R1,1\n2096 : ADD R2,R1\n2098 : MOV [R2],R0\n2100 : JMP 2162\n2102 : MOV R1,BP\n2104 : MOV R2,2\n2106 : SUB R1,R2\n2108 : MOV R2,1\n2110 : SUB R1,R2\n2112 : MOV R0,[R1]\n2114 : PUSH R0\n2116 : MOV R1,BP\n2118 : MOV R2,2\n2120 : SUB R1,R2\n2122 : MOV R2,1\n2124 : SUB R1,R2\n2126 : MOV R0,[R1]\n2128 : MOV R1,1\n2130 : SUB R0,R1\n2132 : PUSH R0\n2134 : PUSH R0\n2136 : CALL 2066\n2138 : POP R0\n2140 : POP R0\n2142 : POP R0\n2144 : MOV R1,3\n2146 : MOV R2,SP\n2148 : ADD R2,R1\n2150 : MOV R1,[R2]\n2152 : MUL R0,R1\n2154 : MOV R2,BP\n2156 : MOV R1,1\n2158 : ADD R2,R1\n2160 : MOV [R2],R0\n2162 : MOV R1,BP\n2164 : MOV R0,1\n2166 : ADD R1,R0\n2168 : MOV R0,[R1]\n2170 : MOV R1,BP\n2172 : MOV R2,2\n2174 : SUB R1,R2\n2176 : MOV [R1],R0\n2178 : POP R0\n2180 : MOV BP,[SP]\n2182 : POP R0\n2184 : RET\n2186 : PUSH BP\n2188 : MOV BP,SP\n2190 : PUSH R0\n2192 : PUSH R0\n2194 : PUSH R0\n2196 : MOV R1,BP\n2198 : MOV R0,1\n2200 : ADD R1,R0\n2202 : PUSH R0\n2204 : PUSH R1\n2206 : MOV R0,\"Read\"\n2208 : PUSH R0\n2210 : MOV R0,-1\n2212 : PUSH R0\n2214 : PUSH R1\n2216 : PUSH R0\n2218 : PUSH R0\n2220 : CALL 0\n2222 : POP R0\n2224 : POP R0\n2226 : POP R0\n2228 : POP R0\n2230 : POP R0\n2232 : POP R0\n2234 : POP R0\n2236 : MOV R1,BP\n2238 : MOV R0,1\n2240 : ADD R1,R0\n2242 : MOV R0,[R1]\n2244 : MOV R1,1\n2246 : GE R0,R1\n2248 : JZ R0,2388\n2250 : MOV R1,BP\n2252 : MOV R0,2\n2254 : ADD R1,R0\n2256 : PUSH R0\n2258 : PUSH R1\n2260 : MOV R0,\"Read\"\n2262 : PUSH R0\n2264 : MOV R0,-1\n2266 : PUSH R0\n2268 : PUSH R1\n2270 : PUSH R0\n2272 : PUSH R0\n2274 : CALL 0\n2276 : POP R0\n2278 : POP R0\n2280 : POP R0\n2282 : POP R0\n2284 : POP R0\n2286 : POP R0\n2288 : POP R0\n2290 : MOV R1,BP\n2292 : MOV R0,2\n2294 : ADD R1,R0\n2296 : MOV R0,[R1]\n2298 : PUSH R0\n2300 : PUSH R0\n2302 : CALL 2066\n2304 : POP R0\n2306 : POP R0\n2308 : MOV R0,2\n2310 : MOV R1,SP\n2312 : ADD R1,R0\n2314 : MOV R0,[R1]\n2316 : MOV R2,BP\n2318 : MOV R1,3\n2320 : ADD R2,R1\n2322 : MOV [R2],R0\n2324 : MOV R1,BP\n2326 : MOV R0,3\n2328 : ADD R1,R0\n2330 : MOV R0,[R1]\n2332 : MOV [2042],R0\n2334 : PUSH R0\n2336 : MOV R0,\"Write\"\n2338 : PUSH R0\n2340 : MOV R0,-2\n2342 : PUSH R0\n2344 : MOV R0,2042\n2346 : PUSH R0\n2348 : PUSH R0\n2350 : PUSH R0\n2352 : CALL 0\n2354 : POP R0\n2356 : POP R0\n2358 : POP R0\n2360 : POP R0\n2362 : POP R0\n2364 : POP R0\n2366 : MOV R1,BP\n2368 : MOV R0,1\n2370 : ADD R1,R0\n2372 : MOV R0,[R1]\n2374 : MOV R1,1\n2376 : SUB R0,R1\n2378 : MOV R2,BP\n2380 : MOV R1,1\n2382 : ADD R2,R1\n2384 : MOV [R2],R0\n2386 : JMP 2236\n2388 : MOV R0,0\n2390 : MOV R1,BP\n2392 : MOV R2,2\n2394 : SUB R1,R2\n2396 : MOV [R1],R0\n2398 : POP R0\n2400 : POP R0\n2402 : POP R0\n2404 : MOV BP,[SP]\n2406 : POP R0\n2408 : RET\n        </code>\n        </pre>"},{"location":"label-translation/#implementing-label-translation","title":"Implementing Label Translation","text":"<p>As noted previously, the input to the label translator program is the machine code with labels (generated by <code>codeGen()</code>). The output is the target machine code with the labels replaced with corresponding addresses. It is easy to design a simple lex program which does two passes on the input file and perform label translation.</p> <p>The first pass must collect all the label declarations and simultaneously keep track of the addresses of the instructions corresponding to the labels. Since the pattern <code>letter(letter|digit)*:</code> identifies a label, it is easy to design a LEX rule to recognize all label declarations in the program. The compiler must ensure that label names are different from instructions, to avoid confusion.</p> <p>Since each XSM instruction takes two words of storage, and the first instruction is at address 2056, the first pass can track the address corresponding to each label declaration as <code>2056 + 2 *(InstructionNumber-1)</code>.</p> <p>The program can maintain a simple linked list into which each label address pair found is entered. The label declarations can be removed from the input program, once it's table entry is made.</p> <p>In the second pass, the program must \"search and replace\" each label occuring in the control transfer instructions (JMP, JZ, JNZ and CALL) with the corresponding address in the label table. Since the instruction set is fixed and labels are lexically different from instructions, a simple set of LEX rules can identify all labels and perform the replacement.</p> <p>We leave the implementation details to you.</p> <p>Question</p> <p>What is the difficulty in implementing the label translation using single pass algorithm?</p>"},{"location":"lex/","title":"Using <code>lex</code>","text":""},{"location":"lex/#introduction","title":"Introduction","text":"<p>LEX is a tool used to generate a lexical analyzer. This document is a tutorial for the use of LEX for ExpL Compiler development. Technically, LEX translates a set of regular expression specifications (given as input in input_file.l) into a C implementation of a corresponding finite state machine (lex.yy.c). This C program, when compiled, yields an executable lexical analyzer.</p> <p></p> <p>The source ExpL program is fed as the input to the the lexical analyzer which produces a sequence of tokens as output. (Tokens are explained below). Conceptually, a lexical analyzer scans a given source ExpL program and produces an output of tokens.</p> <p>Each token is specified by a token name. The token name is an abstract symbol representing the kind of lexical unit, e.g., a particular keyword, or a sequence of input characters denoting an identifier. The token names are the input symbols that the parser processes. For instance integer, boolean, begin, end, if, while etc. are tokens in ExpL.</p> <pre><code>\"integer\" \u00a0 {return ID_TYPE_INTEGER;}\n</code></pre> <p>This example demonstrates the specification of a rule in LEX. The rule in this example specifies that the lexical analyzer must return the token named ID_TYPE_INTEGER when the pattern \u201cinteger\u201d is found in the input file. A rule in a LEX program comprises of a 'pattern' part (specified by a regular expression) and a corresponding (semantic) 'action' part (a sequence of C statements). In the above example, \u201cinteger\u201d is the pattern and {return ID_TYPE_INTEGER;} is the corresponding action. The statements in the action part will be executed when the pattern is detected in the input.</p> <p>Lex was developed by Mike Lesk and Eric Schmidt at Bell labs.</p>"},{"location":"lex/#the-structure-of-lex-programs","title":"The structure of LEX programs","text":"<p>A LEX program consists of three sections : Declarations, Rules and Auxiliary functions</p> <pre><code>DECLARATIONS\n\n%%\n\nRULES\n\n%%\n\nAUXILIARY FUNCTIONS\n</code></pre>"},{"location":"lex/#declarations","title":"Declarations","text":"<p>The declarations section consists of two parts, auxiliary declarations and regular definitions.</p> <p>The auxiliary declarations are copied as such by LEX to the output lex.yy.c file. This C code consists of instructions to the C compiler and are not processed by the LEX tool.The auxiliary declarations (which are optional) are written in C language and are enclosed within ' %{ ' and ' %} ' . It is generally used to declare functions, include header files, or define global variables and constants.</p> <p>LEX allows the use of short-hands and extensions to regular expressions for the regular definitions. A regular definition in LEX is of the form : D \u00a0 R \u00a0\u00a0 where D is the symbol representing the regular expression R.</p> <p>Example:</p> <pre><code>/*Declarations section start here*/\n\n/* Auxiliary declarations start here*/\n\n%{\n #include &lt;stdio.h&gt;\n int global_variable;\n%}\n\n/*Auxiliary declarations end &amp; Regular definitions start here*/\n\n    number [0-9]+           //Regular definition\n    op     [-|+|*|/|^|=]    //Regular definition\n\n/*Declarations section ends here*/\n\n%%\n\n/* Rules */\n\n%%\n\n/* Auxiliary functions */\n</code></pre>"},{"location":"lex/#rules","title":"Rules","text":"<p>Rules in a LEX program consists of two parts :</p> <ol> <li>The pattern to be matched</li> <li>The corresponding action to be executed</li> </ol> <p>Example:</p> <pre><code>/* Declarations*/\n%%\n\n    {number}  {printf(\u201c number\u201d);}\n    {op}      {printf(\u201c operator\u201d);}\n\n%%\n/* Auxiliary functions */\n</code></pre> <p>The pattern to be matched is specified as a regular expression.</p> <p>Sample Input/Output for the above example:</p> <pre><code>I: 234\nO: number\n\nI: *\nO: operator\n\nI: 2+3\nO: number operator number\n</code></pre> <p>LEX obtains the regular expressions of the symbols 'number' and 'op' from the declarations section and generates code into a function yylex() in the lex.yy.c file. This function checks the input stream for the first match to one of the patterns specified and executes code in the action part corresponding to the pattern.</p>"},{"location":"lex/#auxiliary-functions","title":"Auxiliary functions","text":"<p>LEX generates C code for the rules specified in the Rules section and places this code into a single function called yylex(). (To be discussed in detail later). In addition to this LEX generated code, the programmer may wish to add his own code to the lex.yy.c file. The auxiliary functions section allows the programmer to achieve this.</p> <p>Example:</p> <pre><code>/* Declarations */\n%%\n/* Rules */\n%%\n\nint main()\n{\n    yylex();\n    return 1;\n}\n</code></pre> <p>The auxiliary declarations and auxiliary functions are copied as such to the lex.yy.c file</p> <p>Once the code is written, lex.yy.c maybe generated using the command lex \"filename.l\" and compiled as gcc lex.yy.c</p>"},{"location":"lex/#the-yyvariables","title":"The yyvariables","text":"<p>The following variables are offered by LEX to aid the programmer in designing sophisticated lexical analyzers. These variables are accessible in the LEX program and are automatically declared by LEX in lex.yy.c.</p> <ul> <li>yyin</li> <li>yytext</li> <li>yyleng</li> </ul>"},{"location":"lex/#yyin","title":"<code>yyin</code>","text":"<p>yyin is a variable of the type FILE* and points to the input file. yyin is defined by LEX automatically. If the programmer assigns an input file to yyin in the auxiliary functions section, then yyin is set to point to that file. Otherwise LEX assigns yyin to stdin(console input).</p> <p>Example:</p> <pre><code>/* Declarations */\n%%\n    /* Rules */\n%%\n\nmain(int argc, char* argv[])\n{\n if(argc &gt; 1)\n {\n  FILE *fp = fopen(argv[1], \"r\");\n  if(fp)\n   yyin = fp;\n }\n yylex();\n return 1;\n}\n</code></pre> <p>Excercise:</p> <p>Exercise</p> <p>In the generated lex.yy.c file, the following code segment can be found under the definition of yylex().</p> <pre><code>if( ! yyin )\nyyin = stdin;\n</code></pre> <p>Try to locate this code segment in the file lex.yy.c. What could be the consequences of removing this code segment from lex.yy.c before compiling it for generating the lexical analyzer? The above statement indicates that if the programmer does not define yyin, then yylex() by default sets yyin to the console input. Hence, any re-definition for yyin must be made before invoking yylex(). (This will be explained in detail later).</p>"},{"location":"lex/#yytext","title":"<code>yytext</code>","text":"<p>yytext is of type char* and it contains the lexeme currently found. A lexeme is a sequence of characters in the input stream that matches some pattern in the Rules Section. (In fact, it is the first matching sequence in the input from the position pointed to by yyin.) Each invocation of the function yylex() results in yytext carrying a pointer to the lexeme found in the input stream by yylex(). The value of yytext will be overwritten after the next yylex() invocation.</p> <p>Example:</p> <pre><code>%option noyywrap\n%{\n #include &lt;stdlib.h&gt;\n #include &lt;stdio.h&gt;\n%}\n\nnumber [0-9]+\n\n%%\n\n{number} {printf(\"Found : %d\\n\",atoi(yytext));}\n\n%%\n\nint main()\n{\n yylex();\n return 1;\n}\n</code></pre> <p>In the above example, if a lexeme is found for the pattern defined by number then corresponding action is executed . Consider the following sample i/o,</p> <p>Sample Input/Output:</p> <pre><code>I: 25\nO: Found : 25\n</code></pre> <p>In this case when yylex() is called, the input is read from the location given by yyin and a string \u201c25\u201d is found as a match to 'number'. This location of this string in the memory is pointed to by yytext. The corresponding action in the above rule uses a built-in function atoi() to convert the string \u201c25\u201d (of type char*) to the integer 25 (of the type int) and then prints the result on the screen. Note that the header file \u201cstdlib.h\u201d is called in the auxiliary declarations section in order to invoke atoi() in the actions part of the rule.</p> <p>Note</p> <p>The lexeme found by LEX is stored in some memory allocated by LEX which can be accessed through the character pointer yytext.</p> <p>Note</p> <p>The %option noyywrap is used to inform the compiler that the function yywrap() has not been defined. We will see what this function does later on.</p> <p>Exercise</p> <p>Suggest a modification in the above example to check whether a number found is even or odd.</p>"},{"location":"lex/#yyleng","title":"<code>yyleng</code>","text":"<p>yyleng is a variable of the type int and it stores the length of the lexeme pointed to by yytext.</p> <p>Example:</p> <pre><code>/* Declarations */\n%%\n/* Rules */\n%%\n{number} printf(\"Number of digits = %d\",yyleng);\n</code></pre> <p>Sample Input/Output</p> <pre><code>I: 1234\nO: Number of digits = 4\n</code></pre>"},{"location":"lex/#the-yyfunctions","title":"The yyfunctions","text":"<ul> <li><code>yylex()</code></li> <li><code>yywrap()</code></li> </ul>"},{"location":"lex/#yylex","title":"yylex()","text":"<p>yylex() is a function of return type int. LEX automatically defines yylex() in lex.yy.c but does not call it. The programmer must call yylex() in the Auxiliary functions section of the LEX program. LEX generates code for the definition of yylex() according to the rules specified in the Rules section.</p> <p>Note</p> <p>That yylex() need not necessarily be invoked in the Auxiliary Functions Section of LEX program when used with YACC.</p> <p>Example:</p> <pre><code>/* Declarations */\n\n%%\n\n{number} {return atoi(yytext);}\n\n%%\n\nint main()\n{\n int num = yylex();\n printf(\"Found: %d\",num);\n return 1;\n}\n</code></pre> <p>Sample Input/Output :</p> <pre><code>I: 42\nO: Found: 42\n</code></pre> <p>When yylex() is invoked, it reads the input as pointed to by yyin and scans through the input looking for a matching pattern. When the input or a part of the input matches one of the given patterns, yylex() executes the corresponding action associated with the pattern as specified in the Rules section. In the above example, since there is no explicit definition of yyin, the input is taken from the console. If a match is found in the input for the pattern number, yylex() executes the corresponding action , i.e. return atoi(yytext). As a result yylex() returns the number matched. The value returned by yylex() is stored in the variable num. The value stored in this variable is then printed on screen using printf().</p> <p>yylex() continues scanning the input till one of the actions corresponding to a matched pattern executes a return statement or till the end of input has been encountered. In case of the above example, yylex() terminates immediately after executing the rule because it consists of a return statement.</p> <p>Note that if none of the actions in the Rules section executes a return statement, yylex() continues scanning for more matching patterns in the input file till the end of the file.</p> <p>In the case of console input, yylex() would wait for more input through the console. The user will have to input ctrl+d in the terminal to terminate yylex(). If yylex() is called more than once, it simply starts scanning from the position in the input file where it had returned in the previous call.</p> <p>Exercise</p> <p>What would be the outputs of the lexical analyzer generated by the example LEX programs under section 3.2 and 4.1 for the following input : <pre><code>25\n32\n44\n</code></pre> Would both the outputs be the same? If not, explain why.</p>"},{"location":"lex/#yywrap","title":"<code>yywrap()</code>","text":"<p>LEX declares the function yywrap() of return-type int in the file lex.yy.c . LEX does not provide any definition for yywrap(). yylex() makes a call to yywrap() when it encounters the end of input. If yywrap() returns zero (indicating false) yylex() assumes there is more input and it continues scanning from the location pointed to by yyin. If yywrap() returns a non-zero value (indicating true), yylex() terminates the scanning process and returns 0 (i.e. \u201cwraps up\u201d). If the programmer wishes to scan more than one input file using the generated lexical analyzer, it can be simply done by setting yyin to a new input file in yywrap() and return 0.</p> <p>As LEX does not define yywrap() in lex.yy.c file but makes a call to it under yylex(), the programmer must define it in the Auxiliary functions section or provide %option noyywrap in the declarations section. This options removes the call to yywrap() in the lex.yy.c file. Note that, it is mandatory to either define yywrap() or indicate the absence using the %option feature. If not, LEX will flag an error</p> <p>Example:</p> <pre><code>%{\n #include&lt;stdio.h&gt;\n char *file1;\n%}\n\n%%\n\n[0-9]+  printf(\"number\");\n\n%%\n\nint yywrap()\n{\n   FILE *newfile_pointer;\n   char *file2=\"input_file_2.l\";\n   newfile_pointer = fopen(\"input_file_2.l\",\"r\");\n   if(strcmp(file1,file2)!=0)\n   {\n    file1=file2;\n    yyin = newfile_pointer;\n      return 0;\n   }\n   else\n    return 1;\n}\n\nint main()\n{\n file1=\"input_file.l\";\n   yyin = fopen(\"input_file.l\",\"r\");\n   yylex();\n   return 1;\n}\n</code></pre> <p>When yylex() finishes scanning the first input file, <code>input_file.l</code> yylex() invokes yywrap(). The above definition of yywrap() sets the input file pointer to input_file_2.l and returns 0 . As a result, the scanner continues scanning in <code>input_file_2.l</code> . When yylex() calls yywrap() on encountering EOF of input_file_2.l, yywrap() returns 1 and thus yylex() ceases scanning.</p> <p>Exercise</p> <p>Suggest a modification in the above example LEX program to make the generated lexical analyzer read input</p> <ul> <li>Initially from the console and then from a file input_file.l</li> <li>Initially from a file input_file.l and then from the console</li> <li>Twice from the console</li> </ul>"},{"location":"lex/#even-oddl-a-complete-lex-program","title":"<code>even-odd.l</code> - a complete LEX program","text":"<pre><code>%{\n\n/*\n1.Request input of an even and an odd number\n2.indicate input characteristic : Even/Odd\n3.check for input's correctness and print result\n*/\n\n#include &lt;stdlib.h&gt;\n#include &lt;stdio.h&gt;\n\nint number_1;\nint number_2;\n\n%}\n\n\nnumber_sequence [0-9]*\n\n%%\n\n{number_sequence}[0|2|4|6|8] {\n                                printf(\"Even number [%d]\",yyleng);\n                                return atoi(yytext);\n                             }\n\n{number_sequence}[1|3|5|7|9] {\n                                printf(\"Odd number [%d]\",yyleng);\n                                return atoi(yytext);\n                              }\n%%\n\nint yywrap()\n{\n  return 1;\n}\n\nint main()\n{\n  printf(\"\\nInput an even number and an odd number\\n\");\n  number_1 = yylex();\n  number_2 = yylex();\n  int diff = number_1 - number_2;\n  if(diff%2!=0)\n    printf(\"\\nYour inputs were checked for correctness, \\nResult : Correct\\n\");\n  else\n    printf(\"\\nYour inputs were checked for correctness, \\nResult : Incorrect\\n\");\n  return 1;\n}\n</code></pre>"},{"location":"lex/#disambiguation-rules","title":"Disambiguation Rules","text":"<p>yylex() uses two important disambiguation rules in selecting the right action to execute in case there is more than one pattern that matches a string in the given input:</p> <ol> <li>Choose the first match.</li> <li>\"Longest match\" is preferred.</li> </ol> <p>Example:</p> <pre><code>\u201cbreak\u201d   { return BREAK; }\n[a-zA-Z][a-zA-Z0-9]*   { return IDENTIFIER; }\n</code></pre> <p>If \"break\" is found in the input, it is matched with the first pattern and yylex() returns BREAK. If \"breakdown\" is found, it is matched with the second pattern and yylex() returns IDENTIFIER. Note the use of disambiguation rules here.</p> <p>Example:</p> <pre><code>/* Declarations section */\n%%\n\n\u201c-\u201d  {return MINUS;}\n\u201c--\u201d {return DECREMENT;}\n\n%%\n/* Auxiliary functions */\n</code></pre> <p>Assume that the function calling yylex() prints the name of the token.</p> <p>Sample Input/Output :</p> <pre><code>I: -\nO: MINUS\n&lt;\nI: --\nO: DECREMENT\n\nI: ---\nO: DECREMENT MINUS\n</code></pre> <p>Note that, in case of an -- input to the lexical analyzer, yylex() does not return two MINUS tokens, but instead returns a DECREMENT token, by the second disambiguation rule.</p>"},{"location":"lex/#pattern-matching-using-lex","title":"Pattern matching using LEX","text":"<p>Conceptually, LEX constructs a finite state machine to recognize all the regular expression patterns specified in the LEX program file. The code written by the programmer in the action part is executed when the machine is in accept state. The lex.yy.c program stores information about the finite state machine in the form of a decision table (transition table). A transition(current_state,input_char) function is used to access the decision table. LEX makes it's decision table visible if we compile the program with the -T flag. The finite state machine used by LEX is deterministic finite state automaton. The lex.yy.c simulates the DFA.</p>"},{"location":"lex/#a-token-simulator-program","title":"A token simulator program","text":"<pre><code>%{\n\n/* Scan and return a token for identifiers of the format :\n\n             string number\n\nNote: strings are not case sensitive\nExamples: a0 , A1 , ab2 , AB4 , aBc5\n*/\n\n#include&lt;stdio.h&gt;\n\n#define ID 1  //Identifier token\n#define ER 2  //Error token\n\n%}\n\nlow    [a-z]\nupp    [A-Z]\nnumber [0-9]\n\n%option noyywrap\n\n%%\n\n({low}|{upp})({low}|{upp})*({number})  return ID;\n\n(.)*                                   return ER;\n\n%%\n\nint main()\n{\n  int token = yylex();\n  if(token==ID)\n    printf(\"Acceptable\\n\");\n  else if(token==ER)\n    printf(\"Unacceptable\\n\");\n  return 1;\n}\n</code></pre> <p>In this program, the main() function obtains the tokens returned by yylex() and checks if the input contains a valid identifier.</p> <p>Sample Input/Output :</p> <pre><code>I: Var9\nO: Acceptable\n</code></pre> <p>When 'Var9' is provided as the input, the DFA constructed by LEX accepts the string, and the corresponding action 'return ID' executed. As a result yylex() returns the token ID, and the main() function prints 'Acceptable' on the screen.</p>"},{"location":"lex/#construction-of-a-dfa-from-a-regular-expression","title":"Construction of a DFA from a regular expression","text":"<p>(This section explains how LEX converts a reqular expression to a finite automaton. An understanding of the contents of this section is not necessary to proceed to the next section.)</p> <p>The construction of a DFA from a regular expression takes place in two steps.</p> <ul> <li>Constructing a syntax tree from the regular expression</li> <li>Converting the syntax tree into a DFA</li> </ul>"},{"location":"lex/#the-intermediate-syntax-tree","title":"The intermediate syntax tree","text":"<p>Consider the first rule in the token simulator program in section 8. It consists of the following regular expression :</p> <pre><code>({low}|{upp})({low}|{upp})*({number})\n</code></pre> <p>For convenience in representation , let it be represented by :</p> <pre><code>( a | A ) ( a | A )* (N)\n</code></pre> <p>where, 'a' represents {low}, 'A' represents {upp} and 'N' represents {number}. The syntax tree constructed for the above regular expression would look like :</p> <p></p> <p>In the above figure \u00ba represents the 'cat' (concatenation) operator, <code>*</code> represents the 'star' operator (a unary operator) and <code>|</code> represents the 'or' operator. In the syntax tree the inner nodes are operators while the leaves are the operands. The subscript assigned to every leaf is called the position of the leaf. The positions have been assigned to the leaves starting from the left-most leaf proceedig towards the right. We are trying to represent the original regular expression with annotated positions. An annotated regular expression in this case:</p> <pre><code>( a1 | A2 ) ( a3 | A4 )*(N5)\n</code></pre> <p>The position of a leaf plays a vital role in the process of constructing states for the DFA because it represents the possible position a token maybe found in the input stream.</p> <p>Note</p> <p>Each token may have multiple positions corresponding to it as it can be found in more than one leaves. For example 'a' can be possible found in the input at positions 1 and/or 3.</p> <p>Note</p> <p>This syntax tree is an intermediate data structure. There will be no traces of this in lex.yy.c file, because it is only used in the construction of the DFA.</p>"},{"location":"lex/#the-intermediate-syntax-tree_1","title":"The intermediate syntax tree","text":"<p>Constructing the DFA involves two steps:</p> <ol> <li>Constructing the set of states of the DFA</li> <li>Constructing all the possible transitions made by the DFA from one state to another on different inputs.</li> </ol> <p>The language represented by the regular expression ( a | A ) ( a | A )* (N), can only possibly start with an 'a' or 'A'. From the syntax tree we may infer that these could only correspond to positions 1 or 2 . Let the set of these positions {1,2} be the start state of the DFA. For convenience it has been named as state I.</p> <p>Consider the position 1 (position of 'a'), it could be followed by either of the positions 3,4 or 5 (i.e, it can be followed by 'a','A' or 'N'). Let this be a new state {3,4,5} represented by II. The position 2 ('A') could be possibly followed by either of the positions 3,4 or 5. But a new state is not required as {3,4,5} has already been represented by II. Similarly the positions 3 and 4 could be followed by the position 3 or 4 or 5. If followed by 5, the DFA must accept and terminate (syntax tree ends at position 5). Hence let the final (accept) state be III. Thus, the transitions maybe formulated as :</p> <p></p>"},{"location":"lex/#the-intermediate-syntax-tree_2","title":"The intermediate syntax tree","text":"<p>The DFA obtained for the above syntax tree would look like :</p> <p></p> <p>This DFA represents the regular expression provided as a specification (i.e. pattern to be matched) in the first rule of the token simulator program in section 9. When the DFA is in the final state i.e. III, then the corresponding action is executed as instructed in the lex.yy.c file. The constructed DFA is simulated using a simulation algorithm.</p>"},{"location":"lex/#the-dfa-simulation-algorithm","title":"The DFA simulation algorithm","text":"<p>The working of the constructed DFA is simulated using the following algorithm.</p> <pre><code>DFA_simulator()\n current_state = start_state\n c = get_next_char()\n while(c != EOF)\n  current_sate = transition(current_state , c)\n   c = get_next_char()\n  if(current_state \u2208 Final_states)\n   /*ACCEPT*/\n  else\n   /*REJECT*/\n</code></pre> <p>The information about all the transitions made by the DFA can be obtained from the decision table (generally a two dimensional matrix) through the transition() function.</p>"},{"location":"lex/#using-the-generated-lexical-analyzer","title":"Using the generated lexical analyzer","text":"<p>In this document, we have learned to use LEX to build a lexical analyzer. A lexical analyzer generated by LEX can be used for lexical analysis of ExpL. Lexical analysis is the inital stage of compiling a source language. We will learn more about how to use the lexical analyzer in later stages of the documentation.</p> <p>Exercise</p> <ol> <li>Write a lex file<ol> <li>To count the number of lines, words, and characters in the input.</li> <li>To count the number of integers and floating point numbers appearing in the input.</li> <li>To list out all words of length three, starting with \"A\" to uppercase.</li> <li>To list out all C-like comments (both single line and multi line comments) from a text file.</li> </ol> </li> </ol>"},{"location":"lex/#references","title":"References","text":"<p>For further details on the topics covered in this document, the reader may refer to the following :</p> <ol> <li>Compilers : Principles,Techniques and Tools by Alfred V.Aho, Monica S. Lam, Ravi Sethi and Jeffrey D.Ulman .</li> <li>Modern Compiler Implementation in C by Andrew W.Appel</li> <li>Flex &amp; Bison by John Levine</li> <li>http://dinosaur.compilertools.net/</li> </ol>"},{"location":"libinterface/","title":"High Level Library Interface For eXpOS","text":"<p>The High Level Library Interface is a unified interface to access system call routines and dynamic memory management functions from application programs. The ExpL language allows applications to access the OS routines only through the library interface. The syntax for the call to the library function in ExpL is :</p> <pre><code>t = exposcall(fun_code, arg1, arg2, arg3);\n</code></pre> <p>Depending on the <code>fun_code</code> the control is transferred to the system call routines (see below) .</p> Library Function / System Call Function Code Argument 1 Argument 2 Argument 3 Return Values Create  \"Create\" File Name (str) Permission (int) - 0  - Success -1 - No Space for file -2 - If the file already Exists Open \"Open\" File Name (str) - - File Descriptor (int) - Success -1 - fFile not found or file is not a data or root file -2 - Process has reached its limit of resources -3 - System has reached its limit of open files Close \"Close\" File Descriptor (int) - - 0 - Success -1 - invalid File descriptor -2 - File locked by calling process Delete \"Delete\" File Name (str) - - 0 - Success -1 - File not found or file is not a data file -2 - File is open -3 - Permission denied Write  \"Write\" -2 Buffer (int/str)* - 0 - Success -1 - File Descriptor given is invalid Seek \"Seek\" File Descriptor (int) Offset (int) - 0 - Success -1 - File Descriptor given is invalid -2 - Offset value moves the file pointer to a position outside the file Read \"Read\" File Descriptor (int) Buffer (int/str)* - 0 - Success -1 - File Descriptor given is invalid -2 - File pointer has reached the end of file Fork \"Fork\" - - - PID (int) - Success, the return value to the parent is the process descriptor(PID) of the child process. 0 - Success, the return value to the child. -1 - Failure, Number of processes has reached the maximum limit. Returns to the parent Exec \"Exec\" File Name (str) - - -1 - File not found or file is of invalid type -2 - Out of memory or disk swap space Exit \"Exit\" - - - - Getpid \"Getpid\" - - - Process Identifier (int) - Success Getppid \"Getppid\" - - - Parent Process Identifier (int) - Success Wait \"Wait\" Process Identifier (int) - - 0 - Success -1 - Given process identifier is invalid or it is the pid of the invoking process. Signal \"Signal\" - - - 0 - Success FLock \"FLock\" File Descriptor (int) - - 0 - Success -1 - File Descriptor is invalid -2 - Permission denied FUnLock \"FUnLock\" File Descriptor (int) - - 0 - Success -1 - File Descriptor is invalid -2 - File was not locked by the calling process Semget \"Semget\" - - - SEMID (int) - Success, returns a semaphore descriptor(SEMID) -1 - Process has reached its limit of resources -2 - Number of semaphores has reached its maximum Semrelease \"Semrelease\" Semaphore Descriptor (int) - - 0 - Success -1 - Semaphore Descriptor is invalid SemLock \"SemLock\"  Semaphore Descriptor (int) - - 0 - Success or the semaphore is already locked by the current process -1 - Semaphore Descriptor is invalid SemUnLock \"SemUnLock\" Semaphore Descriptor (int) - - 0 - Success -1 - Semaphore Descriptor is invalid -2 - Semaphore was not locked by the calling process Shutdown \"Shutdown\" - - - - Newusr \"Newusr\" User name Password - 0 - Success -1 - User already exists -2 - Permission denied Remusr \"Remusr\" User name  - - 0 - Success -1 - User does not exist -2 - Permission denied Setpwd \"Setpwd\" User name New Password - -1 - Unauthorised attempt to change password Getuname \"Getuname\" User ID (int) - - -1 - Invalid UserID User Name - Success Getuid \"Getuid\" User name - - -1 - Invalid Username uid - Success Login \"Login\" User name (str) Password (str) - -1 - Invalid username or password -2 - Permission denied Test \"Test\" Unspecified Unspecified Unspecified - Initialize \"Initialize\" - - - 0 - Success -1 - Failure Alloc \"Alloc\" Size (int) - - Address in the heap allocated (int)  -1 - No allocation Free \"Free\" Pointer (int) - - 0 - Success -1 - Failure <p>Note</p> <p>The Read() and Write() library functions expect a pointer to a memory address from (or to) which read or write is performed.</p> <p>The description of the system calls can be seen here. The dynamic memory management routines are described below.</p>"},{"location":"libinterface/#dynamic-memory-routines","title":"Dynamic Memory Routines","text":""},{"location":"libinterface/#initialize","title":"Initialize","text":"<p>Arguments: None</p> <p>Return Value:</p> 0 Success -1 Failure <p>Description: Intitalizes the heap data structures and sets up the heap area of the process.It is the applications responsibility to invoke Initialize() before the first use of Alloc(). The behaviour of Alloc() and Free() when invoked without an Intialize() operation is undefined. Any memory allocated before an Intialize() operation will be reclaimed for future allocation.</p>"},{"location":"libinterface/#alloc","title":"Alloc","text":"<p>Arguments: Size (int)</p> <p>Return Value:</p> integer Address in the heap allocated -1 No allocation <p>Description: The Alloc operation takes as input an integer, allocates contiguous words equal to the input specified and returns a pointer (i.e., an integer memory address) to the beginning of the allocated memory in the heap.</p>"},{"location":"libinterface/#free","title":"Free","text":"<p>Arguments: Pointer (int)</p> <p>Return Value:</p> 0 Success -1 Failure <p>Description: The Free operation takes a pointer (i.e., an integer memory address) of a previously allocated memory block and returns it to the heap memory pool. If the pointer does not correspond to a valid reference to the beginning of a previously allocated memory block, the behaviour of Free is not defined.</p>"},{"location":"libinterfaceexpl/","title":"High Level Library Interface For expl","text":"<p>The High Level Library Interface is a unified interface to access system call routines and dynamic memory management functions from application programs.</p> Library Function / System Call Function Code Argument 1 Argument 2 Argument 3 Return Values Read \"Read\" File Descriptor (int) Buffer (int/str)* - 0 - Success -1 - File Descriptor given is invalid -2 - File pointer has reached the end of file Write  \"Write\" File Descriptor (int) Buffer (int/str)* - 0 - Success -1 - File Descriptor given is invalid -2 - No disk space -3 - Permission denied Initialize \"Initialize\" - - - 0 - Success -1 - Failure Alloc \"Alloc\" Size (int) - - Address in the heap allocated (int)  -1 - No allocation Free \"Free\" Pointer (int) - - 0 - Success -1 - Failure <p>* foot note regarding buffer</p> <p>The description of the system calls can be seen here. The dynamic memory management routines are described below.</p>"},{"location":"libinterfaceexpl/#dynamic-memory-routines","title":"Dynamic Memory Routines","text":""},{"location":"libinterfaceexpl/#initialize","title":"Initialize","text":"<p>Arguments: None</p> <p>Return Value:</p> 0 Success -1 Failure <p>Description: Intitalizes the heap data structures and sets up the heap area of the process.It is the applications responsibility to invoke Initialize() before the first use of Alloc(). The behaviour of Alloc() and Free() when invoked without an Intialize() operation is undefined. Any memory allocated before an Intialize() operation will be reclaimed for future allocation.</p>"},{"location":"libinterfaceexpl/#alloc","title":"Alloc","text":"<p>Arguments: Size (int)</p> <p>Return Value:</p> integer Address in the heap allocated -1 No allocation <p>Description: The Alloc operation takes as input an integer, allocates contiguous words equal to the input specified and returns a pointer (i.e., an integer memory address) to the beginning of the allocated memory in the heap.</p>"},{"location":"libinterfaceexpl/#free","title":"Free","text":"<p>Arguments: Pointer (int)</p> <p>Return Value:</p> 0 Success -1 Failure <p>Description: The Free operation takes a pointer (i.e., an integer memory address) of a previously allocated memory block and returns it to the heap memory pool. If the pointer does not correspond to a valid reference to the beginning of a previously allocated memory block, the behaviour of Free is not defined.</p>"},{"location":"library-implementation/","title":"Library Implementation","text":""},{"location":"library-implementation/#introduction","title":"Introduction","text":"<p>The ABI stipulates that the code for a common shared library must be linked to the address space of every program. The library code must be linked to logical page 0 and logical page 1 of each program. When an ExpL source program is compiled by an ExpL compiler, the compiler generates code containing calls to the library assuming the library functions will be \"there\" in the address space when the program is eventually loaded for execution. It is the responsibility of the OS loader to do the actual loading of the library. (In technical jargon, the library is said to be linked at compile time and loaded at run time. Unfortunately, there is lack of agreement on terminology in these matters).</p> <p>All calls to the library will be a CALL to logical address 0 of the address space. The library code expects a function code and three arguments to have been pushed into the stack before the call by the application, as described here.</p> <p>To implement the library, you must write code to implement the six library functions \u2013 read, write, exit, Initialize, Alloc and Free. Among these, read, write and exit just involves calling the corresponding system calls using the low-level system call interface described here. The code for the remaining three functions must be implemented in the library.</p> <p>Initialize, Alloc and Free are heap management functions. Each application program has a heap memory region which is attached to logical pages 2 and 3 of the address space. The heap management functions support allocation and de-allocation of dynamic memory. The Initialize function initializes the heap data structures. The library must contain code to allocate and de-allocate memory when requested by the application. In the case of an allocation request, the address of the first memory address of the allocated memory must be returned.</p> <p>Various dynamic memory allocation algorithms exist. A very simple allocation policy would be to always allocate fixed sized memory blocks. The following document discusses this simple allocation scheme and a more complex variable block allocation method called the Buddy System Allocation scheme. In the project, you will be primarily implementing a fixed size allocator. One of the exercises in the roadmap asks you to implement the buddy system allocator.</p> <p>The advantage of using a library for dynamic memory allocation is that this common code can be loaded by the OS during boot time at some memory and can be attached to the address space of every application, saving memory space.</p> <p>Note</p> <p>The library implementation outline given below assumes that the application code will modify only memory addresses acquired using Alloc. If the application modifies heap region that was not allocated to it, the data structures set up by the library functions may get corrupted and the library functions may fail to work properly.</p>"},{"location":"library-implementation/#illustration","title":"Illustration","text":"<p>The following gives an outline of the library implementation.</p> <p>The ABI stipulates that all the library function calls are invoked using CALL 0 instruction. The library differentiates the calls using function code, pushed by the user program on to the stack, before the CALL 0 instruction. The library should read the function code from the stack and jump to the starting address of the corresponding function logic.</p> <p>The following snippet gives the overview of the design of the library.</p> <pre><code>//get function code from stack\n....\n\nMOV R0, &lt;function code&gt;\nMOV R1, R0\nEQ R1, \"Heapset\"\nJNZ R1, &lt;starting address of Initialize&gt;\nMOV R1, R0\nEQ R1, \"Alloc\"\nJNZ R1, &lt;starting address of Alloc&gt;\n....\n\n// code for Initialize\n....\n\nRET\n// code for Alloc\n....\n\nRET\n....\n</code></pre> <p>As shown above, the function code that was pushed by the application program is used to direct the control of the program to the corresponding function logic. In case of Alloc(), Free() and Initialize() calls, the library contains the logic whereas in case of Read() and Write() system calls the library should invoke the kernel using low level system call interface. The appropriate arguments required for the system call can be obtained from the user stack.</p> <p>A detailed explanation on the usage of library interface can be found here.</p> <p>Note</p> <p>As the library is directly loaded by the ExpOS loader, the code should be free of labels and all the jump instructions should have the target memory addresses.</p>"},{"location":"oexpl-data-structures/","title":"Compile Time Data Structure for OExpL","text":""},{"location":"oexpl-data-structures/#class-table","title":"Class Table","text":"<p>OExpL compilation requires only one additional data structure - the class table. The class table stores information pertaining to all the classes declared in an OExpL program. For a class it stores member fields, member functions, name of the class and parent class pointer.</p>"},{"location":"oexpl-data-structures/#structure","title":"Structure","text":"<p>The structure of Class Table(CT) is as follows:</p> <pre><code>struct Classtable {\n  char *Name;                           //name of the class\n struct Fieldlist *Memberfield;        //pointer to Fieldlist\n struct Memberfunclist *Vfuncptr;      //pointer to Memberfunclist\n struct Classtable *Parentptr;         //pointer to the parent's class table\n int Class_index;                      //position of the class in the virtual function table\n int Fieldcount;                       //count of fields\n   int Methodcount;                      //count of methods\n struct Classtable *Next;              //pointer to next class table entry\n};\n</code></pre> <p>Note</p> <p>Memberfield list is used to store the information regarding the type, name, fieldindex and type of class of all the member fields of that class.</p> <pre><code>struct Fieldlist{\n char *Name;   //name of the field\n int Fieldindex;   //position of the field\n struct Typetable *Type;  //pointer to typetable\n struct Classtable *Ctype; //pointer to the class containing the field\n struct Fieldlist *Next;  //pointer to next fieldlist entry\n};\n</code></pre> <p>Memberfunc list is used to store the information regarding the type, name of the function, argument list, it's flabel and it's position.</p> <pre><code>struct Memberfunclist {\n  char *Name;                      //name of the member function in the class\n struct Typetable *Type;          //pointer to typetable\n struct Paramstruct *paramlist;   //pointer to the head of the formal parameter list\n int Funcposition;                //position of the function in the class table\n  int Flabel;                      //A label for identifying the starting address of the function's code in the memory\n struct Memberfunclist *Next;     //pointer to next Memberfunclist entry\n};\n</code></pre>"},{"location":"oexpl-data-structures/#associated-methods","title":"Associated Methods","text":"<ul> <li> <p><code>struct Classtable* CInstall(char *name,char *parent_class_name)</code> :</p> <p>Creates a class table entry of given 'name' and extends the fields and the methods of parent class and returns a pointer to the newly created class entry.</p> </li> <li> <p><code>struct Classtable* CLookup(char *name)</code>:</p> <p>Search for a class table entry with the given 'name', if exists, return pointer to class table entry else return NULL.</p> </li> <li> <p><code>void Class_Finstall(struct Classtable *cptr, char *typename, char *name)</code> :</p> <p>Installs the field into the given class table entry which is given as an argument.</p> </li> <li> <p><code>void Class_Minstall**(struct Classtable *cptr, char *name, struct Typetable *type, struct Paramstruct *Paramlist)</code> :</p> <p>Installs the method into the given class table entry which is given as an argument.</p> </li> <li> <p><code>struct Memberfunclist* Class_Mlookup(struct Classtable* Ctype,char* Name)</code> :</p> <p>Search through the VFunclist of the class using Ctype that is being parsed and return pointer to the entry in the list with function name as Name. Returns NULL if entry is not found.</p> </li> <li> <p><code>struct Fieldlist* Class_Flookup(struct Classtable* Ctype,char* Name)</code> :</p> <p>Search through the Memberfield of the current class using Ctype that is being parsed and return pointer to the entry in the list with variable name as Name. Returns NULL if entry is not found.</p> </li> </ul>"},{"location":"oexpl-data-structures/#illustration","title":"Illustration","text":"<p>Here is an example illustrating it.</p> <pre><code>class\nPerson{\n decl\n  str name;\n  int age;\n  int printDetails();\n  str findName();\n  int createPerson(str name, int age);\n enddecl\n int printDetails(){\n  decl\n  enddecl\n  begin\n   write(self.name);\n   write(self.age);\n   return 1;\n  end\n }\n str findName(){\n  decl\n  enddecl\n  begin\n   return self.name;\n  end\n }\n int createPerson(str name, int age){\n  decl\n  enddecl\n  begin\n   self.name=name;\n   self.age=age;\n   return 1;\n  end\n }\n}     /*end of Person class */\nStudent extends Person{\n\n decl\n  int rollnumber;               /*  The members name and age are inherited from the parent class */\n  str dept;\n  int printDetails();\n  int createStudent(str name, int age,int rollNo, str dept);\n enddecl\n   int createStudent(str name, int age,int rollNo, str dept){\n  decl\n  enddecl\n  begin\n   self.name =name;\n             self.age = age;\n              self.rollnumber = rollNo;\n              self.dept = dept;\n              return 1;\n  end\n }\n int printDetails(){  /* This function is also overridden in the derived class */\n  decl\n  enddecl\n  begin\n   write(self.name);\n   write(self.age);\n   write(self.rollnumber);\n   write(self.dept);\n   return 1;\n  end\n }         /**  The derived class inherits the findName() function from the parent **/\n}  /* end of student class */\nendclass\n</code></pre> <ol> <li>As soon as the compiler encounters the class name, it installs the class name and the parent class name if present into the class table. Subsequently, If there is an extension to the parent class, all the member fields and methods of parent class are inherited. Following is how class table looks when class Person is installed.  </li> </ol> <p></p> <ol> <li>Following is how class table looks when class Student is installed.</li> </ol> <p></p>"},{"location":"oexpl-grammar-outline/","title":"Annotated OExpL Grammar outline","text":"<p>An outline for the OExpL grammar is given here. Calls to functions that update the symbol table, type table, class table and the abstract syntax tree data structures are indicated as semantic actions at certain places.</p> 1. Program TypeDefBlock <pre><code>TypeDefBlock  : TYPE TypeDefList ENDTYPE\n              |\n              ;\n\nTypeDefList   : TypeDefList TypeDef\n              | TypeDef\n              ;\n\nTypeDef       : ID '{' FieldDeclList '}'   { Tptr = TInstall(tname,size,$3); }\n              ;\n\nFieldDeclList : FieldDeclList FieldDecl\n              | FieldDecl\n              ;\n\nFieldDecl    : TypeName ID ';'\n\nTypeName     : INT\n             | STR\n             | ID       //TypeName for user-defined types\n             ;\n</code></pre> ClassDefBlock <pre><code>Program         : TypeDefBlock ClassDefBlock GlobalDeclBlock FuncDefBlock MainBlock\n                ;\n\nClassDefBlock   : CLASS ClassDefList ENDCLASS\n                |\n                ;\nClassDefList    : ClassDefList ClassDef\n                | ClassDef\n                ;\n\nClassdef        : Cname '{'DECL Fieldlists MethodDecl ENDDECL MethodDefns '}'\n                ;\n\nCname           : ID        {Cptr = Cinstall($1-&gt;Name,NULL);}\n                | ID Extends ID {Cptr = Cinstall($1-&gt;Name,$3-&gt;Name);}\n                ;\n\nFieldlists      : Fieldlists Fld\n                |\n                ;\n\nFld             : ID ID ';'  {Class_Finstall(Cptr,$1-&gt;Name,$2-&gt;Name);} //Installing the field to the class\n                ;\n\nMethodDecl      : MethodDecl MDecl\n                | MDecl\n                ;\n\nMDecl           : ID ID '(' Paramlist ')' ';' {Class_Minstall(Cptr,$2-&gt;Name,Tlookup($1-&gt;Name),$4);}\n                                            //Installing the method to class\n                ;\n\nMethodDefns     : MethodDefns FDef\n                | FDef\n                ;\n\nstmt            :    ...\n                | Field ASSIGN Expr ';'\n                ...\n                | ID ASGN NEW '(' ID ')' ';'\n                | Field ASSIGN NEW \u2019(\u2019 ID \u2019)\u2019 ';'\n                | DELETE \u2019(\u2019 Field \u2019)\u2019 ';'\n                ;\n\nExpr            :     ...\n                | Field\n                | FieldFunction\n                ;\n\nField           : SELF '.' ID\n                | ID '.' ID   //This will not occur inside a class.\n                | Field '.' ID\n                ;\n\nFieldFunction   : SELF '.' ID '(' Arglist ')'\n                | ID '.' ID '(' Arglist ')'   //This will not occur inside a class.\n                | Field '.' ID '(' Arglist ')'\n                ;\n\nArgList         : Arglist ',' Expr\n                |Expr\n                |\n                ;\n</code></pre> GDeclBlock <pre><code>GDeclBlock : DECL GDeclList ENDDECL\n           |\n           ;\n\nGDeclList  : GDecList GDecl\n           | GDecl\n           ;\n\nGDecl      : TypeName Gidlist ';'\n           ;\n\nGidlist    : Gidlist ',' Gid\n           |   Gid\n           ;\n\nGid        :   ID                      { GInstall(varname,ttableptr,ctableptr, 1, NULL); }\n           |   ID '(' ParamList ')'      { GInstall(varname,ttableptr,NULL, 0, $3);   }\n           |   ID '[' NUM ']'          { GInstall(varname,ttableptr,NULL, $3, NULL);   } //Arrays are not allowed with class objects.\n           ;\n\nParamList    :  ParamList ',' Param  { AppendParamlist($1,$2);}\n           |  Param\n           |  //There can be functions with no parameters\n           ;\n\nParam        : TypeName ID { CreateParamlist($1,$2); }\n           ;\n</code></pre> <p>Note</p> <ol> <li>The second argument to the function <code>Ginstall()</code> must be a pointer to a type table entry which will be <code>NULL</code> if it is of class type.</li> <li>The third argument to the function <code>Ginstall()</code> must be a pointer to class table entry which will be <code>NULL</code> if it is not of class type.</li> <li>The functions <code>CreateParamlist()</code> and <code>AppendParamlist()</code> help to create a linked list containing the types and names   of parameters specified in an ExpL function declaration. Design of these functions is left to you.</li> </ol> FDefBlock <pre><code>FDefList  : FDefBlock\n          | FDefList FDefBlock\n          ;\nFDefBlock : TypeName ID '(' ParamList ')' '{' LdeclBlock Body '}'  { GUpdate($2-&gt;name,$1,$4,$7,$8); }\n          ;\n\nBody      : BEGIN Slist Retstmt END\n          ;\n\nSlist     : Slist Stmt\n          |\n          ;\n\nStmt      : ID ASGN Expr ';'\n          | ....\n          | IF '(' Expr ')' THEN Slist ELSE Slist ENDIF ';'\n          | ...\n          | ID ASGN ALLOC'(' ')' ';'\n          | FIELD ASGN ALLOC'(' ')' ';'\n          | FREE '(' ID ')' ';'\n          | FREE '(' FIELD ')' ';'\n          | READ '(' ID ')' ';'\n          | READ '(' FIELD ')' ';'\n          | WRITE '(' Expr ')' ';'\n          ;\n\nFIELD     : ID '.' ID\n          | FIELD '.' ID\n          ;\n\nExpr      : Expr PLUS Expr   { $$ = TreeCreate(TLookup(\"int\"),NODETYPE_PLUS,NULL,(union Constant){},NULL,$1,$3,NULL); }\n          | ....\n          | '(' Expr ')'\n          | NUM\n          | ID\n          | ID '[' Expr ']'\n          | FIELD\n          | ID '(' ArgList ')'  {\n                                gtemp = GLookup($1-&gt;name);\n                                if(gtemp == NULL){\n                                    yyerror(\"Yacc : Undefined function\");exit(1);\n                                }\n                                $$ = TreeCreate(gtemp-&gt;type,NODETYPE_FUNCTION,$1-&gt;name,(union Constant){},$3,NULL,NULL,NULL);\n                                $$-&gt;Gentry = gtemp;\n                              }\n          ;\n</code></pre> MainBlock <pre><code>MainBlock : INT MAIN '(' ')' '{' LdeclBlock Body '}'\n                                {\n                                    type = TLookup(\"int\");\n                                    gtemp = GInstall(\"MAIN\",type,0,NULL);\n                                    //...Some more work to be done\n                                }\n          ;\n</code></pre>"},{"location":"oexpl-run-data-structures/","title":"Runtime Data Structures for OExpL","text":""},{"location":"oexpl-run-data-structures/#virtual-function-table","title":"Virtual Function Table","text":"<p>Virtual Function Table is a run time data structure that is used to resolve at run time the call addresses of methods in a class. Such mechanism (or other table schemes) needs to be implemented by compilers for languages that support inheritance, subtype Polymorphism and method over-riding. A run time virtual function table is maintained in the memory for each class. The compiler generates code to initialize the table for each class such that each function that can be invoked from the class has an entry in the table. For each function defined or inherited by a class, the table will contain the call address of the function in the code region of memory. If a function is inherited by a class from its parent and is not over-ridden by the class, the call address stored will be that of the function defined in the parent class. The same address will be stored for the function in the virtual function table of the parent class as well.</p> <p>The OExpL compiler maintains a virtual function table of eight words for each class. Hence, a class can have at most eight member functions. The i-th entry in the table holds the address of the i-th function of the class (identified by the field Funcposition in the class table - see Memberfunclist). While generating code, if there is a call to a function within a class, the compiler simply translates the call to \"CALL [address]\", where address is obtained from the corresponding virtual function table.</p> <p>A simple way to place the virtual function table is to use the initial part of the stack region (starting at memory address 4096), ahead of global variables. This is suggested because the compilation of classes will be finished before compiling the global declarations. In this scheme, the virtual function table of the class defined first in the program will be stored in the region 4096-4103, the second in 4104-4111 and so on.</p> <p>When the compiler encounters the declaration of a variable of a class, it allocates two words of storage for the variable (unlike other variables, where only one word of storage is allocated). The first word is used to store the address of the memory area allocated in the heap for the class (eight words). Space for member fields is allocated in the heap exactly as done with user defined types. We will call this word the member field pointer. The second word is used to store the address of virtual function table. We will call this word the virtual function table pointer.</p> <p>The key point to note here is that the virtual function pointer of a variable need not always point to the virtual function table of the class of the variable. This is because a variable of a parent class can hold a reference to an object of any of its descendant classes. In such cases, the virtual function pointer will hold the address of the descendant class.</p> <p>Hence, an assignment of a variable (of one class) to another variable (of the same class or an ancestor class) results in transfer of the contents of both the pointers of one variable to the corresponding pointers of the other. The new function sets the virtual function table pointer to the address of the virtual function table of the class specified as the argument to the new function. A little bit of thought is necessary to reveal that this implementation will yield the correct execution semantics.</p> <p>A detailed illustration follows.</p>"},{"location":"oexpl-run-data-structures/#illustration","title":"Illustration","text":"<pre><code>class\nA\n{\n  decl\n    int f0();\n    int f1();\n  enddecl\n  int f0() {                   /*Newly defined method*/\n      begin\n       write(\"In class A f0\");\n       return 1;\n      end\n  }\n  int f1() {                   /*Newly defined method*/\n      begin\n        write(\"In class A f1\");\n        return 1;\n      end\n  }\n}                       /*End of Class Definition A*/\nB extends A\n{\n  decl\n    int f0();\n    int f2();\n  enddecl\nint f0() {                    /*f0 of class A is overridden by this method */\n     begin\n       write(\"In class B f0\");\n       return 1;\n     end\n}\nint f2() {                    /*Newly defined method*/\n     begin\n       write(\"In class B f2\");\n       return 1;\n     end\n}\n/* Class B inherits f1 from Class A */\n\n}                       /*End of Class Definition B*/\nC extends B\n{\n  decl\n    int f0();\n    int f2();\n    int f4();\n  enddecl\nint f0() {                /*f0 of Class B is overridden by this method*/\n     begin\n       write(\"In class C f0\");\n       return 1;\n     end\n}\nint f2() {                /*f2 of Class B is overridden by this method */\n    begin\n       write(\"In class C f2\");\n       return 1;\n    end\n}\nint f4() {                /*Newly defined method*/\n    begin\n       write(\"In class C f4\");\n       return 1;\n    end\n}\n\n/*Class C inherits f1 from Class A */\n\n}                        /*End of Class Definition C*/\nendclass\n</code></pre> <ol> <li> <p>Storage for virtual function tables start at 4096 in the stack. Eight consecutive words are allocated for storing the virtual function table of each class. Each word of virtual function table stores the call address of the corresponding function in the class. Thus, a class can contain atmost eight methods. Virtual function tables of various classes are stored in the order in which the classes are declared in the program. As noted earlier, we will allocate the space for global declarations after virtual function tables are allocated.</p> <p>By using the Class_index field of the class_table entry, the starting address of the virtual function table for that particular class can be computed using the formula 4096 + (Class_index * 8). The class defined first will have Class_index zero, the next will have one and so on.</p> </li> <li> <p>When the declaration of each method is found (in a class) a new label is generated for the function and the label is stored in the class table entry (See Memberfunclist ) for the function at compile time. The compiler also must generate code to store these labels into the virtual function table entry of the function in the corresponding class. (Strictly speaking, an integer value called the \"pseudo-address\" for the function is stored in the flabel field of the Memberfunclist entry of the function. The pseudo addresses could be 0,1,2,3 and so on. When code is generated, for functions with flabel values 0,1,2,3, etc., the actual labels placed could be F0,F1,F2,F3 etc to make them more human readable.)</p> </li> <li> <p>It is better to maintain the index of a method in the class table (Funcposition) and the virtual function table to be the same. This makes code generation for method invocations easier. When a method is invoked, the compiler can look up the index of the method from the appropriate class table and generate code to invoke the function whose call address (label) is stored in the virtual function table at the position determined by index.</p> <p>Note</p> <p>that the class table is a static (compile time) data structure and will not be part of the target program. The compiler uses the class table information to generate code that will create the virtual function table at execution (run) time.</p> <p>Note</p> <p>It is sufficient to place labels, and not addresses in the virtual function table, as the label translation phase will take care of translating labels to addresses</p> <p>In the example given, the function f0 in class A has funcposition 0 and say flabel F0 (we identify flabel 0 with F0) and the function f1 in class A gets a funcposition 1 and say flabel F1 (we identify flabel 1 with F1). The member function list of class A looks as shown in the below figure :</p> <p></p> <p>The virtual function table of class A looks as shown in the figure below. It is constructed using member function list of class A which is shown in the figure above.</p> <p></p> <p>As mentioned earlier, all the labels of the functions will be replaced with addresses during label translation phase.</p> </li> <li> <p>Class B extends class A and over-rides f0(). Further, class B contains the newly defined method f2(). When a class extends another, all the member fields and methods of the parent class are inherited by the derived class, unless over-ridden by a new definition. Since the method f0() is over-ridden by B, a new label will have to be allocated for the function f0() in class B. In the present example, we set the new label to F2. Accordingly, the compiler must update Memberfunclist entry of the method f0() in class B with the new flabel value. Correspondingly, in the virtual function table entry for class B, the entry for method f0() must be F2 (over-riding F0). The entry for method f1() (label F1) will be inherited from class A. A new label (label F3 in the example) must be generated for the function f2() defined in class B. The labels for each method in class B is shown in the table below for easy reference.</p> <p></p> <p>From an implementation point of view, it will be easier to (generate code to) copy all the virtual function table entries of A to the virtual function table of B and then (generate code to) modify the labels of over-ridden functions/add labels for new functions defined in B. The compilation for class C may proceed similarly. Note that OExpL specification stipulates that the signatures of the over-ridden methods must match exactly with the signature of the original definition in the parent class.</p> <p></p> <p>\u2605 Overridden labels are marked in red</p> <p>The corresponding virtual function tables of all the classes are shown in the figure given below :</p> <p></p> <p>\u2605 Overridden labels are marked in red</p> </li> </ol>"},{"location":"oexpl-run-data-structures/#runtime-binding","title":"Runtime Binding","text":"<p>Please go through the OExpL Specification - Run time Binding carefully before proceeding further.</p> <p>Consider the OExpL code given below assuming the classes defined above</p> <p><pre><code>decl\n    A obj ;\nenddecl\n\nint main() {\n  decl\n    int temp,n;\n  enddecl\n  begin\n    temp= initialize();\n    read(n);\n    if(n &lt; 0)then\n        obj = new(A);\n    else\n        if(n == 0)then\n            obj = new(B);\n        else\n            if(n &gt; 0)then\n                obj = new(C);\n            endif;\n       endif;\n    endif;\n   write(obj.f0());             /* Have a careful look at this call */\n    return 1;\n  end\n}\n</code></pre> The method invocation within the statement obj.f0() in the above code needs to be analysed carefully. Depending on the run time value of n, the actual function to be invoked will be different. This is because the variable obj will be bound to different classes depending on the value of n. Here we describe what the compiler must do to bind obj to the correct class at run time.</p> <p>We have already noted earlier that, when the compiler encounters the declaration of a variable of a class, it has to allocate two words of storage for the variable (unlike other variables, where only one word of storage is allocated). The first word ( member field pointer ) is to store the address of the memory area allocated in the heap for the class (eight words). The compiler must use the second word ( virtual function table pointer ) to store the address of the virtual function table of the class to which the variable is bound to at run time.</p> <p>For instance, the statement obj = new(A); must result in two actions:</p> <ol> <li>The member field pointer of obj must be set to a newly allocated heap block.</li> <li>The virtual function table pointer of obj must be set to the start address of the virtual function table of class A.</li> </ol> <p>Recall that the start address of the virtual function table for a class can be computed as (4096 + class_index * 8). In the above example, since the class_index of class A is zero, the above statement sets the virtual function table pointer value of obj to the value 4096.</p> <p>Similarly the statement obj=new(B) results in the compiler generating code to store the value 4104 to the virtual function table pointer of the variable obj. obj=new(C) would result in storing the value 4112 to the virtual function table pointer of obj. As an illustration, assume that the compiler has allocated memory address 4120 and 4121 for storing the member field pointer and virtual function table pointer of obj. Assume that a call to the new function results in allocation of 8 words in the heap starting with the memory address 1024 (using the Alloc() library function). The following figure shows how the values of memory locations 4120 and 4121 has to be set for various values of n.</p> <p>if '( n &lt; 0)' then the two words of obj is :</p> <p></p> <p>if '(n = 0)' then the two words of obj is :</p> <p></p> <p>if '(n &gt; 0)' then the two words of obj is :</p> <p></p> <p>In the above code, the value of n is read from the console and is not known at the compile time. Hence, the actual value stored in the virtual function table pointer of obj during run-time cannot be predicted at compile time. Consequently, the actual function invoked by the call obj.f0() cannot be predicted at compile time. This fact forces the compiler to generate code to maintain the virtual function tables at run time.</p> <p>Note that an assignment statement would result in copying the values of both the pointers of the variable on the right side to the variable on the left side.**</p>"},{"location":"oexpl-run-data-structures/#method-invocations","title":"Method Invocations","text":"<p>Consider the statement write(obj.f0()); in the above code. The compiler can resolve the call obj.f0(); by generating code to:</p> <ol> <li>Use the virtual function table pointer field of obj to find the address of the virtual function table of the class to which obj is bound to.</li> <li>Look up the virtual function table to find the address (label) of the function f0().</li> <li>Call the function (of course, after setting up the call stack).</li> </ol> <p>When compiler encounters the method invocation, obj.f0(), it first checks the type of obj - i.e, to which class the obj belongs to. Then it gets the member function list of the class of that object and checks if there is any method with name f0. If it finds a method, it proceeds with the compilation. Otherwise, a compilation error is reported.</p> <p>In more detail, for the call obj.f0(), the compiler must do the following:</p> <ol> <li>Find the index of f0() in the class table entry of obj. Here obj is declared to be of class A and the index (look up Funcposition field in the member function list of class A) of f0() in class A will be 0.</li> <li>Generate the code to push the registers in use into the stack</li> <li>Generate the code to move to a register (say R0) the label of the function at index 0 from the virtual function table of obj. The virtual function table pointer field of obj will point to the virtual function table.</li> <li>Generate code to push the \"self object\" into the stack as argument (i.e., the member field pointer of obj and the virtual function table pointer of obj must be pushed as arguments to the call to f0() - See Run time Stack Management for Method Invocations below .)</li> <li>Generate code to call the function using the label obtained in step 2. (call R0).</li> <li>Generate code to unwind the stack, extract return values upon return from the call and restore registers.</li> </ol> <p>Note</p> <p>The OExpL specification requires that a class can have only a single method of a given name, and the signature of a method inherited from a parent class (over-ridden or otherwise) must be identical with the signature of the method in the parent class. These simplifications allow the above implementation of virtual function tables where, the index of a method in the virtual function tables of every class in a class hierarchy is unique. If method overloading was supported, then there would be multiple functions with the same name within a class, and the implementation would be slightly more involved. (Think what additional stuff needs to be done in that case!)</p>"},{"location":"oexpl-run-data-structures/#run-time-stack-management-for-method-invocations","title":"Run time Stack Management for Method invocations","text":"<p>While generating the code for invoking a method of a class using an object of the class (for example, in the call obj.f0() above, f0() is invoked using the object obj of class A) the member field pointer and virtual function table pointer of the object must be pushed to the stack in addition to normal arguments of the function. We will follow the convention that these two values will be pushed before other arguments are pushed. This is how the runtime stack looks, when a method of a class is called.</p> <p></p> <p>For instance, in the above example, The value of n read from the input is 0, the following figure shows the run time stack. Note that the function f0 has no arguments.</p> <p></p>"},{"location":"oexpl-run-data-structures/#why-do-we-need-to-push-the-object-illustration","title":"Why do we need to push the object? Illustration","text":"<pre><code>class\nA\n{\n  decl\n      int i;\n      int f0();\n      int f1();\n  enddecl\n\n  int f0() {\n    decl\n        int c;\n    enddecl\n    begin\n        c = self.f1();    // call to f1() from f0()\n        write(self.i);\n        return 1;\n    end\n  }\n  int f1() {\n      decl\n      enddecl\n      begin\n          self.i=0;\n          write(\"In A F1\");        // This is printed when f1() is invoked from an object of class A\n          return 1;\n      end\n  }\n}\nB extends A\n{\n  decl\n     int f1();      // B overrides f1\n  enddecl\n\n  int f1() {\n        decl\n        enddecl\n        begin\n            self.i=1;\n            write(\"In B F1\");   // This is printed when f1() is invoked from an object of class B\n            return 1;\n        end\n  }\n}\nendclass\n\ndecl\n  int n;\n  A obj;\nenddecl\n\nint main() {\n  decl\n  enddecl\n  begin\n      read(n);\n      if(n&gt;0) then\n        obj = new(A);\n      else\n        obj = new(B);\n       endif;\n        n = obj.f0();     // f0() contains a call to f1(). f1() is overriden by class B\n        return 1;\n  end\n}\n</code></pre> <p>According to OExpL Specification, a member field or method should be accessed using self. In order to correctly specify the object referred to self, we need to push the object (member field pointer and virtual function pointer) into the stack.</p> <p>Consider the following OExpL program,</p>"},{"location":"oexpl-run-data-structures/#use-of-self-for-member-field-access","title":"Use of self for member field access","text":"<p>Consider the statement self.i = 0 or self.i = 1 . We need to store the value 0 or 1 for the member field i, of the object represented by the self (calling object). In order to identify the object's heap address, the member field pointer of the obj must be available as an argument in the stack.</p>"},{"location":"oexpl-run-data-structures/#use-of-self-for-method-invocations","title":"Use of self for method invocations","text":"<p>Suppose n &gt; 0, then the variable obj will be bound to an object of class A. If n &lt;= 0, then the variable obj will be bound to an object of class B.</p> <p>When the compiler encounters the method invocation obj.f0(), the virtual function table of obj will be looked up to find the call address of the method f0(). Since f0() is defined in class A and not over-ridden by class B, the virtual function tables of both class A and class B will store the same call address for f0().</p> <p>However, inside the method f0(), there is a call to the method self.f1(). Note that f1() is over-ridden by class B. Hence, the call address for the method f1() when obj holds an object of class A will be different from the call address of f1() when obj holds an object of class B. However, the class corresponding to the object stored in obj is determined by the value of n which is not known at compile time. Hence, to generate code for the call obj.f1() inside f0(), the virtual function table of the class to which self is associated must be available as an argument in the stack. Inside f0(), when the compiler translates the call self.f1(), it needs to do the following:</p> <ol> <li>Generate code to look up the virtual function table field of self (received as argument) to find the call address of the function f1().</li> <li>Generate code to invoke f1() using the address obtained (of course, after setting up the call stack).</li> </ol>"},{"location":"oexpl-runtime-binding-tutorial/","title":"OEXPL Run Time Binding Tutorial","text":"<p>Consider the OExpL code given below extending the classes here <pre><code>decl\n    A obj ;\nenddecl\n\nint main() {\n  decl\n    int temp,n;\n  enddecl\n  begin\n    temp= initialize();\n    read(n);\n    if(n &lt; 0)then\n        obj = new(A);\n    else\n        if(n == 0)then\n            obj = new(B);\n        else\n            if(n &gt; 0)then\n                obj = new(C);\n            endif;\n       endif;\n    endif;\n   write(obj.f0());             /* Have a careful look at this call */\n    return 1;\n  end\n}\n</code></pre></p> <p>In the above code, the value of n is read from the console and not known at the compile time.</p> <p>Consider the call write(obj.f0()); in the above code.</p> <p>if (n &lt; 0), the method f0() of the class A is invoked at run time. If (n = 0), the method f0() in the class B is invoked at run time and If (n &gt; 0), the method f0() in the class C is invoked at run time. So, Depending on the value of n, the variable obj must be bound to a different class. Note that the value of n is known only when the program is run (at run time) and not known statically determined (i.e., not known at compile time). Even though the three methods which are overridden has the same name f0(), the call addresses must be different in each case. The information in the virtual function tables will be useful here.</p> <p>We noted earlier that the variable obj has two words of memory assigned to it at compile time - one member field pointer and one virtual function table pointer. At run time, the member field pointer of obj is used to store a pointer to the space allocated in the heap as done for user defined type variables. The virtual function table pointer is used to store the start address of the virtual function table of the class assigned to obj at run time.</p> <p>For instance, the statement obj = new(A); must result in two actions:</p> <ol> <li>The member field pointer of obj must be set to a newly allocated heap block.</li> <li>The virtual function table pointer of obj must be set to the start address of the virtual function table of class A.</li> </ol> <p>Similarly, obj = new(B); must result in setting the virtual function table pointer of obj to the base address of the virtual function table of class B. Consequently, the compiler can resolve the call obj.f0(); by generating code to:</p> <ol> <li>Use the virtual function table pointer field of obj to find the address of the virtual function table of the class.</li> <li>Look up the virtual function table to find the address (label) of the function f0().</li> <li>Call the function (of course, after setting up the call stack).</li> </ol> <p>In more detail, when the compiler encounters the statement obj=new(B); code is generated for the following:</p> <ol> <li>Call the library routine for Alloc to allocate heap memory. The address returned is stored into the member field pointer of obj.</li> <li>Set the virtual function table pointer of obj to the base address of the virtual function table of the class B (i.e, 4104).</li> </ol> <p>Note that before generating code, compile time check whether B is a descendant class of the class of obj (in this case A) must be made.</p> <p>For the call obj.f0(), the compiler must do the following:</p> <ol> <li>Find the index of f0() in the class table entry of obj. Here obj is declared to be of class A and the index (look up Funcposition field in the member function list of class A) of f0() in class A will be 0.</li> <li>Generate the code to move to a register (say R0) the label of the function at index 0 from the virtual function table of obj. The virtual function table pointer field of obj will point to the virtual function table.</li> <li>Generate code to push the \"self object\" into the stack as argument (i.e., the member field pointer of obj and the virtual function table pointer of obj must be pushed as arguments to the call to f0() - See function call convention for methods below .)</li> <li>Generate code to call the function using the label obtained in step 2. (call R0).</li> <li>Generate code to unwind the stack and extract return values upon return from the call. Note that compile time check whether f0() is a method in the class A to which obj is declared to must be done before proceeding to code generation.</li> </ol>"},{"location":"oexpl-runtime-binding-tutorial/#run-time-stack-management-for-method-invocations","title":"Run time Stack Management for Method invocations","text":"<p>While generating the code for invoking a method of a class using an object of the class (for example, in the call obj.f0() above, f0() is invoked using the object obj of class A) the member field pointer and virtual function table pointer of the object must be pushed to the stack in addition to normal arguments of the function. We will follow the convention that these two values will be pushed before other arguments are pushed. This is how the runtime stack looks, when a method of a class is called.</p> <p></p> <p>For instance, in the above example, if the value read from the input is 0, the following figure shows the run time stack.</p> <p></p>"},{"location":"oexpl-runtime-binding-tutorial/#need-for-pushing-the-object","title":"Need For Pushing The Object","text":"<p>According to OExpL Specification, a member field or method should be accessed using self. In order to find out which object we are talking about,when we say self, we need to push the object into the stack.</p> <p>Consider the following OExpL program,</p> <pre><code>class\nA\n{\n  decl\n      int i;\n      int f0();\n      int f1();\n  enddecl\n\n  int f0() {\n    decl\n        int c;\n    enddecl\n    begin\n        c = self.f1();    // call to f1() from f0()\n        write(self.i);\n        return 1;\n    end\n  }\n  int f1() {\n      decl\n      enddecl\n      begin\n          self.i=0;\n          write(\"In A F1\");        // This is printed when f1() is invoked from an object of class A\n          return 1;\n      end\n  }\n}\nB extends A\n{\n  decl\n     int f1();      // B overrides f1\n  enddecl\n\n  int f1() {\n        decl\n        enddecl\n        begin\n            self.i=1;\n            write(\"In B F1\");   // This is printed when f1() is invoked from an object of class B\n            return 1;\n        end\n  }\n}\nendclass\n\ndecl\n  int n;\n  A obj;\nenddecl\n\nint main() {\n  decl\n  enddecl\n  begin\n      read(n);\n      if(n&gt;0) then\n        obj = new(A);\n      else\n        obj = new(B);\n       endif;\n        n = obj.f0();     // f0() contains a call to f1(). f1() is overriden by class B\n        return 1;\n  end\n}\n</code></pre> <p>For obj1, the member field height must be set to 10. For obj2, the member field height must be set to 20.</p> <p>In the method definition for the method setHeight, the member field height is set by using the statement, self.height = a;. By this statement alone, we cannot say which object is self referring to. To identify which object is self referring to, we push the calling object to the stack.</p> <p>If obj1 calls the method setHeight, the member field pointer and virtual function table pointer of obj1 are pushed into the stack. Now, we know that obj1 is calling the method (By looking at the runtime stack). So, we set the member field height of obj1 by using the member field pointer and the field position of member field height. Member field pointer is the heap address given to the object for storing the member fields of the class it is assigned with.</p> <p>The virtual function table pointer is used, when we invoke other methods using self. p = self.setHeight(5); //In the method defaultHeight(). For this we need to generate a CALL instruction. The call address is obtained from virtual function table.</p>"},{"location":"oexpl-specification/","title":"OExpL Specification","text":""},{"location":"oexpl-specification/#introduction","title":"Introduction","text":"<p>An informal specification for a minimal object oriented extension of the ExpL languge with support for Inheritance and subtype polymorphism is outlined here.</p>"},{"location":"oexpl-specification/#class-definitions","title":"Class Definitions","text":"<p>Classes extend the notion of ExpL types. A class encapsulates member fields and member functions (called methods in OOP jargon). The following is an example for a class definition. Standard syntax and semantics conventions followed in languages like Java and C++ are assumed. <pre><code>class Person{\n    decl\n        str name;\n        int age;\n        int printDetails();\n        str findName();\n        int createPerson(str name, int age);\n    enddecl\n    int printDetails(){\n        decl        /*  local variables, if any */\n        enddecl\n        begin\n            write(self.name);\n            write(self.age);\n            return 1;\n        end\n\n    }\n    str findName(){\n        decl\n        enddecl\n        begin\n            return self.name;\n        end\n    }\n    int createPerson(str name, int age){\n        decl\n        enddecl\n        begin\n            self.name=name;\n            self.age=age;\n            return 1;\n        end\n    }\n}   /*end of Person class*/\nendclass    /* end of all class definitions */\n</code></pre> All the class definitions in a program must be placed together, between the keywords class and endclass. Declaration of class variables follow exactly the same syntax as declaration of user defined type variables in ExpL. The member fields of a class must be declared before member functions are declared. Class definitions must be placed after type definitions, but before global declarations. (Further example programs are provided at the end).</p> <p>Since OExpL is designed for pedegogical purposes, the following restrictions are imposed to simplify implementation.</p> <ol> <li>The member fields of a class may be of type integer, string, user defined types, previously defined classes or of the same class. Thus the language supports both Composition and Inheritance.</li> <li>Member fields of a class are private to the class in the sense that they can be accessed only by the methods defined in the class. The language does not permit access modifiers like public or protected.</li> <li>Class variables can be declared only globally. Class variables cannot be arguments to functions; a function cannot have a class as its return type and class variables cannot occur as local variables within functions.</li> <li>All the member fields and methods should be declared between decl and enddecl.</li> <li>In methods defined within a class, the special keyword self refers to the instance of the class through which the method was invoked. ( The usage is similar in spirit to this in C++. )</li> <li> <p>The methods defined in a class may have parameters as well as local variables. The syntax and semantics rules are similar to other ExpL functions. However, there are some important differences:</p> <ol> <li> <p>Methods of a class, apart from its arguments and local variables, have access only to the member fields of the corresponding class.</p> </li> <li> <p>A method can invoke only functions of the same class or functions inherited from its parent class or methods of class variables occuring as member fields of the class. (Be aware of the fragile base class problem).</p> </li> </ol> </li> </ol> <p>To put in short</p> <ol> <li>class variables can only be global.</li> <li>Member functions of a class can access only its member fields, methods, local variables, arguments and methods of member fields.</li> <li>Member fields of a class can be accessed from outside only through member functions of the class.</li> </ol>"},{"location":"oexpl-specification/#inheritance","title":"Inheritance","text":"<p>The language supports class extension. A class defined by extension of another class is called a derived class (or child class) of the parent class (sometimes called the base class). The following example demonstrates the syntax of class extension. The language does not support multiple inheritance .</p> <p><pre><code>class Person{\n    decl\n        str name;\n        int age;\n        int printDetails();\n        str findName();\n        int createPerson(str name, int age);\n    enddecl\n    int printDetails(){\n        decl\n        enddecl\n        begin\n            write(self.name);\n            write(self.age);\n            return 1;\n        end\n    }\n    str findName(){\n        decl\n        enddecl\n        begin\n            return self.name;\n        end\n    }\n    int createPerson(str name, int age){\n        decl\n        enddecl\n        begin\n            self.name=name;\n            self.age=age;\n            return 1;\n        end\n    }\n}     /*end of Person class */\nStudent extends Person{\n\n    decl\n        int rollnumber;               /*  The members name and age are inherited from the parent class */\n        str dept;\n        int printDetails();\n        int createStudent(str name, int age,int rollNo, str dept);\n    enddecl\n    int createStudent(str name, int age,int rollNo, str dept){\n        decl\n        enddecl\n        begin\n            self.name =name;\n                self.age = age;\n                    self.rollnumber = rollNo;\n                    self.dept = dept;\n                    return 1;\n        end\n    }\n    int printDetails(){  /* This function is also overridden in the derived class */\n        decl\n        enddecl\n        begin\n            write(self.name);\n            write(self.age);\n            write(self.rollnumber);\n            write(self.dept);\n            return 1;\n        end\n    }         /**  The derived class inherits the findName() function from the parent **/\n}  /* end of student class */\nendclass\n</code></pre> The semantics of class extension can be summarized as follows:</p> <ol> <li>The derived class inherits all member fields of the parent class automatically. If additional fields are defined, they will be specific to the derived class. The derived class cannot re-declare a member field already declared in the parent class.</li> <li>The derived class inherits only those methods of the parent class which are not re-defined (overridden). If a method is overridden, the new definition will be the only valid definition for the derived class. All the overridden methods must be declared again in the derived class. The signature of the overridden method must match exactly in both number and types of arguments with the signature of the function in the parent class. Only one function of the same name is permitted in a class. Thus, the language does not permit function overloading.</li> </ol>"},{"location":"oexpl-specification/#class-variables-and-instantiation","title":"Class variables and Instantiation","text":"<p>Class variables are declared just like other variables in the global declaration section after type definitions and class definitions.</p> <p>Example: <pre><code>/* Type definitions */\n/* Class definitions */\n\n decl\n    int n,temp;\n    str name;\n    Person first;\n    Student second;\n    Person arbitrary;\n enddecl\n</code></pre></p> <p>Object instance is created for a variable of a class with the built-in function new. The language does not support constructors and destructors. Hence intitialization of objects has to be done explicitly. An object can be deallocated using the built-in function delete. The function new will create an object of a specified class at run time, and assigns a reference to the object into a variable. A variable of a given class may be assigned a reference to an object of any desendent class using new. Access semantics of class variables is similar to ExpL user-defined-types, except for the details associated with methods defined within classes. These details are described below.</p>"},{"location":"oexpl-specification/#subtype-polymorphism","title":"Subtype Polymorphism","text":"<pre><code>begin\n    n = initialize();\n    first=new(Person);\n    temp = first.createPerson(\u201cRogers\u201d, 37);               /* invokes method in class person */\n    second=new(Student);\n    temp = second.createStudent(\u201cMathew\u201d, 35, 999, \u201cCS\u201d);  /*invokes method in class student */\n    name = first.findName();                              /* invokes method in class person */\n    name = second.findName();                             /* invokes inherited method in class person */\n    delete(first);\n    delete(second);\nend;\n</code></pre> <p>A variable of a parent class can refer to any object in its inheritance hierarchy. That is, if class B extends class A and class C extends class B, then a variable of class A can refer to objects of classes A, B or C, whereas a variable of class B can refer to any object of class B or C. (References are set using the ExpL assignment statement in the normal way, as with user defined types. The function new can also be used to set the reference for a variable). When a method is invoked with a variable of class B or C, if the method is inherited from an ancestor class, the ancestor's method is invoked. This is illustrated by the following examples.</p>"},{"location":"oexpl-specification/#run-time-binding","title":"Run time Binding","text":"<p>Suppose that a variable declared to be of a parent class in an inheritance hierarchy holds the reference to an instance of a derived class. On invocation of a method of the parent class variable, if the method is over-ridden by the derived class, the method of the derived class is invoked.</p> <p>This pivotal feature of object oriented programming compilcates the compiler implementation because at the time of generating code for a method invocation, the correct method to call may not be known, as illustrated in the example below. <pre><code>begin\n    n = initialize();\n    first=new(Person);\n    temp = first.createPerson(\u201cRogers\u201d, 37);              /* invokes method in class person */\n    second=new(Student);\n    temp = second.createStudent(\u201cMathew\u201d, 35, 999, \u201cCS\u201d); /*invokes method in class student */\n    read(n);                                             /* The run time value of n is not known at compile time */\n    if (n&gt;0) then\n        arbitrary = first;\n    else\n        arbitrary = second;\n    endif;\n    n = arbitrary.printDetails();                        /* Function not determined at compile time */\n    delete(first);\n    delete(second);\n end;\n</code></pre></p> <p>In the above code, the value of the variable n read from the input at run-time determines whether the variable arbitrary refers to an object of the class - person or the class - student. Consequently, at compile time, we cannot decide whether the call arbitrary.printDetails() must be translated to an invocation of the function in the parent class or the child class.</p> <p>To resolve such function invocations, the method of dynamic binding must be implemented using the The virtual function table method .A tutorial explaining the implementation of virtual function tables is given here .</p> <p>Important note</p> <p>If a variable of a parent class holds the reference to an object of a descendent class, only methods defined in the parent class are allowed to be invoked using the variable of the parent class.</p>"},{"location":"oexpl-specification/#sample-programs","title":"Sample Programs","text":"<p>Example Programs are here.</p>"},{"location":"oexpl-specification/#appendix","title":"Appendix","text":"<p>Keywords</p> <p>The following are the reserved keywords in OExpL and it cannot be used as identifiers.</p> class endclass extends new delete self"},{"location":"oexpl-testprograms/","title":"OEXPL TEST PROGRAMS","text":""},{"location":"oexpl-testprograms/#test-program-1-binary-search-tree","title":"Test Program 1 : Binary Search Tree","text":"<p>This test program inserts elements into a binary search tree and prints the elements in inorder, preorder and postorder traversal. The program stops taking input elements (that are to be inserted in Binary Search Tree) when the user enters 0.</p> <p>Input : The elements that are to be inserted into a Binary Search Tree and a 0 at last (indicating the end of input).</p> <p>Output : The inorder, preorder and postorder traversal of the tree.</p> <p>This program test the iteration, recursion, conditional, arrays and passing of user-defined datatype as return value of function.</p> <p>The code for the test progam can be found here</p>"},{"location":"oexpl-testprograms/#test-program-2-linked-list","title":"Test Program 2 : Linked list","text":"<p>This test program reads elements into a linked list and prints them.</p> <p>Input : Value of length of list and list of values from standard input.</p> <p>Output : The list of values stored in linked list.</p> <p>This program test the working of dynamic memory allocation functions like Initialize(), Alloc() and Free().</p> <p>The code for the test progam can be found here</p>"},{"location":"oexpl-testprograms/#test-program-3-sum-of-factorials","title":"Test Program 3 : Sum of Factorials","text":"<p>This test program reads an element and finds the sum of factorials of all the numbers till that element.</p> <p>Input : Value of n.</p> <p>Output : Sum of factorials of all the numbers till n.</p> <p>This program tests the declaration of a member field which is an object of another class. This program also tests the recursion, parameter passing, calling a function inside the call of another function.</p> <p>The code for the test progam can be found here</p>"},{"location":"oexpl-testprograms/#test-program-4","title":"Test Program 4","text":"<p>This program tests the runtime binding of the variables of a class.</p> <p>Input : If any input &gt; 0</p> <p>Output : In A F1 0</p> <p>Input : If any input &lt;= 0</p> <p>Output : In B F1 1</p> <p>This program uses the concepts of inheritance and subtype polymorphism.</p> <p>The code for the test progam can be found here</p>"},{"location":"oexpl-testprograms/#test-program-5","title":"Test Program 5","text":"<p>This program tests the correct set up of the virtual function table by the compiler.</p> <p>Input : If n &lt; 0</p> <p>Output : In A F0</p> <p>Input : If n == 0</p> <p>Output : In B F0</p> <p>Input : If n &gt; 0</p> <p>Output : In C F0</p> <p>This program uses the virtual function table, inheritance and subtype polymorphism.</p> <p>The code for the test progam can be found here</p>"},{"location":"oexpl-testprograms/#test-program-6","title":"Test Program 6","text":"<p>This program tests the implementation of inheritance and subtype polymorphism.</p> <p>Input : 1 length breadth</p> <p>Output : length * breadth</p> <p>Input : 2 length</p> <p>Output : length * length</p> <p>This test program uses the concepts of inheritance.</p> <p>The code for the test progam can be found here</p>"},{"location":"oexpl-testprograms/#test-program-7","title":"Test Program 7","text":"<p>This program tests the implementation of inheritance and subtype polymorphism.</p> <p>Input : &gt; 0</p> <p>Output : Rogers 37</p> <p>Input : &lt;= 0</p> <p>Output : Mathew 35 999 CS</p> <p>This program tests the concepts of inheritance, subtype polymorphism and virtual function table.</p> <p>The code for the test progam can be found here</p>"},{"location":"oexpl/","title":"OExPL","text":"<p>OEXPL</p> <p>This page is under development</p>"},{"location":"run-data-structures/","title":"Run Time Data Structures","text":""},{"location":"run-data-structures/#introduction","title":"Introduction","text":"<p>This document explains how the compiler allocates memory for variables in a program. First it is necessary to understand the requirements and the underlying theoretical concepts in some detail.</p>"},{"location":"run-data-structures/#the-storage-allocation-problem","title":"The storage allocation Problem","text":"<p>A program contains global variables as well as variables that are local to functions, both requiring memory space. Of these, global variables are the simplest to handle because during the analysis phase we know how many global variables are there in the program (all global variables are declared) and how much space needs to be allocated for each of them (why?). Thus, the storage requirements for global variables are completely determined at compile time and they can be assigned memory addresses during the analysis phase itself. Such allocation is called static allocation. The binding field of the global symbol table entry for a variable is set to the memory address allocated to the variable. This symbol table information will be used during the code generation phase to find out the address of the variable in memory.</p> <p>During the analysis phase the compiler will not decide on the addresses in the code area of memory where a function's code is loaded. Hence, the compiler cannot fix the address to which function must be attached. To handle this issue, the compiler will assign a pseudo address to each function, which will be stored in the binding field of the function's global symbol table entry. All calls to the function will be translated to an assembly level call to this pseudo address. The correct addresses will be assigned later during label translation.</p> <p>Variables which are local to functions demand more complicated allocation. This is because a function may be invoked several times and for each invocation, separate storage needs to be allocated for variables defined within the scope of the function (i.e., local variables and arguments).\u00a0 [Why?] Moreover, we do not know during the analysis phase how many times a function will be invoked during the execution. Why?</p> <p>To understand this, consider the factorial program below.</p> <pre><code>decl\n    int result,factorial(int n);\nenddecl\nint factorial(int n){\n    decl\n        int f;\n    enddecl\n    begin\n        if( n==1 || n==0 ) then\n            f = 1;\n        else\n            f = n * factorial(n-1);\n        endif;\n        return f;\n    end\n}\nint main(){\n    decl\n        int a;\n    enddecl\n    begin\n        read(a);\n        result = factorial(a);\n        write(result);\n        return 1;\n    end\n}\n</code></pre> <p>The function factorial contains an argument 'n'. Suppose the initial value of 'n' input by the user at run time was 5, then factorial(n) with n=5 is invoked from the main. This function invokes factorial(n) with n=4. However, we need to retain the old value of n since the orginal factorial function must resume execution after the completion of factorial(4). Thus, we cannot statically assign a fixed memory address to the variable n. Instead, for each invocation of the function, we need to create a different memory space for storing the value of n. Moreover, the initial value of n given by the user is not known at compile time. Hence, we cannot determine at compile time the exact storage requirements. The compiler should generate code in such a way that necessary memory space is allocated at run time as required.</p> <p>In addition to allocating storage for local variables and arguments, additional storage needs to be allocated at run time for each invocation of a function to store the return values of the call and control information like a pointer to the next instruction in the calling function (return address).</p> <p>The classical solution to handle the above problem is to maintain a run time stack. Whenever a function is invoked during execution, an activation record is created in the run time stack with sufficient space for storing local variables, arguments, return values and return address, and the stack grows. Upon return from the function, the activation record is popped out of the stack and the stack shrinks, leaving the activation record of the calling program at the top of the stack. Thus, at each point during execution, the activation record of the currently executing function will be on the top of the stack. Such storage allocation is called stack based run time allocation.</p> <p>[Note: The semantics of ExpL makes stack based allocation possible. Primarily, this is possible because data stored in an activation record can be forgotten once the execution of the call is finished. There are languages like LISP which permit higher order functions where a stack based run time allocation is not possible. Languages which permit stack based run time allocation for function invocations are said to follow stack discipline.]</p> <p>Observe that for each function defined in an ExpL program, the amount of storage needed in its activation record is known during the analysis phase. [Why?] What is not known is how many activation records will have to be created in the stack as this is known only during execution time.</p> <p>In addition to allocating storage for global variables and variables local to functions, ExpL supports dynamic memory allocation through the alloc() function. The alloc() function allows a program to request for memory space at run time. Since the amount of memory requested is not known during the analysis phase (why?), static allocation is not possible in this case. Stack allocation also is ruled out because memory allocated by alloc() inside a function is not de-allocated when the function returns. Hence, a mechanism to dynamically allocate memory on demand at run time is required.</p> <p>The classical solution to this problem is to maintain a contiguous area of memory called the heap memory from which memory is allocated by alloc() on demand. Heap management algorithms like the fixed size allocator algorithm and the buddy system algorithm are explained in detail later in this documentation.</p> <p>Finally, intermediate values generated during program execution needs temporary storage. For example, while evaluating an expression (a+b)*(c+d), the values of the sub-expressions (a+b) and (c+d) might need temporary storage. The machine registers are used for temporary storage. When a function invokes another function, the registers in current use will be pushed to the stack (activation record of the caller) so that the called function (callee) has the full set of registers free for its use. Upon return from the callee, the values pushed into the stack are restored to the registers before the caller resumes its execution.</p> <p>To summarize, we have four kinds of memory allocation \u2013 static, stack, heap and register (temporary). The implemention of each of these are discussed below.</p>"},{"location":"run-data-structures/#the-memory-model","title":"The memory model","text":"<p>The compiler assumes an address space model for the target program, determined by the target machine architecture as well as the target operating system.</p> <p>The memory model provided for application programs running on the Experimental Operating System(eXpOS) for the XSM machine architecture is explained below. For further details, see the Application Binary Interface(ABI) Specification documentation.</p> <p></p> <p>The figure shows that the target code generated by the compiler will be loaded to memory addresses 2048 to 4095 (total 2048 memory words). Since each XSM instruction occupies two memory words, the target program can have at most 1024 machine instructions.</p> <p>Since the XEXE executable format stipulated in the eXpOS ABI does not provide separate memory areas for static and run time data, the compiler must allocate both static variables and run time stack between memory addresses 4096 and 5119. The recommended convention is to allocate global variables in the initial portion of this memory and then the run time stack may be initialized to the top of this data so that it can grow upward during run time. Note that the target program must contain instructions to initialize the run time stack. This is because eXpOS does not initialize the stack pointer when the program is loaded for execution. The OS instead expects the loaded executable to contain instructions to set up the stack.</p> <p>When an XEXE executable file is loaded by the OS into the memory, the OS loader will link a collection of pre-loaded routines in memory (called the library to the address space of the newly loaded program. These routines include the dynamic memory routines - alloc(), free(), Initialize() and input-output routines read() and write(). This makes compiler design easy because the compiler just has to translate any high level invocation of the above functions to low level calls to the corresponding library routines. The details of how to generate code to invoke library routines is specified in the library interface. [Note 1: You can design and implement the library routines yourself in ExpL and install your library routines into the OS so that OS uses your routines as its library.] [Note 2: The first eight words of an XEXE executable contains a header. One of the fields in the header is a library flag. While preparing the executable file, the compiler must set this flag bit to tell the OS loader that the library must be linked to the address space at the time of loading the program] The library routines for alloc(), free() and initialize() as implemented in eXpOS library uses the heap region in the address space for managing dynamic memory. Hence, the compiler must not allocate its own variables in this space. The static and runtime memory allocation by the compiler can instead use the stack region, as described previously.</p> <p>Finally, the XSM machine provides 20 registers R0-R19 for storing temporary values. The machine requires operands to be loaded to registers before doing arithmetic/logical operations.</p> <p>In the following, we describe how activation records are allocated in the stack, how the library routines for Alloc() and Free() must manage heap memory and how the compiler may allocate registers for temporary storage.</p>"},{"location":"run-data-structures/#temporary-allocation","title":"Temporary Allocation","text":"<p>Register allocation is performed through two simple functions. int get_register()...</p> <p>Read more</p>"},{"location":"run-data-structures/#static-allocation","title":"Static Allocation","text":"<p>Global variables are allocated statically. In our interpreter, the initial portion of the stack will be used for ....</p> <p>Read more</p>"},{"location":"run-data-structures/#run-time-stack-allocation","title":"Run time Stack Allocation","text":"<p>During run-time, when an ExpL function is invoked, space has to be allocated for storing the arguments of a function, return value...</p> <p>Read more</p>"},{"location":"run-data-structures/#heap-allocation","title":"Heap Allocation","text":"<p>ExpL specification stipulates that variables of user defined types are allocated dynamically using the alloc() function. The alloc() function has the following syntax: .... Read more</p>"},{"location":"xsm-environment-tut/","title":"XSM EXECUTION ENVIRONMENT TUTORIAL","text":"<p>Prerequisites</p> <p>A quick reading of the ExpOS ABI documentation for XSM machine. You may not understand the whole content now. The details will be explained as you read ahead.</p> <p>Learning Objectives</p> <p>At the end of this tutorial you will be able to generate XEXE executable files containing XSM assembly language programs which can be run on the XSM simulator given to you. Along the way, you will learn how to use the system call interface and the library interface of the underlying Operating system to handle console input and output.</p> <p>This tutorial helps you to gain a basic understanding of the execution environment provided by the XSM simulator. The compiler you design for the ExpL language is supposed to generate target XSM machine code that runs on the XSM Simulator provided to you. However, the bare machine cannot directly run the target code. The operating system (OS) that runs on top of the machine is the actual software that sets up an execution enviornment necessary for running the target code. Hence, the compiler's obligation is to generate target code that is understandable to the operating system.</p> <p>Consequently, there must be a document provided by the OS implementation to the compiler designer that explains the interface to the operating system that the compiler must adhere to. This document is called the Application Binary Interface or ABI.</p> <p>The XSM simulator given to you is actually much more than a bare XSM hardware simulator. It has the capacity to understand the ABI for the ExpOS operating System for the XSM machine. This ABI expects that the compiler generates the target file in a format called the XEXE executable format.</p> <p>Your compiler simply needs to generate an executable file following the XEXE executable format and store it on the local machine. When you use the XSM simulator to run the program, the following actions take place.</p> <ul> <li>1. The script that runs the simulator transfers the file from your local machine's disk to the XSM machine's (simulated) hard disk.</li> <li>2. It then boots up the operating system (the OS is already preloaded in the simulator's hard disk). The bootstrap loader starts in the kernel mode and sets up a user process in memory, allocating an address space. Then, it transfers the executable file from the hard disk to the code region of this memory. Page tables are also set up to run the process in user mode.</li> <li>3. Finally, the simulator sets the instruction pointer (IP) to the address specified in the entry-point field of the header of the executable file and control transfers to this instruction, resulting in execution of the loaded program starting with the instruction specified by the entry point. The machine also switches from the kernel mode to the user mode. (Technically, the OS code pushes the entry point address on to the program's stack and executes the IRET instruction resulting in transfer of control in user mode to the specified memory address. These details are not relevant for your work and are noted just for the sake of information.)</li> </ul> <p>We start now by generating a small XEXE executable file containing an XSM program to find the sum of two numbers and store the value in a register. The value of the register will have to be inspected in order to view the ouput. This is possible by executing the XSM simulator in debug mode. Later we will see how console input and output are handled.</p>"},{"location":"xsm-environment-tut/#experiment-i-adding-two-numbers-using-registers","title":"Experiment I : Adding two numbers using registers","text":"<p>As noted above, executable programs must be designed in such a way that it must be possible for the file to be loaded and executed by the underlying operating system. When a program is loaded into memory by the OS, the OS typically assigns a virtual address space (or simply an address space). In the present case, the address space of a program starts at address 0 of the memory and ends at address 5119. This means that while designing the target program, you may assume that this is the total computer memory accessible to the program.</p> <p>The compiler typically divides this memory into various regions \u2013 namely the code region, (often called the text region), data region, stack region, heap region etc. The ABI specifies the starting address and ending address of each region in the address space. This is specified HERE. The ABI specifies that the compiler must divide the memory into four regions \u2013 library, code, stack and heap. (there is no separate data region \u2013 instead the stack region must be used for this as well).</p> <p>For our immediete requirements, the important region is the code region. The code region contains two parts \u2013 a header (addresses 2048 to 2055) and code (address 2056-4095). The target code will be loaded into this region of the memory when the OS (simulator) loads the program for execution. Details will be described soon.</p> <p>The XEXE executable format stipulates that the first 8 words of an executable file must be a header. The rest of the file must contain assembly language program to be executed. The loader actually will simply copy the contents of the executable file into the region of memory between addresses 2048 and 4095. Consequently, the header will be loaded between 2048-2055 and the rest of the file (containing the XSM instructions) into addresses 2056 to 4095. The contents of the file will be copied to the memory in the order in which they appear in the file.</p> <p>Since each XSM assembly instruction requires two words of memory storage, the first instruction will be loaded into address 2056 and 2057, the second in 2058 and 2059 and so forth. Since the code region of the memory ends at 4095, the maximum number of instructions possible in a program is limited to 1020. This is the limit set by the particular OS platform used in this experiment.</p> <p>One important field of the header is its second entry \u2013 the entry point. The loader initializes the Instruction Pointer (IP) register of the XSM machine to this value. Thus, if entry point is 2064, the simulator the XSM machine simulator will start program execution by fetching the instruction stored at this address. The ABI stipulates that the value of the first field called the magic number must be set to zero. The setting of other fields in the header are not relevant for this experiment.</p> <p>Note: When the program is actually loaded for execution by the OS, the physical addresses in the actual memory to which the executable program is loaded will be different from the virtual addresses set by the compiler. Such relocation requires architecture support. In the XSM machine, the support is through paging. However address translation is a concern of the OS, not of the compiler. Hence we will not pursue this matter here. However, for those interested, details on XSM paging scheme is given HERE.</p> <p>With this, we complete the background needed to complete the present experiment. We now proceed to the implementation.</p>"},{"location":"xsm-environment-tut/#implementation","title":"Implementation","text":"<p>An XSM assembly language program to find the sum of two numbers could work as the following:</p> <pre><code>1. Store the first number in a register \u2013 say R0.\n2. Store the second number in a register \u2013 say R1.\n3. ADD R0, R1.\n</code></pre> <p>The result will be stored in R0. To generate code for the above tasks and write it into a target_file, you must write code as:</p> <pre><code>fprintf(target_file, \"BRKP\");\nfprintf(target_file, \"MOV R0, 3\\n\");\nfprintf(target_file, \"MOV R1, 2\\n\");\nfprintf(target_file, \"ADD R0, R1\\n\");\n</code></pre> <p>The <code>target_file</code> will look as shown below.</p> <pre><code>BRKP\nMOV R0, 3\nMOV R1, 2\nADD R0, R1\n</code></pre> <p>However, the header must be written into the first eight words of the target file before writing out the instructions. You must reserve the first eight words of the executable file for the header before writing code into the file. Now, set the entry point field to the first instruction to be executed. If the code is written immedietely after the header, the first instruction will be loaded to memory address 2056 and 2057 (see memory model). Hence, you must set the header as:</p> <pre><code>fprintf(target_file, \" %d\\n %d\\n %d\\n %d\\n %d\\n %d\\n %d\\n %d\\n \",0,2056,0,0,0,0,0,0);\n</code></pre> <p><code>target_file</code> after adding header</p> <pre><code>0\n2056\n0\n0\n0\n0\n0\n0\nBRKP\nMOV R0, 3\nMOV R1, 2\nADD R0, R1\n</code></pre> <p>The above code essentially sets the first field \u2013 magic number - to 0, the second field - entry point - to 2056 and other fields to 0.</p> <p>Now, to run the executable file, you must use the XSM simulator. The simulator usage commands are specified here. You must read the above link before proceeding further.</p> <p>The simulator expects a library file by the name library.lib together with the XEXE executable file to be supplied as a command line argument. You will learn more about the library in later in this documentation. For now create a file library.lib with just one instruction in the XSM simulator folder.</p> <pre><code>RET\n</code></pre> <p>Now we will try to execute the target_file in the debug mode.</p> <ol> <li>Open terminal and navigate to the simulator folder.</li> <li>Type <code>./xsm -l library.lib -e &lt;path to target_file.xsm&gt; --debug</code>.</li> </ol> <p>Note</p> <p>Path to the xsm file need to be relative path.</p> <p>Since we are trying to execute the <code>target_file</code> in debug mode, the simulator executes all the instructions present before the <code>BRKP</code> instruction. We will look at the status of register R0 before the execution of instruction <code>MOV R0, 3</code>.</p> <p></p> <p>Type <code>s</code> and then type <code>reg R0</code>.</p> <p></p> <p>We can see that value 3 is stored in this register. Now try typing <code>s</code> and then <code>reg R1</code>.</p> <p></p> <p>Type <code>s</code> and then type <code>reg R0</code>.</p> <p></p> <p>We can see that value stored in the register is 5. Now type <code>reg R0 R1</code></p> <p></p> <p>The command <code>reg Rn Rm</code> dislays the contents of all registers from <code>n</code> to <code>m</code>.</p> <p>Now type <code>reg</code>.</p> <p></p> <p>This command displays the contents of all the machine registers namely IP, SP, BP, PTBR, PTLR, EIP, EC, EPN, EMA, R0-R19 in that order. We will not be concerned with PTBR, PTLR, EIP, EC, EPN and EMA registers which are accessible only to the OS kernel executing in previliged mode. Note that the value of IP register is 2064. IP was initialized to 2056 while loading (entry point value) and after executing four instructions, IP got incremented to 2064. The OS kernel had set SP to point 4095 at load time (why?).</p> <p>Note</p> <p>You would have observed that if you try to continue to execute beyond the last instruction, the simulator flags abnormal program termination. This is because after executing the last instruction of the program, the simulator increments the instruction pointer and tries to execute the next instruction. However, since there is no valid instruction stored in the memory, the simulator will enconter an invalid instruction and generate an exception. This results in transfer of program control to the OS kernel code that will terminate execution and report error. We will see how graceful program termination is achieved in the next experiment.</p> <p>Exercise 1</p> <p>Write an XSM assembly langauge program to find the largest of three numbers and run it on the simulator. You will learn how to handle the JMP instruction while doing this exercise.</p> <p>Exercise 2</p> <p>Modify your code generation module to store the result of the previous program in the first location in stack region namely address 4096 and watch the contents in debug mode after execution.</p>"},{"location":"xsm-environment-tut/#experiment-ii-inputoutput-using-os-system-call-interface","title":"Experiment II : Input/Output using OS system call interface","text":"<p>Reading Assignment</p> <p>Read the low level system call interface of the ABI</p> <p>In this experiment, you will extend the previous stage to print the result of adding two numbers to the console using the low level system call interface provided by the ABI.</p> <p>The conceptual point to understand here is that console I/O is handled by the kernel routines of the operating system. Kernel modules execute in privileged mode of execution and can execute special privileged instructions that access devices and other resources in a machine.</p> <p>However, your XEXE executable program execute in unprivileged mode. Such programs are called application programs or simply applications. These programs cannot contain privileged instructions. (If you try to write privileged instruction in your program and execute, the machine will raise an exception when it fetches the instruction and the exception handler module of the OS kernel will terminate the application, flagging an error.) The instructions specified in the ABI given to you are all unprivileged instructions. (To know more about privileged instructions in XSM, see ExPOS documentation).</p> <p>An OS typically provides you with a set of kernel level routines called system calls which your code can invoke for performing console I/O. A system call is invoked by a trap instruction (The INT instruction is the trap instruction of the XSM machine). Arguments like the system call number specifying the particular OS service (like read/write/program exit) and so on are required. (see details here). The OS specifies how an application must pass arguments and extract return values from system calls called the calling conventions. Generally, arguments to a system call are passed through the application program's stack. These details are written down in the low level system call interface of the ABI.</p> <p>Note</p> <p>An OS typically will provide a large number of system calls for various requirements. For our purposes, the relevant system calls are those for console read, console write and program exit.</p> <p>As noted previously, the arguments/return values to/from a system call are passed through the application program's stack. Each application maintains a stack region in memory where run-time data can be stored while the program executes. The ABI specification stipulates that the stack region of a program shall be between memory addresses 4096 and 5119. The application generally reserves some initial addresses starting from 4096 for storing global variables in the program (called static allocation) and then initializes the stack to the first free memory after those allocated to variables. Arguments to a system call are pushed into the stack before executing the INT instruction. Before the system call transfer control back (using the IRET instruction), return values would have been pushed into the stack.</p>"},{"location":"xsm-environment-tut/#implementation_1","title":"Implementation","text":"<p>In Experiment I above, you were asked to calculate the sum of two numbers which are stored in registers. Now, we will see how this number can be printed out into the console.</p> <p>To print the data into the console, we need to:</p> <ol> <li>Push the data(using registers) into the stack along with other arguments to the system call.</li> <li>Invoke the write system call using the INT instruction specifying the appropriate interrupt number.</li> </ol> <p>To use the stack we need to set the stack pointer(SP). Always SP should point the top value of the stack. The XSM machine increments SP immedietely before a PUSH operation by XSM machine and hence the first PUSH operation will be storing data to address 4096. So, we need to initialize SP to 4095.</p> <pre><code>MOV SP, 4095\n</code></pre> <p>Now, the arguments to a write operation must be pushed on to the stack: Note that the contents which are to be written to the console are present in the register R0. So, we are not using the register R0. System Call Number : 5 for Write</p> <pre><code>MOV R2, 5\nPUSH R2\n</code></pre> <p>Argument 1 : value -2</p> <pre><code>MOV R2, -2\nPUSH R2\n</code></pre> <p>Argument 2 : Data to be written (For this example, data is present in R0. So, we are pushing R0)</p> <pre><code>PUSH R0\n</code></pre> <p>Note</p> <p>Whenever there is a blank argument or a space to be pushed on to the stack, we follow the convention of pushing R0 on to the stack and the status of stack in the figure will be shown using blank argument only.</p> <p>Argument 3 : Blank /* Push any register */</p> <pre><code>PUSH R0\n</code></pre> <p>Storage for Return Value : Push any register</p> <pre><code>PUSH R0\n</code></pre> <p>Now, invoke the trap instruction to invoke the kernel module for console output. The ABI specifies that the interrupt number must be 7.</p> <p>Interrupt Number : 7 for Write System Call</p> <pre><code>INT 7\n</code></pre> <p>The status of the stack after the INT instruction will look as shown below</p> <p></p> <p>Note that in the above diagram argument 2 is 5 because the contents of the register R0 is 5.</p> <p>The above sequence of instructions will invoke the write system call. Upon successful write operation, the value 0 will be returned to the calling program through the stack. We assume here that the call will be successful.</p> <p>Now upon exit from the system call :</p> <ol> <li>The return value may be retrievied if required.</li> <li>The stack must be set back to the state before the call as stipulated in the ABI. This is necessary to avoid loss of stack space after each call.</li> </ol> <p>The following instructions will do the above.</p> <pre><code>// The following code must be executed after return from the system call\nPOP R0 // Pop and save the return value in some register\nPOP R1 // Pop and discard the argument3\nPOP R1 // Pop and discard the argument2\nPOP R1 // Pop and discard the argument1\nPOP R1 // Pop out system call number.\n</code></pre> <p>The <code>target_file</code> will look as shown below after adding the Write system call.</p> <pre><code>0\n2056\n0\n0\n0\n0\n0\n0\nMOV R0, 3\nMOV R1, 2\nADD R0, R1\nMOV SP, 4095\nMOV R2, 5\nPUSH R2\nMOV R2, -2\nPUSH R2\nPUSH R0\nPUSH R2\nPUSH R2\nINT 7\nPOP R0\nPOP R1\nPOP R1\nPOP R1\nPOP R1\n</code></pre> <p>Now, having generated the executable program run the program using the simulator. To run the program, follow the instructions given below.</p> <ol> <li>open terminal and navigate to the XSM simulator folder.</li> <li>Type <code>./xsm -e &lt;relative path to target_file.xsm&gt;</code></li> </ol> <p>You can see that the value 5 is printed on the console.</p> <p>Observe that the simulator flagged an error after the last statement was executed. This happened because after executing the last valid instruction in the program, the simulator had no idea that the program had ended and hence tried to fetch the next instruction from memory. However, since there is no valid insturction in that memory location, the machine raises an exception [see here for exceptions of XSM] and control was transfered to an exception handler routine of the OS kernel. Typically, in a multitasking environment, the OS will terminate the program, reclaim resources allocated to it and schedule some other process.</p> <p>The exception handler routine of the XSM simulator given to you is designed to print an error message and terminate the simulation.</p> <p>The \"proper\" way to exit the application is to invoke the exit system call. This will inform the OS that the program has finished execution. The exit system call code of a typical OS kernel will \"gracefully\" exit the application and schedule other programs for execution. The OS will never return to the application that invokes the exit system call.</p> <p>The exit system call routine of the XSM simulator given to you will print a message indicating successful program execution and terminate the simulation.</p> <p>Important Note</p> <p>The system call code for read, write and exit will modify some of the registers R0, R1 etc. Hence, if you had stored some value into these registers before the call, those values will be lost during the call. Hence, if you wish to restore the values of the registers, the following procedure must be adopted.</p> <ol> <li>Push all registers in current use into the stack. For example, if you wish to retain values of R0, R1 and R2 after the call, push these three registers into the stack.</li> <li>Now, follow procedure outlined earlier to make the system call.</li> <li>After return POP out the registers saved in the stack. (Note that you must pop the registers out in reverse order of push).</li> </ol> <p>Exercise 3</p> <p>Follow the instructions in the low level system call interface of the ABI to invoke the exit system call after the console output in your previous program.</p> <p>So far, there was no need to allocate memory for storing variables as all the data involved were stored in registers. The next exercise requires allocation of storage for variables. Suppose you want to read a number from the console, then the address of a memory location must be passed as the second argument to the read system call (INT 6). The system call will place the input data into the memory address received as the second argument.</p> <p>Suppose you need three variables to be read, then you may reserve the first three words of the stack (memory addresses 4096, 4097 and 4098) for those variables. As some portion of the stack is now reserved for variables, the initial value of the stack pointer may be set such that the run time stack begins above the reserved region. (SP may be set to 4098 here). This ensures that the reserved region is not over-written when the program pushes data into the stack. To read a variable from input, you need to push the address of the memory location reserved for the variable as the second argument (4096 for the first, 4097 for the second, 4098 for the third.) and invoke the read system call. With this strategy, the following exercise can be easily solved.</p> <p>Exercise 4</p> <p>Write an XSM assembly language program to read three numbers from the console and print the largest. (Invoke the read system call for console input.)</p> <p>Caution : Ensure that you understand the important note written above before starting with the implementation.</p> <p> Exercise 5</p> <p>Write an XSM assembly language program to read numbers until a zero is entered and print their sum.</p> <p>Important Note</p> <p>Exercises 4 and 5 essentially ask you to handle conditional and iterative constructs in assembly language. These exercises give insight into how machine code must be genrated for if-then-else and while-do constructs of programming languages.</p>"},{"location":"xsm-environment-tut/#experiment-iii-understanding-the-library-interface","title":"Experiment III: Understanding the Library Interface","text":"<p>Prerequisite Reading</p> <p>Read and understand the library interface.</p> <p>In this experiment, you will learn how to implement the library interface stipulated in the ABI for supporting read, write and exit system calls.</p> <p>The memory address space model of a program reserves the first 1024 words of the address space of a program to load a library. Here we explain the purpose of the library.</p> <p>If we consider C programs, almost every program uses the routines in the library stdio.h. Since in a computer system, several application programs will be running concurrently, it is a good idea to have the code for stdio.h loaded once at bootstrap time into some region of the physical memory and link this memory to the address space of each program's standard library region at load time. This code will be designed once and shared between all applications.</p> <p>The ABI specifies that the ExpOS library for the XSM machine must be linked to address 0 to 1023. The XSM simulator given to you will load the contents of the file library.lib to the addresses 0 - 1023 of your program. The ABI stipulates that the library must support functions for read, write and exit. (The library also must contain functions Alloc, Free and Initialize which will not be discussed here.)</p> <p>To access any library function, an application must transfer control to the code at memory address 0 using the instruction CALL. This is the first memory address in the library region. The arguments to the call specify which library function is being invoked. The library interface is specified here.</p> <p>An application program can execute read, write and exit functions through the library. This means that once the library is implemented, application programs can call the library (CALL 0) to perform read, write and exit operations by passing appropriate function code and arguments. Internally, the library contains code that traps to the Os kernel.</p> <p>One might naturally raise the question \u2013 why should we route the system calls through the library than call them directly as was done so far. There are several advantages in using the library. At a later time, if the interrupt number for an OS service \u2013 say write \u2013 gets modified, only the library needs to be replaced. The compiler need not be modified, nor application programs need re-compilation. Thus, the library provides an abstraction that hides low level details from the compiler and the application.</p>"},{"location":"xsm-environment-tut/#implementation_2","title":"Implementation","text":"<p>In this experiment, we implement the program of Experiment II using the library.</p> <p>Recall that to print the data into the console, we need to:</p> <ol> <li>Push the data(using registers) into the stack along with other arguments to the system call.</li> <li>Invoke the write system call using the INT instruction specifying the appropriate interrupt number.</li> </ol> <p>The step 1 will remain same as in the above experiment. We will implement step 2 using library interface.</p> <p>To use the stack we need to set the stack pointer(SP). Always SP should point the top value of the stack. The XSM machine increments SP immedietely before a PUSH operation by XSM machine and hence the first PUSH operation will be storing data to address 4096. So, we need to initialize SP to 4095.</p> <pre><code>MOV SP, 4095\n</code></pre> <p>Now, the arguments to a write operation must be pushed on to the stack: Note that the contents which are to be written to the console are present in the register R0. So, we are not using the register R0. Function Code : \"Write\"</p> <pre><code>MOV R2, \"Write\"\nPUSH R2\n</code></pre> <p>Argument 1 : value -2 (see ABI for specification)</p> <pre><code>MOV R2, -2\nPUSH R2\n</code></pre> <p>Argument 2 : Data to be written (For this example, data is present in R0. So, we are pushing R0)</p> <pre><code>PUSH R0\n</code></pre> <p>Argument 3 : Blank /* Push any register */</p> <pre><code>PUSH R0\n</code></pre> <p>Storage for Return Value : Push any register</p> <pre><code>PUSH R0\n</code></pre> <p>The main difference between the system call interface and the library interface come at the next instruction. If we were using the system call interface, we would have called the interrupt for write (INT 7). Here instead, we will always use CALL 0 to transfer control to the library. (Remember that library file is loaded in the memory addresses 0 - 1023.). The library understands that the action requested is a write operation by looking at the function code passed as argument (in this case \"Write\"). If the action requested is a read operation, then \"Read\" is passed, and so on.</p> <pre><code>CALL 0\n</code></pre> <p>The status of the stack after the INT instruction will look as shown below</p> <p></p> <p>Note that in the above diagram argument 2 is 5 because the contents of the register R0 is 5.</p> <p>The above sequence of instructions will invoke the write system call from the library. Upon successful write operation, the library must retuen value 0 to the calling program through the stack. We assume here that the call will be successful.</p> <p>Now upon exit from the call :</p> <ol> <li>The return value may be retrieved if required.</li> <li>The stack must be set back to the state before the call as stipulated in the ABI. This is necessary to avoid loss of stack space after each call.</li> </ol> <p>The following instructions will do the above.</p> <pre><code>// The following code must be executed after return from the system call\nPOP R0 // Pop and save the return value in some register\nPOP R1 // Pop and discard the argument3\nPOP R1 // Pop and discard the argument2\nPOP R1 // Pop and discard the argument1\nPOP R1 // Pop out the function code.\n</code></pre> <p>The <code>target_file</code> will look as shown below after adding the Write system call.</p> <pre><code>0\n2056\n0\n0\n0\n0\n0\n0\nMOV R0, 3\nMOV R1, 2\nADD R0, R1\nMOV SP, 4095\nMOV R1, \"Write\"\nPUSH R1\nMOV R1, -2\nPUSH R1\nPUSH R0\nPUSH R1\nPUSH R1\nCALL 0\nPOP R0\nPOP R1\nPOP R1\nPOP R1\nPOP R1\n</code></pre> <p>Now we need to write logic in the library file to handle the request for Write system call. Earlier we have created the \"library.lib\" file with RET instruction alone. Now we will edit this file.</p> <p>When CALL 0 is executed, the IP+2 is pushed on the top of the stack and IP is set to 0. Therefore now IP points to the first instruction of the library file.</p> <p>Since every call to the library points IP to 0 address, we need to have logic to distinguish the type of request at this address. The information regarding the type of request can be found from the function code that is pushed as an argument on the stack. The function code can be obtained from the stack using SP - 5[Why?].</p> <p>In this experiment we are dealing only with \"Write\" system call, so we will have our discussion only specific to it. After recognising the type of request we need to handle the request in the same way as we did in the previous experiment using system call interface. The arguments to be passed in the system call interface are system call number(5),-2, register holding the value to be written (It is at SP - 3) and a blank argument. The library simply has to copy the arguments 1 to 3 to the system call without any modification.</p> <p>Get the function code from the stack and compare if it is equal to \"Write\" and get the arguments from the stack.</p> <pre><code>MOV R1, SP\nMOV R2, 5\nSUB R1, R2\nMOV R2, \"Write\"\nMOV R1, [R1]\nEQ R1, R2\nJZ R1, 62\nMOV R1, SP\nMOV R2, 4\nSUB R1, R2\nMOV R2, [R1] //argument 1 at SP - 4\nADD R1, 1\nMOV R3, [R1] //argument 2 at SP - 3\nADD R1, 1\nMOV R4, [R1] //argument 3 at SP - 2\n</code></pre> <p>Once you get the arguments, the procedure to invoke the system call is same as we did in the earlier experiment.</p> <pre><code>/* pushing arguments and space for return value for system call */\nMOV R5, 5 //System call number 5 for Write\nPUSH R5\nPUSH R2 //R2 contains [SP - 4] = -2\nPUSH R3 //R3 contains [SP - 3] = 5 // Contains Value\nPUSH R4 //R4 contains [SP - 2] = blank\nPUSH R5 // space for return value\n\n/* trap instruction */\nINT 7\n\n/* Pop the arguments and return value */\nPOP R1 //Pop and save return value\nPOP R2 //Pop and discard\nPOP R2 //Pop and discard\nPOP R2 //Pop and discard\nPOP R2 //Pop and discard\n</code></pre> <p>The return value of the library is the same as the return value of the system call. Hence the library must copy the return value of the system call back to the application as its own return value through the stack.</p> <pre><code>/* Storing the return value on the top of the stack */\nMOV R2, SP\nMOV R3, 1\nSUB R2, R3\nMOV [R2], R1\n// [SP - 1] = R1 (Return value was popped to R1 earlier) RET\n</code></pre> <p>The library.lib file will look as shown below after adding the code to handle Write system call.</p> <pre><code>MOV R1, SP\nMOV R2, 5\nSUB R1, R2\nMOV R2, \"Write\"\nMOV R1, [R1]\nEQ R1, R2\nJZ R1, 62\nMOV R1, SP\nMOV R2, 4\nSUB R1, R2\nMOV R2, [R1]\nADD R1, 1\nMOV R3, [R1]\nADD R1, 1\nMOV R4, [R1]\nMOV R5, 5\nPUSH R5\nPUSH R2\nPUSH R3\nPUSH R4\nPUSH R5\nINT 7\nPOP R1\nPOP R2\nPOP R2\nPOP R2\nPOP R2\nMOV R2, SP\nMOV R3, 1\nSUB R2, R3\nMOV [R2], R1\nRET\n</code></pre> <p>Important note</p> <p>Your library code for read, write and exit may modify some of the registers R0, R1 etc. Hence, if you had stored some values into these registers before the call, those values will be lost while the library code is executed. To safely restore the values of the registers, the following procedure must be adopted.</p> <ol> <li>Push all registers in current use into the stack. For example, if you wish to retain values of R0, R1 and R2 after the call, push these three registers into the stack.</li> <li>Now, code the library call and return steps.</li> <li>After return POP out the registers saved in the stack. (Note that you must pop the registers out in reverse order of push).</li> </ol> <p>Exercise 6</p> <p>Implement <code>read()</code> and <code>exit()</code> functions of the library.</p> <p>Exercise 7</p> <p>Modify the program to read three numbers from the console and print the largest to perform I/O using the library interface.</p> <p>Exercise 8</p> <p>Modify the program to read numbers until a zero is entered from the console and print their sum to perform I/O using the library interface.</p>"},{"location":"xsmusagespec/","title":"XSM SIMULATOR USAGE SPECIFICATION","text":""},{"location":"xsmusagespec/#usage","title":"Usage","text":"<p>The XSM (eXperimental String Machine) Simulator is used to simulate the hardware and OS abstractions specified in the ExpOS Application Binary Interface.</p> <p>Within your XSM directory, use the following command to run the simulator</p> <pre><code>./xsm [-l library.lib] -e &lt;filename.xsm&gt; [--debug]\n</code></pre> <ol> <li> <p>Syntax : <code>-l library.lib</code></p> <p>Semantics : This flag loads the library, library.lib to the machine memory. (The simulator specification does not allow any name other than library.lib for the library file.) The argument is optional and needs to be given only if the library is to be linked to page 0 and page 1 of the virtual address space</p> </li> <li> <p>Syntax : <code>-e &lt;filename.xsm&gt;</code></p> <p>Semantics : This flag loads the executable file named as filename which is of the XEXE format . This argument is mandatory. The file is loaded into pages 4,5,6 and 7 in the virtual address space .</p> </li> <li> <p>Syntax : <code>--debug</code></p> <p>Semantics : This flag sets the machine into DEBUG mode when it encounters a BRKP machine instruction. Any BRKP instruction in the program will be ignored by the machine if this flag is not set. Further details are given in the section below.</p> </li> </ol>"},{"location":"xsmusagespec/#debugging","title":"Debugging","text":"<p>The <code>--debug</code> flag is used to debug the running machine. When this flag is set and the machine encounters a breakpoint instruction, the machine enters the DEBUG mode. In this mode a prompt is displayed which allows the user to enter commands to inspect the state of the machine. The commands in DEBUG mode are :</p> <ol> <li> <p>Syntax : <code>step</code> / <code>s</code></p> <p>Semantics : The execution proceeds by a single step.</p> </li> <li> <p>Syntax : <code>continue</code> / <code>c</code></p> <p>Semantics : The execution proceeds till the next breakpoint (BRKP) instruction.</p> </li> <li> <p>Syntax : <code>reg</code> / <code>r</code></p> <p>Semantics : Displays the contents of all the machine registers namely IP, SP, BP, PTBR, PTLR, EIP, EC, EPN, EMA, R0-R19 in that order.</p> </li> <li> <p>Syntax : <code>reg &lt;register_name&gt;</code> / <code>r &lt;register_name&gt;</code></p> <p>Semantics : Displays the contents of the specified register.</p> <p>Sample usage: <code>r R5</code>, <code>reg SP</code></p> </li> <li> <p>Syntax : <code>reg &lt;register_name_1&gt; &lt;register_name_2&gt;</code> / <code>r &lt;register_name_1&gt; &lt;register_name_2&gt;</code></p> <p>Semantics : Displays the contents of the registers from <code>&lt;register_name_1&gt;</code> to <code>&lt;register_name_2&gt;</code> in the order specified in (3).</p> </li> <li> <p>Syntax : <code>mem &lt;page_num&gt;</code> / <code>m &lt;page_num&gt;</code> Semantics : Displays the contents of the memory page in the virtual address space.     Sample usage: <code>mem 5</code>, <code>m 8</code></p> </li> <li> <p>Syntax : <code>mem &lt;page_num_1&gt; &lt;page_num_2&gt;</code> / <code>m &lt;page_num_1&gt; &lt;page_num_2&gt;</code></p> <p>Semantics : Displays the contents of the memory from pages to in the virtual address space.</p> <p>Sample usage: <code>mem 4 7</code>, <code>m 8 9</code></p> </li> <li> <p>Syntax : <code>list</code> / <code>l</code></p> <p>Semantics : List 10 instructions before and after the current instruction.</p> </li> <li> <p>Syntax : <code>stacktrace</code> / <code>st</code></p> <p>Semantics : List the contents of the top 12 memory locations on the stack, starting with the contents of the address pointed to by the SP register.</p> </li> <li> <p>Syntax : <code>val &lt;virtual_address&gt;</code> / <code>v &lt;virtual_address&gt;</code></p> <p>Semantics : Displays the content at memory address.</p> </li> <li> <p>Syntax : <code>watch &lt;virtual_address&gt;</code> / <code>w &lt;virtual_address&gt;</code></p> <p>Semantics : Sets a watch point to this address. Watch point is used to track changes of a particular memory location. Whenever a word which is watched is altered, program execution is stopped and the debug interface is invoked. Atmost 16 watch points can be set.</p> </li> <li> <p>Syntax : <code>watchclear</code> / <code>wc</code></p> <p>Semantics : Clears all the watch points.</p> </li> <li> <p>Syntax : <code>exit</code> / <code>e</code></p> <p>Semantics : Exits the debug prompt and halts the machine.</p> </li> <li> <p>Syntax : <code>help</code> / <code>h</code></p> <p>Semantics : Displays commands.</p> </li> </ol>"},{"location":"yacc/","title":"Using YACC","text":""},{"location":"yacc/#introduction-to-yacc","title":"Introduction to YACC","text":"<p>YACC (Yet Another Compiler Compiler) is a tool used to generate a parser. This document is a tutorial for the use of YACC to generate a parser for ExpL. YACC translates a given Context Free Grammar (CFG) specifications (input in input_file.y) into a C implementation (y.tab.c) of a corresponding push down automaton (i.e., a finite state machine with a stack). This C program when compiled, yields an executable parser.</p> <p></p> <p>The source SIL program is fed as the input to the generated parser ( a.out ). The parser checks whether the program satisfies the syntax specification given in the input_file.y file.</p> <p>YACC was developed by Stephen C. Johnson at Bell labs.</p>"},{"location":"yacc/#parser","title":"Parser","text":"<p>A parser is a program that checks whether its input (viewed as a stream of tokens) meets a given grammar specification. The syntax of SIL can be specified using a Context Free Grammar. As mentioned earlier, YACC takes this specification and generates a parser for SIL.</p>"},{"location":"yacc/#context-free-grammar-cfg","title":"Context Free Grammar (CFG)","text":"<p>A context free grammar is defined by a four tuple (N,T,P,S) - a set N of non-terminals, a set T of terminals (in our project, these are the tokens returned by the lexical analyzer and hence we refer to them as tokens frequently), set P of productions and a start variable S. Each production consists of a non-terminal on the left side (head part) and a sequence of tokens and non-terminals (of zero or more length) on the right side (body part). We will explore productions further in detail later in this documentation. For more about context free grammars refer to this wiki .</p> <p>Example: This example is an Infix to Postfix converter implemented using YACC. The rules part of the YACC program has been shown below:</p> <pre><code>start: expr '\\n' {exit(1);}\n     ;\nexpr:  expr '+' expr {printf(\"+ \");}\n    | expr '*' expr {printf(\"* \");}\n    | '(' expr ')'\n    | DIGIT  {printf(\"NUM%d \",pos);}\n    ;\n</code></pre> <p>In this example:</p> <p>The set of non-terminals are <code>N = {start, expr}</code></p> <p>The set of terminals are <code>T = {'\\n', '+', '*', '(', ')' , DIGIT }</code></p> <p>The start symbol <code>S = start</code></p> <p>Sample Input/Output :</p> <pre><code>I: 1+5\nO: NUM1 NUM2 +\n</code></pre> <p>When the input expression 1+5 is given to the parser generated by YACC, the parser prints a postfix form of the original expression 1+5 as NUM1 NUM2 + where, NUM1 represents the first number ( 1 ) in the input and NUM2 represents the second number ( 5 ) in the input.</p> <p>Sample Input/Output :</p> <pre><code>I: 3+(1*9)+5\nO: NUM1 NUM2 NUM3 * + NUM4 +\n\nI: 5$\nO: NUM1 error\n</code></pre> <p>The example above demonstrates the specification of rules in YACC. In this example there are five rules. Each rule has a production part and an action part .The action part consists of C statements enclosed within a { and }. Each production part has a head and a body separated by a ':'. For example, the first rule above has production part with start as the head and expr '\\n' as the body. The action part for the rule is {exit(1);}. The parser reads the input sequentially and tries to find a pattern match with the body part of each production. When it finds a matching production, the action part of the corresponding rule is executed. The process is repeated till the end of the input.</p> <p>In the above example, when the input 1+5 is given to the parser, it attempts to match the input with the body of the production of the first rule. When the input has been parsed completely and correctly matched with the start production start: expr '\\n' the parser executes the action exit(1);. The statements printf(\"NUM \"); and printf(\"+ \"); are executed as result of the input being matched with the productions expr: DIGIT and expr: expr '+' expr respectively. If the parser fails to find any matching body part, it invokes a special yyerror() function. In our example, the yyerror() function is programmed to print the message \u201cerror\u201d.</p>"},{"location":"yacc/#yyparse","title":"yyparse()","text":"<p>The <code>y.tab.c</code> file contains a function yyparse() which is an implementation (in C) of a push down automaton. yyparse() is responsible for parsing the given input file. The function yylex() is invoked by yyparse() to read tokens from the input file. Click here to view an example of yylex() definition. Note that the yyparse() function is automatically generated by YACC in the y.tab.c file. Although YACC declares yylex() in the y.tab.c file, it does not generate the definition for yylex(). Hence the yylex() function definition has to be supplied by you (either directly by defining yylex() in the auxiliary functions section (explained in the next section) or using a lexical analyzer generator like LEX). Each invocation of yylex() must return the next token (from the input steam) to yyparse(). The action corresponding to a production is executed by yyparse() only after sufficient number of tokens has been read (through repeated invocations of yylex()) to get a complete match with the body of the production.</p>"},{"location":"yacc/#the-structure-of-yacc-programs","title":"The structure of YACC programs","text":"<p>A YACC program consists of three sections: Declarations, Rules and Auxiliary functions. (Note the similarity with the structure of LEX programs).</p> <pre><code>DECLARATIONS\n\n%%\n\nRULES\n\n%%\n\nAUXILIARY FUNCTIONS\n</code></pre>"},{"location":"yacc/#declarations","title":"Declarations","text":"<p>The declarations section consists of two parts: (i) C declarations and (ii) YACC declarations . The C Declarations are delimited by <code>%{</code> and <code>%}</code>. This part consists of all the declarations required for the C code written in the Actions section and the Auxiliary functions section. YACC copies the contents of this section into the generated y.tab.c file without any modification. The following example shows an abstract outline of the structure of the declarations part of a YACC program:</p> <p>Example :</p> <pre><code>/* Beginning of Declarations part */\n\n%{\n    /*Beginning of C declarations*/\n\n    /*End of C declarations*/\n%}\n\n    /*Beginning of YACC declarations  */\n\n    /*End of YACC declarations */\n\n/* End of Declarations Part */\n%%\n</code></pre> <p>The YACC declarations part comprises of declarations of tokens (usually returned by the lexical analyzer). The parser reads the tokens by invoking the function yylex() (To be discussed in detail later).</p>"},{"location":"yacc/#rules","title":"Rules","text":"<p>A rule in a YACC program comprises of two parts (i) the production part and (ii) the action part. In this project, the syntax of SIL programming language will be specified in the form of a context free grammar. A rule in YACC is of the form:</p> <pre><code>production_head : production_body { action in C };\n</code></pre> <p>The following example shows an abstract outline of the structure of the rules part of a YACC program:</p> <pre><code>%%\n/* Rules Section begins here */\n\n/* Rules Section ends here */\n%%\n</code></pre> <p>The rules in our example can be found here</p>"},{"location":"yacc/#productions","title":"Productions","text":"<p>Each production consists of a production head and a production body. Consider a production from our example:</p> <pre><code>expr : expr '+' expr\n</code></pre> <p>The expr on the LHS of the : in the production is called the head of the production and the expr '+' expr on the RHS of the : is called the body of the production. In the above example, '+' is a terminal (token) and expr is a non-terminal. Users can give name to a token. (for instance we can give the name 'PLUS' to the token '+'). In such cases, the names must be defined in the declarations section. For example have a look at the definition of the token DIGIT here. The head of a production is always a non-terminal. Every non-terminal in the grammar must appear in the head part of at least one production.</p> <p>Note that a non-terminal in the head part of a production may have one or more production bodies separated by a \u201c|\u201d. Consider the non-terminal expr in our example. The non-terminal has four production bodies expr '+' expr , expr '*' expr , '(' expr ')' and DIGIT. The first production body has an associated print action op_printf(\"+\") and the second production body has an associated action op_print(\"*\"). yyparse() executes the action only when the body expr '+' expr has been matched with the input. The action part of a single production may have several statements of C code.</p>"},{"location":"yacc/#actions","title":"Actions","text":"<p>The action part of a rule consists of C statements enclose within a '{' and '}'. These statements are executed when the input is matched with the body of a production and a reduction takes place. The notion of a reduction will be explained later. From the example below, consider the following rule:</p> <p>expr: DIGIT {printf(\"NUM%d \",pos);}</p> <p>In this rule, when the input matches with the body of the production DIGIT, it is reduced to expr and the action {printf(\"NUM%d \",pos);} is executed.</p>"},{"location":"yacc/#auxiliary-functions","title":"Auxiliary Functions","text":"<p>The Auxiliary functions section contains the definitions of three mandatory functions main(), yylex() and yyerror(). You may wish to add your own functions (depending on the the requirement for the application) in the y.tab.c file. Such functions are written in the auxiliary functions section. The main() function must invoke yyparse() to parse the input. You will need to write your supporting functions later in this project.</p> <p>Example: intopost.y <pre><code>%{\n/*** Auxiliary declarations section ***/\n\n#include&lt;stdio.h&gt;\n#include&lt;stdlib.h&gt;\n\n/* Custom function to print an operator*/\nvoid print_operator(char op);\n\n/* Variable to keep track of the position of the number in the input */\nint pos=0;\n\n%}\n\n /*** YACC Declarations section ***/\n%token DIGIT\n%left '+'\n%left '*'\n%%\n\n/*** Rules Section ***/\nstart : expr '\\n'  {exit(1);}\n      ;\n\nexpr: expr '+' expr     {print_operator('+');}\n    | expr '*' expr     {print_operator('*');}\n    | '(' expr ')'\n    | DIGIT             {printf(\"NUM%d \",pos);}\n    ;\n\n%%\n\n/*** Auxiliary functions section ***/\n\nvoid print_operator(char c){\n    switch(c){\n        case '+'  : printf(\"PLUS \");\n                    break;\n        case '*'  : printf(\"MUL \");\n                    break;\n    }\n    return;\n}\n\nyyerror(char const *s)\n{\n    printf(\"yyerror %s\",s);\n}\n\nyylex(){\n    char c;\n    c = getchar();\n    if(isdigit(c)){\n        pos++;\n        return DIGIT;\n    }\n    else if(c == ' '){\n        yylex();         /*This is to ignore whitespaces in the input*/\n    }\n    else {\n        return c;\n    }\n}\n\nmain()\n{\n yyparse();\n return 1;\n}\n</code></pre></p> <p><code>y.tab.c</code> file can be generated using the command</p> <pre><code>yacc intopost.y\n</code></pre> <p><code>y.tab.c</code> is compiled using C compiler</p> <pre><code>gcc y.tab.c\n</code></pre> <p>Note</p> <p><code>%left</code> option is used to resolve shift/reduce conflicts. It is explained in detail later.</p> <p>Sample Input/Output:</p> <pre><code>I: 2+2\nO: NUM1 NUM2 PLUS\n</code></pre> <p>When <code>yyparse()</code> matches the input 2+2 with the production body expr '+' expr, it executes the action <code>op_print('+');</code> and as a result prints \u201cPLUS\u201d in place of '+' as per the definition of <code>op_print()</code>.</p> <p>Note</p> <p><code>op_print()</code> is used in the example just to show an example of the declaration, definition and usage of a user defined auxliary function. Generally in this project, we use <code>printf()</code> to display content.</p>"},{"location":"yacc/#a-working-introduction-to-shift-reduce-parsing","title":"A working introduction to shift-reduce parsing","text":"<p>YACC uses shift-reduce parsing methodology to parse the given input. The shift-reduce parser is essentially a push down automaton . It consists of a finite state machine with a stack. The stack is used to hold terminal and/or non-terminal symbols. The following is a gentle introduction to shift-reduce parsing.</p> <p>Take note of the following points before we proceed:</p> <p>A shift-reduce parser is initialized in the following configuration.</p> <pre><code>STACK: $    I/P BUFFER:  &lt;Input to be parsed&gt; $\n</code></pre> <p>The input to be parsed, which is a sequence of terminal symbols, is stored in an input buffer with '$' symbol at the end (used as an end-marker). The stack is initialized to contain just the symbol '$'.</p> <p>The parser works by repeatedly performing the following actions :</p> <ol> <li>Read the next terminal symbol from the input and push it into the stack and removing it from the input. This operation is called a shift. (The shift operation will be explained in detail later.)</li> <li>Do some conditional operations on the stack. These operations are called reductions. Not every iteration may involve reductions. (Reductions will be explained in detail later.)</li> <li>Until an error is encountered or the input is successfully parsed.</li> </ol> <p>Parsing ends successfully when the input buffer is empty (except for the end-marker '$') and the stack contains nothing but the '$' followed by the start symbol of the grammar. Error condition occurs when the input does not belong to the language of the grammar and the parser detects the same. We will look at error conditions later.</p> <p>Consider the following context free grammar. This will be used as a running example for this section.</p> <pre><code>expr : expr '+' expr                                             (Production 1)\n     | expr '\\*' expr                                            (Production 2)\n     | '(' expr ')'                                              (Production 3)\n     | '0' | '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' (Production 4)\n     ;\n</code></pre> <p>The terminal set is {+,*,(,),0,1,2,3,4,5,6,7,8,9}. The only non-terminal is 'expr'. Production 4 is actually a collection of 10 productions. We refer them collectively with one production number for simplicity.</p> <p>Let us consider parsing of the input 2+2*3 using this grammar. When the parsing process begins, the contents of the stack and the input buffer would be as follows:</p> <pre><code>STACK:  $    I/P BUFFER: \u00a0 \u00a0 2 + 2 $\n</code></pre> <p>The contents of the stack and the contents of the input buffer together define the configuration of the parser. On successful completion of parsing, the configuration would be:</p> <pre><code>STACK: \u00a0 \u00a0  $ expr \u00a0 \u00a0 \u00a0   I/P BUFFER: \u00a0 \u00a0 $\n</code></pre> <p>Note here that expr is the start variable of the parser's context free grammar. This is the accepting configuration.</p> <p>At each step of parsing, the parser takes an action resulting in a configuration change. A shift-reduce parser can take four possible parser-actions:</p> <ol> <li>Shift is the parser-action of removing the next unread terminal from the input buffer and pushing it into the stack. (The input terminal gets \u201cshifted\u201d to the stack).</li> <li>Reduce is the parser-action of replacing one or more grammar symbols from the top of the stack that matches a body of a production, with the corresponding production head. The contents on top of the stack which matches the right side of a production is called a handle. The process of replacing a handle with the corresponding production head is called a reduction.</li> <li> <p>Accept is the parser-action indicating that the entire input has been parsed successfully. The parser executes an accept action only if it reaches the accepting configuration \u2013 one in which the input buffer is empty and the stack contains just the start variable followed by '$'.     Accepting state would be of the form:</p> <pre><code>STACK: $ &lt;start\\_variable&gt;   I/P BUFFER:       $\n</code></pre> </li> <li> <p>Error indicates that an error was encountered while parsing the input. In our example, there is no error. We will see error conditions later.</p> </li> </ol>"},{"location":"yacc/#the-parsers-iteration-steps","title":"The parser's Iteration Steps","text":"<p>After initialization, the parser executes the following algorithm.</p> <pre><code>Repeat\n      shift the next terminal from the input to the stack.\n      While there is a \u201cvalid\u201d reduction\n        perform the reduction.\nUntil accepting configuration is reached.\n</code></pre> <p>At each step of parsing, the shift-reduce parser decides on an action depending on the configuration of the parser.</p> <p>Several details are left out in this description. For instance, what is a \u201cvalid reduction\u201d, or what the error conditions are etc. have not been specified. These are determined by the contents of a parsing table maintained by the parser and we will not go into the details here. Instead, we will try to see how the parser operates in the case of our running example.</p> <pre><code>(1) STACK: $    I/P BUFFER: 2 + 3 * ( 4 + 5 ) $\n</code></pre> <p>At this configuration, the parser executes a shift action i.e. 2 is pushed onto the stack resulting in the configuration:</p> <pre><code>(2) STACK: $ 2    I/P BUFFER: + 3 * ( 4+ 5 ) $\n</code></pre> <p>Now, the top of the stack matches the right side (body) of Production 4 i.e., the 2 on the stack is the handle in this case and a reduction takes place replacing the handle with the production head expr.</p> <pre><code>(3) STACK: $ expr    I/P BUFFER: + 3 * ( 4 + 5 ) $\n</code></pre> <p>As there is no further handles to perform reductions, the parser shifts the next terminal '+' from the input to the stack.</p> <pre><code>(4) STACK: $ expr +    I/P BUFFER: 3 * ( 4 + 5 ) $\n</code></pre> <p>In the next iteration, as no reductions are possible, the parser again shifts the next input:</p> <pre><code>(5) STACK: $ expr + 3    I/P BUFFER: * ( 4 + 5 ) $\n</code></pre> <p>Now, the parser can apply Production 4 and reduce the handle '3' on the top of the stack to expr. Thus the parser reduces by Production 4 and replaces '3' with expr.</p> <pre><code>(6) STACK: $ expr + expr   I/P BUFFER: * ( 4 + 5 ) $\n</code></pre> <p>At this point there is a further reduction possible using Production 1. However, the \u201cvalid\u201d action here is not to perform the reduction, but shift the next input to the stack. The reason being that '*' has higher precedence over '+'. (similar issues occur with associativity of operators). Unless the parser is somehow is informed about what the correct action is (shift/reduce), under every such situation, the correct precedence/associativity may not be respected. For the time being, it is sufficient to understand that there are ways by which the user can force the parser to act in the right way in most practical situations, particularly when using a parser generator like YACC. Hence we hide these issues for now and assume that the parser is somehow capable of finding the \u201cvalid\u201d actions. (Some more details on how this will be done will be explained in the later sections.) Hence, the next action is a shift.</p> <pre><code>(7) STACK: $ expr + expr *   I/P BUFFER: ( 4 + 5 )$\n</code></pre> <p>In the next few iterations, the parser continuously shifts and reduces to reach the configuration:</p> <pre><code>(8) STACK: $ expr + expr * ( expr + expr I/P BUFFER: ) $\n</code></pre> <p>Now, the handle \u201cexpr+expr\u201d matches the body of production 1, hence the parser reduces by production 1.</p> <pre><code>(9) STACK: $ expr + expr * ( expr  I/P BUFFER: ) $\n</code></pre> <p>The parser continues to iterate as the accepting configuration has not been reached. In the next iteration, the parser shifts, as a result emptying the input buffer.</p> <pre><code>(10) STACK: $ expr + expr * ( expr )  I/P BUFFER: $\n</code></pre> <p>Now the parser reduces the handle \u201c ( expr ) \u201d by production 3,</p> <pre><code>(11) STACK: $ expr + expr * expr  I/P BUFFER: $\n</code></pre> <p>In the next iteration, as yet another valid reduction is possible, the parser reduces by Production 2</p> <pre><code>(12) STACK: $ expr + expr   I/P BUFFER: $\n</code></pre> <p>As the parser has not reached accepting configuration and there exists another handle top of the stack, the parser further reduces the entire contents of the stack, i.e., the handle \u201cexpr + expr\u201d with production 1 and thus puts the start symbol expr on the stack.</p> <pre><code>(13) STACK: $ expr    I/P BUFFER: $\n</code></pre> <p>On reaching accepting configuration, the parser quits iterating. Since the I/P BUFFER is empty and the stack contains only the start variable, the parser executes an accept action, indicating that the input has been parsed successfully. The following table summarizes the step-by-step change in the parser's configuration after each action taken by a shift reduce parser.</p> STACK I/P BUFFER PARSER-ACTION EXECUTED 2 + 3 * (4 + 5) $ _ $2 + 3 * ( 4 + 5 ) $ SHIFT $expr + 3 * ( 4 + 5 ) $ REDUCE $expr + 3 * ( 4 + 5 ) $ SHIFT $expr + 3 * ( 4 + 5 ) $ SHIFT $expr + expr * ( 4 + 5) $ REDUCE $expr + expr * ( 4 + 5 ) $ SHIFT $expr + expr * ( 4 + 5 ) $ SHIFT $expr + expr * ( 4 + 5 ) $ SHIFT $expr + expr * ( expr + 5 ) $ REDUCE $expr + expr * ( expr + 5 ) $ SHIFT $expr + expr * ( expr + 5 ) $ SHIFT $expr + expr * ( expr + expr ) $ REDUCE $expr + expr * ( expr ) $ REDUCE $expr + expr * ( expr ) $ SHIFT $expr + expr * expr $ REDUCE $expr + expr $ REDUCE $expr $ REDUCE $expr $ ACCEPT <p>There are several variants of shift-reduce parsing like the LR(1), SLR(1) and LALR(1) parsing methods. The notion of valid shift or a valid reduce depends on the particular parsing method and can be fairly involved. We will see how routine situations like precedence and associativity of operators can be easily handled when you are using YACC. YACC uses an LALR(1) parsing method. An understanding of the general principles of shift-reduce parsing at the level presented here will be sufficient for most of this project.</p>"},{"location":"yacc/#infix-to-postfix-program","title":"Infix to Postfix program","text":"<p>When <code>yacc_file.y</code> is fed to YACC, it generates a <code>y.tab.c</code> file. When compiled, this program yields a parser. The generated parser uses shift-reduce parsing to parse the given input. Yacc copies the C declarations (in the Declaration section of input_file.y) and all the auxiliary functions (in the Auxiliary functions section of input_file.y) directly into y.tab.c without any modification. In addition to these, YACC generates the definition of yyparse() in <code>y.tab.c</code>.</p> <p>It is important to understand that, y.tab.c contains the following :</p> <ol> <li>The C declarations from the input_file.y file</li> <li>Generated yyparse() definition</li> <li>All the auxiliary functions from the input_file.y</li> </ol> <p>Recall our infix to postfix program.</p> <p>Here is a Sample Input and Output:  <pre><code>I: 2+3*(4+5)\nO: NUM1 NUM2 NUM3 NUM4 + * +\n</code></pre> <p>When the expression 2+3 is fed as the input to the generated parser, the main() function in the auxiliary functions section invokes yyparse() as below: (The code for main() from the example is copied below)</p> <pre><code>main()\n{\n yyparse();\n return 1;\n}\n</code></pre> <p>As noted earlier, yyparse() invokes yylex() to read tokens from the input. For example, when yylex() reads the input 2 and returns the token DIGIT (code of yylex() shown below)</p> <pre><code>yylex()\n{\n int c;\n c = getchar();\n if(isdigit(c))  /* Every time a number is found in the input stream,\n                yylex() increments pos and returns a token DIGIT */\n {\n  pos++;\n  return DIGIT;\n }\n return c;   /* If any character other than a number is found,\n                yylex() simply returns the character itself to yyparse() */\n}\n</code></pre> <p>Note</p> <p>As pos was initialized to 0, it holds the value 1 after returning the first DIGIT, 2 after returning the second DIGIT and so on.</p> <p>yyparse() is the function that parses the given input using shift-reduce parsing. When the reduction of a handle takes place, yyparse() executes the action (specified in the action part of the rule) corresponding to the handle's production in the yacc program. On successful parsing of the given input, yyparse() returns 0. If yyparse() fails to parse the given input, it returns 1.</p> <p>A generalized algorithm of yyparse() would look like:</p> <pre><code>Initialize the stack with the end-marker $\nnew_token = yylex() /* read the first token from the input */\nwhile (true)\n switch(parser_action(stack, new_token))\n  case 'reduce':\n                  pop the handle from stack, replace it with the\n                  head of the handle's production.Execute action\n                  part in the yacc file corresponding to the handle's production\n  case 'shift':\n                  push new_token into the stack.\n            new_token = yylex()  /* read the next token from the input */\n  case 'accept':\n   return 0\n  case 'error':\n   return 1\n</code></pre> <p>The following table summarizes the parsing process in every iteration of the above algorithm.</p> Input buffer new_ token parser_action() returns Stack contents after parser-action Action executed by yyparse() Output 1+2$ DIGIT _ _ _ _ 1+2$ DIGIT SHIFT DIGIT $ _ _ +2$ + REDUCE expr $ printf(\"NUM%d\", pos); NUM1 +2$ + SHIFT + expr $ _ NUM1 2$ DIGIT SHIFT DIGIT + expr $ _ NUM1 $ $ REDUCE expr + expr $ printf(\"NUM%d\", pos); NUM1 NUM2 $ $ REDUCE expr $ printf(\"+ \"); NUM1 NUM2 + $ $ ACCEPT expr $ _ NUM1 NUM2 +"},{"location":"yacc/#conflicts-in-parsing-using-yacc","title":"Conflicts in Parsing using YACC","text":"<p>As noted earlier, YACC uses the shift-reduce parsing methodology. Conflicts arise when the parser is unable to make a decision on the action to execute. These conflicts are practically of two-types: shift/reduce conflict and reduce/reduce conflict.</p>"},{"location":"yacc/#resolving-shiftreduce-conflicts","title":"Resolving shift/reduce conflicts","text":"<p>When the parser cannot decide whether to shift or to reduce in a configuration where both the actions seem to be viable options. Consider the following grammar:</p> <pre><code>expr : expr '+' expr\n     | '(' expr ')'\n     | '0' | '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9'\n;\n</code></pre> <p>When the above grammar is fed to YACC, it produces a warning as shown below</p> <pre><code>yacc: 1 shift/reduce conflict\n</code></pre> <p>Let us consider an example to demonstrate a shift-reduce conflict. Consider an input of 1+2+3 to the parser generated by YACC for the above context free grammar. The input can be interpreted as <code>[1+2]+3</code> or <code>1+[2+3]</code>.</p> <p>Case 1: When the parser reaches a configuration of:</p> <pre><code>STACK: $ expr+expr \u00a0I/P BUFFER: +3 $\n</code></pre> <p>The parser can choose to reduce by reducing the handle expr+expr on top of the stack to expr.</p> <p>Case 2: When the parser reaches the configuration as in Case 1, it could chose to shift instead of reduce, hence resulting in the configuration of:</p> <pre><code>STACK: $ expr+expr+expr \u00a0I/P BUFFER: $\n</code></pre> <p>Now, the parser can reduce expr+expr on top of the stack to expr, following which the contents of the stack expr +expr can be reduced to the expr.</p> <p>The example showed how the parser faced a conflict on deciding between the shift and reduce actions. Such conflicts are called shift/reduce conflicts. If the parser had chosen to reduce (like in Case 1), the input would be interpreted as [1+2]+3 (left associative). If the parser chooses to shift (like in Case 2), the input would be interpreted as 1+[2+3] (right associative). The difference in the interpretations is the associativity of the '+' operator. As the + operator is left associative, we would want the input to be interpreted as (1+2)+3. This can be done by specifying the associativity of the token '+' using the YACC keyword %left in the Declarations section as shown below:</p> <pre><code>%left '+'\n</code></pre> <p>Once this had been done, when the parser faces a conflict it refers to the declaration and decides to reduce as the token '+' has been declared left associative. Tokens can be declared to be right associative or non-associative by using the YACC keywords %right and %nonassoc. As an example, if you add the production expr -&gt; expr '&lt;' expr then declaring</p> <pre><code>% nonassoc '&lt;'\n</code></pre> <p>makes the parser return a parser error on inputs like (a&lt;b&lt;c) ).</p> <p>The conflict in our example arises because the grammar is an ambiguous. Note that, a shift-reduce parser cannot successfully parse ambiguous grammars. To overcome this difficulty, YACC offers certain features like the provision for specifying the associativity (seen above) and precedence (to be seen below) that allows the use of certain ambiguous grammars.</p> <p>Consider another ambiguous grammar:</p> <pre><code>expr: expr '+' expr\n    | expr '*' expr\n    | '(' expr ')'\n    | '0'|'1'|'2'|'3'|'4'|'5'|'6'|'7'|'8'|'9'\n</code></pre> <p>When fed to YACC, it produces a warning</p> <pre><code>yacc: 4 shift/reduce conflicts.\n</code></pre> <p>The expressions 2+3+5, 2*3+5, 2+3*5 and 2*3*5 are examples that demonstrate the four different shift reduce conflict cases. In the first example, after reading 2+3 the parser must do a reduce operation because + is left associative (why?). In the third expression, the parser should not perform a reduce operation after reading 2+3 because * has higher precedence over +, whereas, in the second expression, the parser must indeed reduce after reading 2*3 (why?). Thus, the parser must be told the precedence and associativity of operators to avoid such conflicts.</p> <p>The precedence of these operators can be specified as shown below:</p> <pre><code>%left '+'   /*    '+' is left associative */\n%left '*'   /*    '*' is left associative and has higher precedence over '+' */\n</code></pre> <p>Here '*' gets higher precedence over '+' as it has been listed below the '+' operator. The declarations for the associativity of operators must be made in increasing order of precedence, with operators declared in each line assuming higher precedence over those declared above. If more than one tokens are listed on the same line, they will be assigned equal precedence.</p> <pre><code>%left '+' '-'\n%left '*' '/'\n</code></pre> <p>Here '*' and '/' have the same precedence, but both have higher precedence than '+' and '-'.</p> <p>YACC resolves shift/reduce conflicts using the precedence and associativity declarations. YACC assigns precedence and associativity for a production as well. A handle's precedence and associativity is the precedence and associativity of the last token (not non-terminal) in the handle.</p> <p>When YACC encounters a shift/reduce conflict, it shifts if the token in the input buffer has a greater precedence than the production of the handle on top of the stack and reduces if the production of the handle on top of the stack has a higher precedence than the token. If the production and the token have same precedence, it reduces if the production corresponding to the handle is left associative and shifts if they are right associative. (NOTE: If the production and token in such a case of equal precedence occur and they both are non associative, YACC reports an error).</p> STACK I/P BUFFER PARSER-ACTION EXECUTED 2 + 3 * (4 + 5) $ _ $2 + 3 * ( 4 + 5 ) $ SHIFT $expr + 3 * ( 4 + 5 ) $ REDUCE $expr + 3 * ( 4 + 5 ) $ SHIFT $expr + 3 * ( 4 + 5 ) $ SHIFT $expr + expr * ( 4 + 5) $ REDUCE <p>At the last configuration of the above table, The parser faces a shift reduce configuration. To resolve this the parser refers to the precedence declarations (Assuming precedence has been declared), and finds:</p> <pre><code>%left '+' '-'\n%left '*' '/'\n</code></pre> <p>On finding that the '*' token has a greater precedence than '+', the parser chooses to shift '*' instead of reducing the handle \u201cexpr + expr\u201d. Recall, that a handle's precedence and associativity is the precedence and associativity of the last token in the handle. Hence, the handle \u201cexpr+expr\u201d has the same precedence as its last token '+'. On comparing the precedence of \u201cexpr + expr\u201d and '*', parser finds that '*' has a greater precedence, and hence it decides to shift, resulting in the configuration:</p> STACK I/P BUFFER PARSER-ACTION EXECUTED $expr + expr * ( 4 + 5) $ SHIFT <p>And the parser continues to iterate till it reaches accept configuration.</p> <p>Note</p> <p>If the precedence and associativity declarations are not specified, YACC shifts by default to resolve a shift/reduce conflict.</p>"},{"location":"yacc/#reducereduce-conflicts","title":"reduce/reduce conflicts","text":"<p>When the parser cannot decide upon which of several possible reductions to make it faces a reduce/reduce conflict. For example, consider the following grammar:</p> <pre><code>program     :  statement\n            | conditional\nstatement   :  if boolean then stmt else stmt\n            |  stmt\nconditional :  if boolean then stmt else stmt\n</code></pre> <p>And the configuration to be:</p> <pre><code>STACK     :    $ if boolean then stmt else stmt\nI/P BUFFER:    $\n</code></pre> <p>The handle \u201cif boolean then stmt else stmt\u201d can be reduced using</p> <pre><code>statement : if boolean then stmt else stmt\n\n or\n\nconditional : if boolean then stmt else stmt\n</code></pre> <p>i.e., there are more than one possible reductions. The parser faces a conflict on deciding which of the several (two in this example) productions to reduce by. This conflict is called reduce/reduce conflict.</p> <p>Note</p> <p>Reduce-reduce conflicts are bad to have in a grammar. They are indicative of the fact that your grammar is not properly designed. Always make it a point to modify the grammar so that there are no more reduce-reduce conflicts.</p>"},{"location":"yacc/#passing-values-from-the-yylex-to-yyparse","title":"Passing values from the yylex() to yyparse()","text":"<p>The previous infix to postfix program prints the structure of the postfix expression and not the postfix expression itself. For the parser to print the postfix expression it would need the value associated with every DIGIT token. For example, the value associated with the token NUM1 in the first sample input/output is 2. The value associated with a token is called an attribute of the token. For example, 2 is an attribute value of NUM1.</p> <p>In the previous program, yylex() simply returns the token DIGIT to yyparse() and does not return any value associated with it. In order to access the value of the token DIGIT, there must be some method to return an attribute along with the token from yylex() to yyparse(). This can be achieved using a variable called yylval. The following program demonstrates the use of yylval:</p> <pre><code>%{\n\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\n%}\n\n%token DIGIT\n%left '+'\n%left '*'\n\n%%\nstart : expr '\\n'  {printf(\"\\nComplete\");exit(1);}\n ;\n\nexpr:  expr '+' expr  {printf(\"+ \");}\n | expr '*' expr  {printf(\"* \");}\n | '(' expr ')'\n | DIGIT   {printf(\"%d \",$1);}\n ;\n\n%%\n\nyyerror()\n{\n printf(\"Error\");\n}\n\nyylex()\n{\n int c;\n c = getchar();\n if(isdigit(c))\n {\n  yylval = c - '0';\n  return DIGIT;\n\n }\n return c;\n}\n\nmain()\n{\n yyparse();\n return 1;\n}\n</code></pre> <p>Sample Input/Output</p> <pre><code>I: 1+2*3\nO: 1 2 3 * +\n\nI: (2+7)*4\nO: 2 7 + 4 *\n</code></pre> <p>When yylex() recognizes a token, the YACC defined variable yylval is used to store the attribute value of a token. yylval is a global variable of the type YYSTYPE declared in y.tab.c. By default, YYSTYPE is of the type int. This is evident from the following code segment found in y.tab.c</p> <pre><code>typedef int YYSTYPE;\n</code></pre> <p>As a result, yylval (which is originally of the type YYSTYPE), has an inferred type int. It is used to return additional information about the lexeme found to the parser i.e., yylval is used to return an attribute in addition to the token to the parser.</p> <p>In the above example, the yylex() returns the token DIGIT and the value of the token in the following code segment under definition of yylex():</p> <pre><code>yylval = c - '0';\nreturn DIGIT;\n</code></pre> <p>Note that in the above code segment, the automatic type casting feature of a C compiler has been implicitly used. The attribute of a token (i.e., the value of yylval associated with the token when it was returned by yylex()) can be accessed in the action of a YACC rule using $i (where i is the position of the token in the body of a production).</p> <p>Example :</p> <pre><code>expr: DIGIT   {printf(\u201c%d\u201d,$1);}\n</code></pre> <p>The action prints the attribute associated with the token DIGIT obtained through $1.</p> <p>YYSTYPE can be re-defined to any user defined data type by the programmer in the YACC declarations section. This will allow yylex() to return attributes of types other than integer. We will learn more about customizing YYSTYPE in the later stages of this documentation.</p>"},{"location":"yacc/#exercises","title":"Exercises","text":"<p>Exercise 1</p> <p>Program to recognize nested IF control statements and display the levels of nesting.</p> <p>Exercise 2</p> <p>Program to recognize a valid variable, which starts with a letter,followed by any number of letters or digits.</p>"},{"location":"yacc/#references","title":"References","text":"<p>For further details on the topics covered in this document, the reader may refer to the following :</p> <ol> <li>Compilers : Principles,Techniques and Tools by Alfred V.Aho, Monica S. Lam, Ravi Sethi and Jeffrey D.Ulman .</li> <li>Modern Compiler Implementation in C by Andrew W.Appel</li> <li>Flex &amp; Bison by John Levine</li> <li>http://dinosaur.compilertools.net/</li> </ol>"},{"location":"ywl/","title":"USING LEX WITH YACC","text":""},{"location":"ywl/#integrating-lex-with-yacc","title":"Integrating LEX with YACC","text":"<p>In the previous documents, we have noted that YACC is used to generate a parser (YACC documentation) and LEX is used to generate a lexical analayzer (LEX documentation). YACC generates the definition for yyparse() in y.tab.c and LEX generates the definition for yylex() in lex.yy.c. We have also noted that yyparse() repetitively calls yylex() to read tokens from the input stream. Till now, for simplicity, we had written a user-defined yylex() in the YACC program. In this section of the document we will use LEX to generate the definition of yylex() and make YACC use this definition for retrieving tokens.</p> <pre><code>/* Declarations section */\n\nint yylex();\n\n%%\n\n/* Rules */\n\n%%\n\n/* Auxiliary Functions */\n</code></pre> <p>We should now compile it as gcc y.tab.c lex.yy.c -o &lt;objectfilename&amp;rt;</p> <p>Note</p> <p>We must not provide a main() definition in the LEX program calling yylex(), as there already exists a main() function in the YACC program which calls yyparse() which in turn calls yylex().</p> <p>Recall that yyparse() attempts to parse the given input by calling yylex() to obtain tokens. In the infix to postfix conversion example in the YACC documentation, we had used a user defined yylex() in the YACC program. In that example, the YACC program contains the declaration for the token DIGIT in the declarations section . The definition of the token DIGIT is given in the auxiliary functions section under the function yylex(). Instead, we will now use LEX to generate yylex().</p> <p>First, we will write a YACC program to declare the tokens and generate yyparse().</p>"},{"location":"ywl/#declaring-tokens","title":"Declaring tokens","text":"<p>The token DIGIT must be declared in the declaration section to be used in the rules section. The declaration for a token must be made by specifying it in the YACC declarations section using the %token feature offered by YACC. The following example shows the declaration of the token DIGIT in a YACC program.</p> <p>in2post.y <pre><code>%{\n      #include &lt;stdio.h&gt;\n%}\n\n%token DIGIT NEWLINE\n\n%%\n\nstart : expr NEWLINE  {\n                        printf(\"\\nComplete\\n\");\n                        exit(1);\n                      }\n  ;\n\nexpr:  expr '+' expr        {printf(\"+ \");}\n  | expr '-' expr     {printf(\"- \");}\n  | '(' expr ')'\n  | DIGIT             {printf(\"%d \",$1);}\n  ;\n\n%%\n\nvoid yyerror(char const *s)\n{\n    printf(\"yyerror  %s\\n\",s);\n    return ;\n}\nint main()\n{\n  yyparse();\n  return 1;\n}\n</code></pre></p> <p> The YACC program given above contains the declaration of the token DIGIT in the declarations section. Note that the grammar contains other terminals like '+', '-', '(' and ')' that also are tokens, but are not declared in the declaration section. These tokens are called literal tokens. Literal tokens are tokens with fixed lexemes. This means that the lexeme corresponding to a literal token is a single character or a character string. Such a token do not require an expicit declaration in the YACC program.</p> <p>Note</p> <p>Conceptually, the lexeme of a literal token can be a character or a string. But, not all versions of YACC support string literal tokens. Hence, in our project we will use only single character literal tokens.</p> <p>Examples of literal tokens:</p> <pre><code>'+' '*' '-'\n</code></pre> <p>A lexical analyzer returns a token when it finds a corresponding lexeme. In the case of a literal token, the lexical analyzer returns the lexeme itself as the token ( A type coercion to integer is done so that the value returned by yylex() is of integer type.). For example in the above YACC program, on encoutering the pattern '+' in the input file, yylex() returns '+' itself as the token.</p> <p>In the parser, an expression like :</p> <pre><code>expr: expr '+' expr\n</code></pre> <p>is valid because YACC automatically identifies '+' as the literal token.</p> <p>We must now write a LEX program that contains the regular definition for DIGIT and the literal tokens.</p>"},{"location":"ywl/#ytabh","title":"y.tab.h","text":"<p>Before writing the LEX program, there must be some way by which the YACC program can tell the LEX program that DIGIT is a valid token that has been declared in the YACC program. This communication is facilitated by the file \"y.tab.h\" which contains the declarations of all the tokens in the YACC program. The \"y.tab.h\" is automatically generated by YACC when the 'yacc' command is executed with the -d flag.</p> <p>In order to generate y.tab.c and y.tab.h for the YACC program in in2post.y, do:</p> <pre><code>user@localhost:~$ yacc -d in2post.y\n</code></pre> <p>An example of the contents of y.tab.h file is shown below.</p> <pre><code>#define DIGIT 253\n</code></pre> <p>Note that '253' is a YACC generated constant to represent DIGIT. The constant may vary at different executions of YACC. YACC represents a token by defining a macro identifier corresponding to it.</p> <p>The y.tab.h file must be included in the declarations section of the LEX program. This makes the token declarartions accessible to the LEX program. We will see an example in the next section.</p>"},{"location":"ywl/#defining-tokens","title":"Defining tokens","text":"<p>The next example example shows the definition of DIGIT and the literal tokens in the LEX program.</p> <p>in2post.l </p> <pre><code>%{\n    #include &lt;stdio.h&gt;\n   #include \"y.tab.h\"\n%}\n\n%%\n\n[0-9]+ {\n          yylval = atoi(yytext);\n          return DIGIT;\n        }\n\"+\"   return *yytext;\n\"-\"   return *yytext;\n[()]   return *yytext;\n[\\n]      return NEWLINE;\n\n%%\n\nyywrap()\n{\n return 1;\n}\n</code></pre> <p>No explicit declaration of the token DIGIT is requied in the LEX program as y.tab.h (which contains the declaration of DIGIT) has been included in the declarations section.</p> <p>Note</p> <p>As noted earlier we return the lexeme found in case of literal tokens: '+','*','(',')'. Note that yylex() is a function of return type int but the above LEX program makes yylex() return *yytext where yytext is a character pointer. *yytext de-references to the character value pointed by yytext. Returning a character value does not cause an error because the C compiler type-casts the value to integer automatically.</p> <p>To generate lex.yy.c, do:</p> <pre><code>user@localhost:~$ lex in2post.l\n</code></pre> <p>Once y.tab.c and lex.yy.c files have been generated by YACC and LEX respectively, they can be linked and compiled using the following commands as mentioned earlier. The compilation steps and sample input/output of the above example are shown below:</p> <pre><code>user@localhost:~$ gcc lex.yy.c y.tab.c -o in2post.exe\nuser@localhost:~$ ./in2post.exe\n11+22-33\n11 22 33 - +\nuser@localhost:~$\n</code></pre>"},{"location":"ywl/#passing-tokens-from-the-lexer-to-the-parser","title":"Passing tokens from the Lexer to the Parser","text":"<p>Let us consider the\u00a0YACC and\u00a0LEX programs above.</p> <p>When the input</p> <pre><code>11+22-33\n</code></pre> <p>is given to the executable file (in2post.exe)</p> <ol> <li>The main() function in y.tab.c begins execution. It calls yyparse() which inturn calls yylex() for tokens.</li> <li>yylex() reads the input and finds that \"11\" found in the input matches with the pattern for token DIGIT and returns DIGIT.</li> <li>yyparse() which obtains the token DIGIT, shifts it to the parser stack.</li> <li>A reduction (corresponding to the rule expr: DIGIT) takes place. This results in the terminal getting replaced with the non-terminal(expr) in the parser stack</li> <li>The C statement (semantic action) corresponding to the production is executed (i.e., printf(\"%d \",$1); is executed.). This prints 11.</li> </ol> <p>We will see what '$1' means and why printing '$1' results in printing the value 11 in detail in the next section.</p> <p>The execution continues in a similar fashion to complete parsing the entire input.</p> <p>A complete illustration of all the shift and reduce steps is given later. The parsing steps have been summarised in the below table for now.</p> I/P Buffer yylex() returns Parser stack Parser action on stack C Action executed Output Stream 11 + 22 - 33 _ + 22 - 33 DIGIT DIGIT SHIFT + 22 - 33 expr REDUCE printf(\"%d \",$1); 11 22 - 33 + expr + SHIFT 11 - 33 DIGIT expr + 22 SHIFT 11 - 33 expr + expr REDUCE printf(\"%d \",$1); 11 22 33 - expr + expr - SHIFT 11 22 DIGIT expr + expr - DIGIT SHIFT 11 22 0 expr + expr - expr REDUCE printf(\"%d \",$1); 11 22 33 expr + expr REDUCE printf(\"- \"); 11 22 33 - expr REDUCE printf(\"+ \"); 11 22 33 - + <p>Note that yylex() makes a call to yywrap(), when 'End of file' is encountered. We have defined yywrap() to return 1 (We have provided the definition for yywrap() in our LEX file). Recall that when yylex() receives non-zero value from yywrap(), it returns zero to yyparse(). Also recall that yyparse() does not call yylex() once it has returned 0. It return zero to main() function to indicate successful parsing.</p> <p>We have noted how to integrate the lexical analyzer generated by LEX with the parser generated by YACC. Now, we will learn more about managing attributes using LEX and YACC..</p>"},{"location":"ywl/#introduction-to-attributes","title":"Introduction to attributes","text":"<p>In the last section of the YACC documentation we have noted that it is possible to pass values associated with tokens from yylex() to yyparse(). We had described the term 'attribute' as a value associated with a token. YACC uses yylval to facilitate passing values from the lexical analyzer to the parser. We will now explore how YACC associates attribute values to terminals and non-terminals in a production. We will also explore the usage of YYSTYPE to define custom (user defined )attribute types.</p> <p>Recall that yylval is a global variable declared in y.tab.c of type YYSTYPE (YYSTYPE is integer unless defined otherwise. We will let YYSTYPE take its default type of integer since it is simpler to understand how attributes are processed in this case. Later we will see how more complex attribute types can be defined and handled).</p> <p>In the YACC documentation, we had seen an example which illustrates the passing of attributes from yylex() to yyparse(). We use the variable yylval to hold the attribute to be passed. If the programmer were to use LEX to generate yylex(), then the attributes will have to be passed to yyparse() using the same mechanism i.e, using yylval (see example below).</p> <p>In the LEX program, yylex() returns each token by its name. The attribute associated with each token is assigned to yylval and thus becomes accessible to yyparse(). Note that, all tokens except literal tokens must be declared in the declarations section of the YACC program. The following example is a LEX program which returns a token DIGIT when it finds a number.</p> <p> <pre><code>%{\n  #include \"y.tab.h\"\n  #include&lt;stdlib.h&gt;\n  #include&lt;stdio.h&gt;\n%}\n\nnumber  [0-9]+\n\n%%\n\n{number}{\n yylval = atoi(yytext);\n return DIGIT;\n  }\n\n. return *yytext;\n\n%%\n</code></pre></p> <p>In this example, we want to return the token DIGIT when an integer is found in the input stream. In addition to the token, we need to pass the value found in the input stream to yyparse(). The lexeme found in the input stream is a string which contains the integer found. atoi() is a built-in function of return type int defined in the stdlib.h header file. We use atoi() to obtain the integer equivalent of the lexeme found. The obtained integer value is then assigned to yylval.</p> <p>The following code segment demonstrates how yyparse() receives the attribute value corresponding to the token DIGIT passed by yylex(). Note that YACC must be run with the -d flag to generate y.tab.h. The LEX program above includes the y.tab.h file in the auxiliary declarations section to import the declarations from y.tab.h.</p> <pre><code>%{\n    #include &lt;stdio.h&gt;\n    int yyerror();\n%}\n\n%token DIGIT\n\n%%\n\nstart : expr '\\n' {printf(\"\\nComplete\");exit(1);}\n ;\n\nexpr:  expr '+' expr {printf(\"+ \");}\n | expr '*' expr {printf(\"* \");}\n | '(' expr ')'\n | DIGIT    {printf(\"%d \",$1);}\n ;\n\n%%\n\nint yyerror()\n{\n printf(\"Error\");\n}\n\nint main()\n{\n  yyparse();\n  return 1;\n}\n</code></pre> <p>Note the semantic action for the production <code>expr:DIGIT</code></p> <pre><code>DIGIT {printf(\"%d \",$1);}\n</code></pre> <p>The value corresponding to the token DIGIT, that was assigned to yylval by lex is accessed in YACC using the symbol $1. Recall that values corresponding to the symbols in the handle of a grammar may be accessed using $1, $2, etc according to its position in the production rule.</p> <p>Generally, we say that in the YACC program, the attribute of a grammar symbol in a production can be accessed using the following syntax: $1 for the first symbol in the body of a production, $2 for the second symbol, $3 for the third and so on. For example consider the following example of a YACC rule.</p> <pre><code>X: A B C\n</code></pre> <p>The attribute value of 'A' is accessed by the symbol $1, value of \u2018B' by $2 and 'C' can by $3. The symbol $$ refers to the attribute value of \u2018X\u2019 which is the head of the production. Note that the head of a production must be a non-terminal. Hence, it becomes possible to assign an attribute value to the head of a production by assigning a value to $$. In the above example, an attribute value can be assigned to X through an assignment to $$. Hence we extend our notion of an attribute to: \"An attribute is a value associated with a terminal or non-terminal grammar symbol\".</p> <p>We will make this clear with an example.</p> <p>Consider the problem of displaying two numbers in an input stream (ending with a \u2018\\n\u2019) if they occur as a pair separated by a comma. Also suppose that the numbers must be displayed ONLY after a pair is found. Let us look at a YACC program that solves the problem.</p> <p>Example: pair.y</p> <pre><code>%{\n  #include &lt;stdio.h&gt;\n  int yyerror();\n%}\n\n%token DIGIT\n\n%%\n\nstart : pair '\\n'  {printf(\"\\nComplete\"); }\n ;\n\npair: num ',' num { printf(\"pair(%d,%d),$1,$3\"); }\n  ;\nnum: DIGIT   { $$=$1; }\n  ;\n\n%%\n\nint yyerror()\n{\n printf(\"Error\");\n}\n\nint main()\n{\n yyparse();\n return 1;\n}\n</code></pre> <p>We will use the same lex program to receive tokens and token values (attributes).</p> <p>Note</p> <p>We have assumed that the attribute values of each symbol is an integer. Later we will see how to allow more complex attributes.</p> <p>In the above program segment, the first rule displays the value of the numbers for each pair in the input stream. In the action part of the rule, $1 refers to the attribute value of the first num and $3 refers to the attribute value of the and the second num. (Note that $2 refers to the attribute value of the\u00a0literal token\u00a0',' which is the token itself). Since num is a non-terminal, its attribute cannot be set by yylex().\u00a0Recall\u00a0that every non-terminal symbol in the CFG must have at least one production with the non-terminal as the head. The attribute value of a non-terminal must be set by writing semantic rules to set the value of $$ in such productions. Such an attribute value which is \u201csynthesized\u201d by the semantics actions in a production is called a synthesized attribute. In the example, the attribute value of the non-terminal num is synthesized by the following rule:</p> <pre><code>num: DIGIT { $$=$1; }\n</code></pre> <p>The action of the rule sets the attribute value of num (referred to using $$) to the attribute value of DIGIT (referred to using $1).</p> <p>Sample I/O:</p> <pre><code>I: 2,5 O: pair(2,5)\nI: 3,5,7 O: syntax error\n</code></pre>"},{"location":"ywl/#attribute-synthesis","title":"Attribute Synthesis","text":"<p>We have seen that attributes of terminals can be passed from yylex() to yyparse(), whereas attributes of a non-terminal can be\u00a0synthesized. An attribute of a non-terminal grammar symbol is said to be\u00a0synthesized\u00a0if it has been calculated from the attribute values of it's children in the\u00a0parse tree. Thus the (synthesized) attribute associated with a non-terminal is calculated using the attribute values of the symbols in the handle that it replaces. For example, consider the following grammar:</p> <pre><code>Z: X {printf(\"Result=%d\",$1);}\nX: A '+' B { $$ = $1 + $3; }\n</code></pre> <p>The attribute value of X is a synthesized attribute as it has been calculated using the attribute values of the symbols in the handle (A \u2018+\u2019 B) that it replaces.</p> <p>We will look at an example now.</p> <p>This is a YACC program that evaluates an expression:</p> <pre><code>%{\n  #include &lt;stdio.h&gt;\n  int yyerror();\n%}\n\n%token DIGIT\n\n%left '+'\n%left '*'\n\n%%\n\nstart : expr '\\n'  { printf(\"Expression value = %d\",$1);}\n ;\n\nexpr:  expr '+' expr  {$$ = $1 + $3;}\n | expr '*' expr  {$$ = $1 * $3;}\n | '(' expr ')'   {$$ = $2;}\n | DIGIT   {$$ = $1;}\n ;\n\n%%\n\nint yyerror()\n{\n printf(\"Error\");\n}\n\nint main()\n{\n  yyparse();\n  return 1;\n}\n</code></pre> <p>Sample I/O:</p> <pre><code>I: 2+3*(4+5)\nO: 29\n</code></pre> <p>Each of the semantic actions in the following rules synthesizes the attribute value for expr by assignment to $$.</p> <pre><code>expr: expr '+' expr {$$ = $1 + $3;}\n    | expr '*' expr {$$ = $1 * $3;}\n    | '(' expr ')' {$$ = $2;}\n    | DIGIT {$$ = $1;}\n    ;\n</code></pre> <p>We will now see how attribute synthesis is managed internally.</p>"},{"location":"ywl/#the-attribute-stack","title":"The Attribute Stack","text":"<p>Recall that YACC maintains a parse stack to achieve\u00a0shift-reduce parsing. The parse stack contains grammar symbols (both terminal and non-terminal ) representing the current\u00a0configuration of the parser. Similar to the parse stack, YACC also maintains an attribute stack to store the attribute value of each grammar symbol in the parse stack.</p> <p>The attribute stack is\u00a0synchronous\u00a0with the parse stack -- synchronous\u00a0because the i'th value on the attribute stack will be the attribute value of the i'th symbol on the parse stack.</p> <p>We will see how attribute synthesis is done on input 2+3*(4+5).</p> <ol> <li> <p>The\u00a0main() function\u00a0in y.tab.c begins execution. It calls yyparse() which in turn calls yylex() for tokens.</p> </li> <li> <p>yylex() reads the input and finds that the lexeme \"2\" matches with the pattern for the token DIGIT. It assigns \u20182\u2019 to yylval and returns DIGIT. Note that YYSTYPE is assumed to take its default value of integer and hence yylval is set to integer type by YACC.</p> </li> <li> <p>yyparse() which obtains the token DIGIT and its attribute value inside the variable yylval, shifts the token DIGIT to the parser stack and pushes the value of yylval (2) to the attribute stack.</p> <p> INITIAL PARSE STACK INITIAL ATTRIBUTE STACK </p> <p> PARSE STACK - AFTER SHIFT ATTRIBUTE STACK - AFTER SHIFT </p> </li> <li> <p>A reduction (corresponding to the rule expr: DIGIT) takes place. This results in the following events:</p> <ol> <li> <p>The terminal \u2018 DIGIT\u2019 gets replaced with the non-terminal expr in the parser stack.</p> </li> <li> <p>The semantic action {$$=$1} for the corresponding reduction is executed. (This sets the (attribute) value of the     non terminal at the head of the rule (\u2018expr\u2019) to the (attribute) value of the first symbol in the handle (DIGIT).)</p> </li> <li> <p>The value of DIGIT (2) is popped from the attribute stack and the synthesized value of \u2018expr\u2019(2) is pushed into it.</p> </li> </ol> <p>Note that at any point in the parser\u2019s execution, the symbols $1, $2, $3 etc., refers to the first, second, third etc. attribute values (of the corresponding tokens) on top of the stack. $$ refers to the attribute value of the non-terminal which is the head of the production. When the non-terminal is pushed on to the parse stack, the value of $$ is pushed on to the attribute stack. $$ refers to the symbol on top of the stack after a reduction has taken place.</p> <p> PARSE STACK - BEFORE READ ATTRIBUTE STACK - BEFORE READ </p> <p> PARSE STACK - AFTER READ ATTRIBUTE STACK - AFTER READ </p> </li> <li> <p>The parser executes a shift action. Now Lex reads and returns the token \u2018+\u2019. Since this is a literal token, its value, \u2018+\u2019 gets pushed into both the parse stack and the attribute stack after implicit type coercion .</p> <p> PARSE STACK - AFTER SHIFT ATTRIBUTE STACK - AFTER SHIFT </p> </li> <li> <p>Since there are no possible reductions to be performed, parser executes another shift operation. Lex returns the token DIGIT again as it encounters \u20183\u2019. The token DIGIT gets pushed to the parser stack and its value, \u20183\u2019, gets pushed to the attribute stack.</p> <p> PARSE STACK - AFTER SHIFT ATTRIBUTE STACK - AFTER SHIFT </p> </li> <li> <p>The reduction by the rule expr: DIGIT takes place. The token DIGIT in parse stack is replaced by \u2018expr\u2019. The semantic action {$$=$1} sets the value of \u2018expr\u2019 to \u20183. In the attribute stack, the value of DIGIT (3) gets replaced by the value of expr (3 itself).</p> <p> PARSE STACK - BEFORE READ ATTRIBUTE STACK - BEFORE READ </p> <p> PARSE STACK - AFTER READ ATTRIBUTE STACK - AFTER READ </p> </li> <li> <p>Now even though a valid reduction is possible for expr + expr, the parser executes a shift action. This is because shift/reduce conflict is resolved by looking at operator precedence. Recall shift/reduce parsing. The next token, \u2018*\u2019 is returned by Lex. This is again a literal token and is pushed into both the parse stack and attribute stack.</p> <p> PARSE STACK - AFTER SHIFT ATTRIBUTE STACK - AFTER SHIFT </p> </li> <li> <p>Since there are no matching handles in any of the rules, another shift action is executed. Lex returns \u2018(\u2018 which is again a literal token. The configuration is now</p> <p> PARSE STACK - AFTER SHIFT ATTRIBUTE STACK - AFTER SHIFT </p> </li> <li> <p>Again, there are no matching rules. So another shift action is executed. Lex returns DIGIT for \u20184\u2019.</p> <p> PARSE STACK - AFTER SHIFT ATTRIBUTE STACK - AFTER SHIFT </p> </li> <li> <p>A reduction by expr:DIGIT takes place.</p> <p> PARSE STACK - BEFORE READ ATTRIBUTE STACK - BEFORE READ </p> <p> PARSE STACK - AFTER READ ATTRIBUTE STACK - AFTER READ </p> </li> <li> <p>Since there are no matching rules, a shift action is executed. The literal token \u2018+\u2019 is returned by Lex and pushed into both stacks by YACC.</p> <p> PARSE STACK - AFTER SHIFT ATTRIBUTE STACK - AFTER SHIFT </p> </li> <li> <p>Since there are no matching rules, another shift action is executed. Lex returns DIGIT for \u20185\u2019.</p> <p> PARSE STACK - AFTER SHIFT ATTRIBUTE STACK - AFTER SHIFT </p> </li> <li> <p>A reduction by the rule expr:DIGIT takes place.</p> <p> PARSE STACK - BEFORE READ ATTRIBUTE STACK - BEFORE READ </p> <p> PARSE STACK - AFTER READ ATTRIBUTE STACK - AFTER READ </p> </li> <li> <p>The parse stack now contains \u2018expr + expr\u2019. Now a reduction by the rule expr : expr \u2018+\u2019 expr takes place. The tokens \u2018expr\u2019, \u2018+\u2019 and \u2018expr\u2019 in the parse stack are replaced by a single \u2018expr\u2019. The semantic action {$$=$1+$3} executes. $1 and $3 refer to the first and third values in the attribute stack , that is, 4 and 5 respectively. Hence the value of the head($$), \u2018expr\u2019, is set to 4+5(=9). \u20184\u2019 ,\u2019+\u2019, and \u20185\u2019 are popped out from the stack and \u20189\u2019 is pushed in.</p> </li> </ol> <p> </p> <p>PARSE STACK-BEFORE READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-BEFORE READ</p> <p> </p> <p>PARSE STACK-AFTER READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER READ</p> <ol> <li>Since there are no matching reductions, a shift action takes place. Lexer returns the literal token \u2018)\u2019 which is pushed to both parser stack and attribute stack.</li> </ol> <p> </p> <p>PARSE STACK-AFTER SHIFT \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER SHIFT</p> <ol> <li>Now a reduction by the rule expr: \u2018(\u2018 expr \u2018)\u2019 takes place. The tokens \u2018(\u2018 , expr and \u2018)\u2019 in the parser stack are replace by a single expr and the symbols \u2018(\u2018 ,\u20199\u2019 and \u2018)\u2019 in the attribute stack are replaced by \u20189\u2019. (Since the semantic action sets $$ to $2 which is \u20189\u2019).</li> </ol> <p> </p> <p>PARSE STACK-BEFORE READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-BEFORE READ</p> <p> </p> <p>PARSE STACK-AFTER READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER READ</p> <ol> <li>Now we have expr*expr on the top of the parser stack. Reduction by the rule expr: expr \u2018*\u2019 expr occurs. The tokens \u2018expr\u2019, \u2018*\u2019 and \u2018expr\u2019 are removed from the parse stack and a single \u2018expr\u2019 is pushed instead. The symbols \u20183\u2019, \u2018*\u2019 and \u20189\u2019 are replaced by \u201827\u2019 (that is, 3*9) in the attribute stack.</li> </ol> <p> </p> <p>PARSE STACK-BEFORE READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-BEFORE READ</p> <p> </p> <p>PARSE STACK-AFTER READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER READ</p> <ol> <li>Reduction by the rule expr: expr \u2018+\u2019 expr takes place. Now we have a single \u2018expr\u2019 in the parser stack and \u201829\u2019 in the attribute stack.</li> </ol> <p> </p> <p>PARSE STACK-BEFORE READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-BEFORE READ</p> <p> </p> <p>PARSE STACK-AFTER READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER READ</p> <ol> <li>Finally, lexer returns the \u2018\\n\u2019 character and the final reduction to \u2018start\u2019 occurs by the rule start: expr \u2018\\n\u2019. The semantic action prints \u201829\u2019.</li> </ol> <p> </p> <p>PARSE STACK-AFTER SHIFT \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER SHIFT</p> <p> </p> <p>PARSE STACK-BEFORE READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-BEFORE READ</p> <p>,/a  </p> <p>PARSE STACK-AFTER READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER READ</p> <ol> <li> <p>Lexer now encounters end of input (You need to enter Ctrl+D to indicate end of input as input is being read from stdout.) As a result yylex calls yywrap() which returns a non-zero value indication end of input. yylex() returns 0. (The $ in the input buffer stands for the end of input marker.)</p> </li> <li> <p>When yyparse receives 0 from lexer, it returns 0 to main function to indicate that parsing was successfull.</p> </li> </ol> <p>The following table shows the configuration of the parse stack and the attribute stack at every step of the parsing process. Assume that whenever yylex() returns a token with no attribute, yyparse() pushes a '.' to the attribute stack.</p> PARSE STACK ATTRIBUTE STACK I/P BUFFER PARSER-ACTION EXECUTED 2 + 3 * (4 + 5) $ _ DIGIT 2 + 3 * ( 4 + 5 ) $ SHIFT expr 2 + 3 * ( 4 + 5 ) $ REDUCE expr + 2 . 3 * ( 4 + 5 ) $ SHIFT expr + DIGIT 2 . 3 * ( 4 + 5 ) $ SHIFT expr + expr 2 . 3 * ( 4 + 5) $ REDUCE expr + expr * 2 . 3 . ( 4 + 5 ) $ SHIFT expr + expr * ( 2 . 3 . . 4 + 5 ) $ SHIFT expr + expr * ( DIGIT 2 . 3 . . 4 + 5 ) $ SHIFT expr + expr * ( expr 2 . 3 . . 4 + 5 ) $ REDUCE expr + expr * ( expr + 2 . 3 . . 4 . 5 ) $ SHIFT expr + expr * ( expr + DIGIT 2 . 3 . . 4 . 5 ) $ SHIFT expr + expr * ( expr + expr 2 . 3 . . 4 . 5 ) $ REDUCE expr + expr * ( expr 2 . 3 . . 9 ) $ REDUCE expr + expr * ( expr ) 2 . 3 . . 9 . $ SHIFT expr + expr * expr 2 . 3 . 9 $ REDUCE expr + expr 2 . 27 $ REDUCE expr 29 $ REDUCE $expr 29 $ ACCEPT"},{"location":"ywl/#customising-attribute-types","title":"Customising Attribute Types","text":""},{"location":"ywl/#yystype","title":"YYSTYPE","text":"<p>The attribute stack consists of attributes of tokens as well as synthesized attributes. The macro YYSTYPE denotes the type of the attribute stack. For example, in the above production, $$,$1 and $3 are all of the type YYSTYPE. YYSTYPE is int by default. The macro definition</p> <pre><code>#define YYSTYPE int\n</code></pre> <p>can be found in the y.tab.c file. YACC automatically declares yylval to be of the type YYSTYPE.</p> <p>Since by default, YACC defines YYSTYPE to be the type int, only integer valued attributes can be passed from yylex() to yyparse() using the variable yylval and only integer attributes can be synthesized by default. If we were to attempt to assign any other value to yylval or any of the attribute stack variables, a type error would be flagged on compiling y.tab.c using gcc.</p> <p>We will now see how to handle attributes of types other than integer.</p> <p>The default definition of YYSTYPE can overriden with any built-in or userdefined data type. For example if we wanted to print the prefix form of an expression:</p> <pre><code>expr: expr OP expr { printf(\"%c %c %c\",$2,$1,$3);}\n</code></pre> <p>The type of YYSTYPE can be overriden manually as shown below. The following line has to be added to the declarations section of the YACC program. This may be used (not recommended) to change the type of all the attributes from int to some other type.</p> <pre><code>#define YYSTYPE char\n</code></pre> <p>In general, YACC sets the type of yylval to that defined by YYSTYPE. Hence, in this case, only character variables and constants can be assigned to yylval.</p> <p>But in order to have multiple custom attribute values, YACC offers a useful feature called %union declaration to customize the type of YYSTYPE. %union declaration is useful when we require to have different tokens return attributes of different types using yylval. For example if we wanted some tokens to be of the type int and some tokens to be of the type char, the following code segment may be added to the declaration section of the YACC program.</p> <pre><code>/* YACC Auxiliary declarations*/\n\n/* YACC Declarations*/\n\n%union\n{\n char character;\n int integer;\n\n};\n\n%token OP\n%token NUMBER\n\n%type &lt;character&gt; OP\n%type &lt;integer&gt; NUMBER\n\n%%\n\nexpr: expr OP expr { printf(\"%c %d %d\",$&lt;character&gt;2,$&lt;integer&gt;1,$&lt;integer&gt;3); }\n    | DIGIT        { $&lt;integer&gt;$=$&lt;integer&gt;1; }\n    ;\n\n%%\n\n/* Auxiliary functions */\n</code></pre> <p>Note that the type of the attribute of each token must be mentioned when the token is being declared using the following syntax.</p> <pre><code>%token tokenname\n%type &lt;token-type&gt;\u00a0tokenname\n</code></pre> <p>'token-type' must be declared under %union prior to use in the declaration of a token. If the type of a token is not explicitly mentioned, no attribute value can be assigned to the token i.e, it is assumed to be of type\u00a0void.</p>"},{"location":"ywl/#exercise","title":"Exercise","text":"<p>Use the %union feature for doing the following exercises</p> <p>Exercise 1</p> <p>Do Infix to postfix conversion where lexemes are either operators or single characters instead of numbers.</p> <p>Sample input: a+b*c</p> <p>Sample output: abc*+</p> <p>The <code>%union</code> feature may be used as follows:</p> <pre><code>%union{\n    char c;\n}\n</code></pre> <p>Hint</p> <p>This exercise is similar to infix to postfix conversion in stage 2. Here we need to output the lexemes of a token instead of just the token names. Here each lexeme is a single character. Use yylval to pass the lexemes as the attribute values for each token.</p> <p>Exercise 2</p> <p>Do symbolic infix to postfix conversion:</p> <p>Sample input: hello+my*world</p> <p>Sample output: hello my world * +</p> <p>Exercise 3</p> <p>Do symbolic infix to prefix conversion:</p> <p>Sample input: hello+my*world</p> <p>Sample output: + hello * my world</p> <p>Important note</p> <p>Now the attribute values to be passed are strings like \u201chello\u201d. The simple way to do this is to set YYSTYPE has to be set to char* and pass strings from the lexer to the parser using yylval. To achieve this, we may declare: <pre><code>%union{\n    char *c;\n}\n</code></pre></p> <p>YACC sets the type of yylval to char*. Hence yylval can hold a pointer to a character string. Note that yytext holds the lexeme that was most recently read by yylex(). Hence, if we were to assign yytext directly to yylval, then yylval would point to this lexeme as required. When yylex() returns the token to yyparse(), this pointer gets pushed to the attribute stack corresponding to the token. However, this method fails because the location that yytext points to gets overwritten when the next lexeme is read from the input by yylex(). Hence the previously read string would be lost from that location. This corrupts the data referenced by the pointer in the attribute stack. To avoid this problem, separate memory should be allocated (using malloc) and the string in yytext should be copied (using strcpy) to this memory and yylval should be set to the newly allocated store. (Alternately the library function strdup may be used. This function allocates a new space, duplicates the string provided as input into this space and returns pointer to it.)</p>"},{"location":"ywl/#example","title":"Example","text":"<p>Let us look at an example program that creates an expression tree using union.</p> <p>Sample input: 33+42*(21-16)</p> <p>Intermediate data structure: </p> <p>Sample output: 243</p> <p>To build such a data structure, we will use a user defined type tnode containing the following fields:</p> <pre><code>int flag -  We will set this to 0 or 1 to indicate whether the node is a leaf node storing  an integer value or an internal node.\n\nint val \u2013 To store the value in case of leaf node.\n\nchar op- To store the operator in case of internal node\n\nstruct tnode *right-  To store pointer to right child.\n\nstruct tnode *left-  To store pointer to left child.\n</code></pre> <p>We will create a header file by the name exptree.h for the necessary declarations. This file is to be included in the lex and yacc programs.</p> <p>Note</p> <p>Always keep declarations in a header file, function definitions in .c file and include them in your yacc file. This would keep your code clean.</p> <p>exprtree.h</p> <pre><code>typedef struct tnode{\n int val; //value of the expression tree\n char *op; //indicates the opertor\n struct tnode *left,*right; //left and right branches\n }tnode;\n\n/*Make a leaf tnode and set the value of val field*/\nstruct tnode* makeLeafNode(int n);\n\n/*Make a tnode with opertor, left and right branches set*/\nstruct tnode* makeOperatorNode(char c,struct tnode *l,struct tnode *r);\n\n/*To evaluate an expression tree*/\nint evaluate(struct tnode *t);\n</code></pre> <p>As the lexer scans the input, it should recognise two types of tokens \u2013 numbers and operators. ( In the following example we have used literal tokens to indicate each of the operators '+' , '-', '*', '/'. ) The attribute value corresponding to these tokens can be made to indicate which number/operator was read. We will pack this information in the node structure tnode mentioned above .</p> <p>exprtree.l</p> <pre><code>%{\n #include &lt;stdlib.h&gt;\n #include &lt;stdio.h&gt;\n #include \"y.tab.h\"\n #include \"exprtree.h\"\n\n int number;\n\n%}\n\n%%\n\n[0-9]+ {number = atoi(yytext); yylval.no = makeLeafNode(number); return NUM;}\n\"+\" {return PLUS;}\n\"-\" {return MINUS;}\n\"*\" {return MUL;}\n\"/\" {return DIV;}\n[ \\t] {}\n[()] {return *yytext;}\n[\\n] {return END;}\n. {yyerror(\"unknown character\\n\");exit(1);}\n\n%%\n\nint yywrap(void) {\n return 1;\n}\n</code></pre> <p>Notice that yylval is assigned a pointer to newly allocated (using malloc) node of type node. For each token that is a number (DIGIT) or operator(returned as literal tokens '+', '-' , '*', '/' ) that is recognized by the lexer, we pack the information in a node structure and a pointer to this node is passed as attribute to the parser. During reductions, the semantic actions specified in the parser will set the left and the right pointers of these nodes appropriately to complete the creation of the expression tree. We will see how these actions are executed in detail next.</p> <p>exprtree.y</p> <pre><code>%{\n #include &lt;stdlib.h&gt;\n #include &lt;stdio.h&gt;\n #include \"exprtree.h\"\n #include \"exprtree.c\"\n int yylex(void);\n%}\n\n%union{\n struct tnode *no;\n\n}\n%type &lt;no&gt; expr NUM program END\n%token NUM PLUS MINUS MUL DIV END\n%left PLUS MINUS\n%left MUL DIV\n\n%%\n\nprogram : expr END {\n    $$ = $2;\n    printf(\"Answer : %d\\n\",evaluate($1));\n\n    exit(1);\n   }\n  ;\n\nexpr : expr PLUS expr  {$$ = makeOperatorNode('+',$1,$3);}\n  | expr MINUS expr   {$$ = makeOperatorNode('-',$1,$3);}\n  | expr MUL expr {$$ = makeOperatorNode('*',$1,$3);}\n  | expr DIV expr {$$ = makeOperatorNode('/',$1,$3);}\n  | '(' expr ')'  {$$ = $2;}\n  | NUM   {$$ = $1;}\n  ;\n\n%%\n\nyyerror(char const *s)\n{\n    printf(\"yyerror %s\",s);\n}\n\n\nint main(void) {\n yyparse();\n\n return 0;\n}\n</code></pre> <p>The following .c file gives the required function definitions. exprtree.c</p> <pre><code>struct tnode* makeLeafNode(int n)\n{\n    struct tnode *temp;\n    temp = (struct tnode*)malloc(sizeof(struct tnode));\n    temp-&gt;op = NULL;\n    temp-&gt;val = n;\n    temp-&gt;left = NULL;\n    temp-&gt;right = NULL;\n    return temp;\n}\n\nstruct tnode* makeOperatorNode(char c,struct tnode *l,struct tnode *r){\n    struct tnode *temp;\n    temp = (struct tnode*)malloc(sizeof(struct tnode));\n    temp-&gt;op = malloc(sizeof(char));\n    *(temp-&gt;op) = c;\n    temp-&gt;left = l;\n    temp-&gt;right = r;\n    return temp;\n}\n\nint evaluate(struct tnode *t){\n    if(t-&gt;op == NULL)\n    {\n        return t-&gt;val;\n    }\n    else{\n        switch(*(t-&gt;op)){\n            case '+' : return evaluate(t-&gt;left) + evaluate(t-&gt;right);\n                       break;\n            case '-' : return evaluate(t-&gt;left) - evaluate(t-&gt;right);\n                       break;\n            case '*' : return evaluate(t-&gt;left) * evaluate(t-&gt;right);\n                       break;\n            case '/' : return evaluate(t-&gt;left) / evaluate(t-&gt;right);\n                       break;\n        }\n    }\n}\n</code></pre> <p>Let us now see how the expression tree for the sample input 33+42*(21 - 16) was created.</p> <p>1. On reading the lexeme 33, the lexer recognizes the lexeme as a DIGIT and creates a node, setting its val field to 33. The flag field is set to 0 indicating that the node contains an integer. This node is passed to the parser by setting yylval to a pointer to this node. The token DIGIT is returned by the lexer to the parser. This means that this pointer is pushed into the attribute stack as the value corresponding to the token DIGIT pushed into the parser stack. Note that we have set YYSTYPE to node * so that the attribute stack can hold a pointer to a node structure.</p> <p> </p> <p>PARSE STACK-AFTER SHIFT \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER SHIFT</p> <p>2. Yacc reduces DIGIT to expr following the rule expr : DIGIT and sets the attribute value of expr to the attribute value of INTEGER which is the pointer to the node containing 3. Yacc then calls yylex for the next token.</p> <p> </p> <p>PARSE STACK-AFTER READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER READ</p> <p>3. On reading + lexer creates a node and sets its op field to +. The flag field is set to 1 indicating that the node contains an operator. This node is passed to the parser by setting yylval to a pointer to this node.</p> <p> </p> <p>PARSE STACK-AFTER SHIFT \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER SHIFT</p> <p>4. Since no rule in matched in YACC, yylex is called for the next token.</p> <p>5. Similar to step 1, the Lexer returns a node containing 42 and a reduction similar to step 2 takes place in the parser.</p> <p> </p> <p>PARSE STACK-AFTER SHIFT \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER SHIFT</p> <p> </p> <p>PARSE STACK-AFTER READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER READ</p> <p>Note that the reduction expr : expr \u2018+\u2019 expr does not take place since * has higher precedence over +. The look-ahead hence tells the parser to shift and not reduce [LINK].</p> <p>6. \u2018*\u2019 is read and returned similar to step 3. No reduction takes place in YACC since there are no matching rules.</p> <p> </p> <p>PARSE STACK-AFTER SHIFT \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER SHIFT</p> <p>7. The literal token \u2018(\u2018 is read by lexer and passed to YACC. Again, no reduction takes place.</p> <p> </p> <p>PARSE STACK-AFTER SHIFT \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER SHIFT</p> <p>8. The integer 21 is read passed to YACC and subsequent reduction takes place similar to steps 1 and 2.</p> <p> </p> <p>PARSE STACK-AFTER SHIFT \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER SHIFT</p> <p> </p> <p>PARSE STACK-AFTER READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER READ</p> <p>9. The operator \u2018-\u2018 is read passed to YACC similar to step 3.</p> <p> </p> <p>PARSE STACK-AFTER SHIFT \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER SHIFT</p> <p>10. The integer 16 is read passed to YACC and subsequent reduction takes place similar to steps 1 and 2.</p> <p> </p> <p>PARSE STACK-AFTER SHIFT \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER SHIFT</p> <p> </p> <p>PARSE STACK-AFTER READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER READ</p> <p>11. Now the reduction expr: expr \u2018-\u2018 expr can take place. The nodes containing 21 and 16 are set to the l and r fields of the node containing \u2018-\u2018 and the pointer to \u2018-\u2018 is now the attribute value of the head. The bottom most part of the tree has been created.</p> <p> </p> <p>PARSE STACK-AFTER READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER READ</p> <p>12. The literal token \u2018(\u2018 is read and returned. The reduction expr: \u2018(\u2018 expr \u2018)\u2019 can now take place. Note how operator precedence is overridden using parentheses.</p> <p> </p> <p>PARSE STACK-AFTER SHIFT \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER SHIFT</p> <p> </p> <p>PARSE STACK-AFTER READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER READ</p> <p>13. Now the reduction expr: expr \u2018*\u2018 expr can take place. The nodes containing 4 and \u2018-\u2018 are set to the l and r fields of the node containing \u2018*\u2018 and the pointer to \u2018*\u2018 is now the attribute value of the head. The tree now looks like this:</p> <p> </p> <p>PARSE STACK-AFTER READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER READ</p> <p>14. Now the reduction expr: expr \u2018+\u2018 expr can take place. The nodes containing 33 and \u2018*\u2018 are set to the l and r fields of the node containing \u2018+\u2018 and the pointer to \u2018+\u2018 is now the attribute value of the head. The whole tree now looks like this: has been created.</p> <p> </p> <p>PARSE STACK-AFTER READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER READ</p> <p>15. Lexer now reads \u2018\\n\u2019 and finally the reduction program: expr \u2018\\n\u2019 takes place and the function evaluate is called with the rot node containing \u2018+\u2019 passed as argument.</p> <p> </p> <p>PARSE STACK-AFTER SHIFT \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER SHIFT</p> <p> </p> <p>PARSE STACK-AFTER READ \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ATTRIBUTE STACK-AFTER READ</p> <p>16. An inorder evaluation of the tree returns 243 which is printed as result.</p>"},{"location":"ywl/#references","title":"References","text":"<p>For further details on the topics covered in this document, the reader may refer to the following :</p> <ol> <li>Compilers : Principles,Techniques and Tools by Alfred V.Aho, Monica S. Lam, Ravi Sethi and Jeffrey D.Ulman .</li> <li>Modern Compiler Implementation in C by Andrew W.Appel</li> <li>Flex &amp; Bison by John Levine</li> <li>http://dinosaur.compilertools.net/</li> </ol>"},{"location":"about/authors/","title":"Authors","text":"<p>The content in the website and the documentation has been authored in the Department of Computer Science and Engineering, National Institute of Technology, Calicut under the guidance of Dr. Murali Krishnan K. The project's activity started in the year 2013 and completed in the year 2018. Below is a list of co-authors and contributors to the project. The work evolved from an earlier version of the project a Simple Integer Language Compiler development student project under the guidance of Dr. Murali Krishnan K. and Dr. Vineeth Paleri. The work received technical support from Dr. Vineeth Paleri and Dr. Saleena N. .</p>"},{"location":"about/authors/#project-team-2017-2018","title":"Project team (2017-2018)","text":"<ul> <li>Jaini Phani Koushik</li> <li>Jampala Ritesh</li> <li>Madisetty Jayaprakash</li> <li>Subin Puleri</li> </ul>"},{"location":"about/authors/#project-team-2016-2017","title":"Project team (2016-2017)","text":"<ul> <li>Thallam Sai Sree Datta</li> <li>N Ruthvik</li> </ul>"},{"location":"about/authors/#project-team-2015-2016","title":"Project team (2015-2016)","text":"<ul> <li>Nunnaguppala Surya Harsha</li> <li>Vishnu Priya Matha</li> </ul>"},{"location":"about/authors/#project-team-2014-2015","title":"Project team (2014-2015)","text":"<ul> <li>Ashwathy T Revi</li> <li>Subisha V</li> </ul>"},{"location":"about/authors/#project-team-2013-2014","title":"Project team (2013-2014)","text":"<ul> <li>Nachiappan V.</li> <li>Arun Rajan</li> </ul>"},{"location":"about/authors/#project-team-2001-2002","title":"Project team (2001-2002)","text":"<ul> <li>Jithesh Kumar O. V</li> <li>Dileep Mathew Thomas</li> </ul>"},{"location":"about/authors/#technical-contributors","title":"Technical Contributors","text":"<ul> <li>Peeyush Singh</li> <li>C.H. Vishal</li> </ul> <p>Please send queries and bug reports to kmuralinitc@gmail.com</p>"},{"location":"about/license/","title":"License","text":"<p>SILCNITC by Dr. Murali Krishnan K, Department of Computer Science and Engineering, National Institute of Technology, Calicut is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</p> <p>Based on a work at https://github.com/silcnitc</p>"},{"location":"about/philosophy/","title":"Philosophy","text":"<p>Any pedagogical compiler implementation project offered as part of an undergraduate junior level compiler design course needs to satisfy two fundamental requirements:  </p> <ol> <li> <p>The student must be given as much depth and detail as possible about the central concepts. That is, the project must be sufficiently non-trivial to be instructive.</p> </li> <li> <p>The quantity of work involved must not exceed what a student is able to complete in about four months, taking also into consideration the fact that she/he would be crediting several other courses concurrently. Thus, the project must be sufficiently simple to be do-able.</p> </li> </ol> <p>The problem before the teacher is to decide on how much compromise on (1) must be done in favour of (2). The present project is our stance in this matter. We expain our choices here.</p> <p>There are two aspects associated with the design and implementation of each major functional unit of a compiler. \u2013 1) A Policy and 2) An implementation Mechanism. As an illustration, consider dynamic memory allocation. Fixed size allocation is a policy. The most common implementation mechanism is to have a run time library that manages allocation from the the heap. As another example, consider passing of parameters to functions. Call by value/call by reference are a policies. Passing values/addresses through a run time stack is the standard implementation mechanism. Yet another example, a language may describe a dynamic method binding policy for supporting subtype polymorphism in single inheritence hierarchy. Virtual function table mechanism is the most common way to implement the policy. Of course, each of the above policies and mechanisms need more detailed and concrete specification. Detailed descriptions of the policies and mechanisms associated with various functions of a compiler are given in the project documentation.</p> <p>The pedagogical strategy is to specify a programming language that has a very simple policy associated with functional unit of the compiler. This allows the student to implement the policy easily, once the implementation mechanism is understood. For instance, fixed-size allocation policy is specified for dynamic memory allocation. We provide detailed tutorials for various implementation mechanisms necessary to implement the policies associated with each such functional unit of the compiler. This helps the student to learn the implementation mechanisms quickly. Once the student completes the implementation one simple policy that uses a particular mechanism, she will be in a position to visualize the implementation of more sophisticated policies associated with a particular functionality that use similar mechanisms without actually going through an implementation project.</p> <p>The project is designed to be done concurrently with a theory course in Compiler Design, typically offered during the third year of an undergraduate CS curriculum. It by no means is a replacement to the theory course, but is only designed to suppliment it. The project will help in solidifying the student's grasp of compiler design theory - about how the components of a compiler can be assembled together to form the whole. The student will experience the end-to-end process of translation from a high level language source to a target executable. The road-map is designed in such a way that as far as practicable, only one new concept is introduced at a time.</p> <p>It is our responsiblity to explicitly state some central concepts that the project fails to teach. Here are some key omissions:  </p> <ol> <li> <p>The machine architecture, virtual memory model (and the the target ABI in general) are unrealisitically simple and custom made. Consequently it is easy to generate code for the target platfform, but the platform is far from any real system. To illustrate the level of oversimplification, a memory word of the target machine is assumed to be capable of storing an arbitrary interger or a string. Floating point handling is ommitted. The executable file format is extremely simple to understand, but too restrictive for real use. (There are simplifications in the source language specification as well, but those are less dramatic.)</p> </li> <li> <p>The project is front-end intensive, but has a thin back-end. Code, register or memory optimizations are not attempted. The focus here is to get working target code generated as easily as possible. The roadmap asks the students to directly traverse an intermediete abstract syntax tree representation of the program and generate assembly language code. This is followed by a linking phase to resolve labels in the target code. Improving the back-end code generation process would require data flow analysis (at least liveliness analysis) which is better done with the support of tools like LLVM. Going into these directions would make the project too heavy for one semester. Typically, a second course in compiler design takes up these topics anyway.</p> </li> <li> <p>Focus has not been placed on efficient data structuring or following software engineering practices religiously. The road-map suggests a simple implementation that can be built incrementally.</p> </li> </ol> <p>The project is designed to help the student to gain knowledge, appreciation and insight into the working of compilers, but does not try to train the student in professional compiler writing. This particular pedagogical choice has been taken to spare the student from the technicalities of machine architecture, executable/object formats and the complexities of the ABIs of real systems \u2013 something that in our experience seems to drive a lot of students away from systems projects. Our hope is that once the basic material is assimilated, the student will be more confident to get involved with these details in professional life.</p> <p>Feedback data collected from students who credited the course is summarized here.</p> <p>This project is the second one in a suite of two student learning projects designed to tutor undergraduate CS juniors. The first one in the suite is an OS development project (exposnitc.github.io), which asks the student to implement a simple multi-tasking operating system on the same machine architecture used in the present project. The target code of the compiler implemented in the present project is designed to be executable by the OS implemented in the first project. Our hope is that by going through the projects, the student will gain a clear conceptual understanding of how the two central software systems \u2013 the OS and the compiler - work together in a computer system.</p>"},{"location":"data_structures/abstract-syntax-tree/","title":"Abstract Syntax Tree","text":""},{"location":"data_structures/abstract-syntax-tree/#introduction","title":"Introduction","text":"<p>The machine independent front-end phase of a compiler constructs an intermediate representation of the source program called the Abstract Syntax Tree (AST).This is followed by a machine dependent back-end that generates a target assembly language program.</p>"},{"location":"data_structures/abstract-syntax-tree/#structure","title":"Structure","text":"<p>The node structure of Abstract Syntax Tree is as follows: <pre><code>struct ASTNode{\n    struct Typetable *type;           //pointer to the type table entry\n    int nodetype;                     //node type information,eg:NODETYPE_WHILE,NODETYPE_PLUS,NODETYPE_STMT etc\n    char *name;                       //stores the variable/function name in case of variable/function nodes\n    union Constant value;             //stores the value of the constant if the node corresponds to a constant\n    struct ASTNode *arglist;          //pointer to the expression list given as arguments to a function call\n    struct ASTNode *ptr1,*ptr2,*ptr3; //Subtrees of the node. (Maximum Subtrees for IF THEN ELSE)\n    struct Gsymbol *Gentry;           //pointer to GST entry for global variables and functions\n    struct Lsymbol *Lentry;           //pointer to the function's LST for local variables and arguements\n};\n</code></pre></p> <p>The union Constant is used to store the value of an integer or sting constant. <pre><code>union Constant{\n    int intval;\n    char* strval;\n};\n</code></pre></p>"},{"location":"data_structures/abstract-syntax-tree/#associated-methods","title":"Associated Methods","text":""},{"location":"data_structures/abstract-syntax-tree/#treecreate","title":"TreeCreate","text":"<p><pre><code>struct ASTNode* TreeCreate(\n    struct Typetable *type,\n    int nodetype,\n    char *name,\n    union Constant value,\n    struct ASTNode *arglist,\n    struct ASTNode *ptr1,\n    struct ASTNode *ptr2,\n    struct ASTNode *ptr3\n)\n</code></pre> Creates a node with the fields set according to the arguments passed. The function must be responsible for doing type checking, and will be successful only if the expression tree corresponds to an ExpL statement (or ExpL expression) with no syntax or semantic errors. The function returns a pointer to the root node of the AST upon success, NULL is returned otherwise. The arguments to the function includes pointers to the subtrees of the AST node (which must have been created earlier). Other arguments include the type of the ExpL expression represented by the AST node, a node type (described below) etc.</p> <p>The type field of an AST node is designed to contain a pointer to the typetable entry corresponding to the type of the expression represented by the AST node (The type is set to void for statements). The type and nodetype fields of an AST node may be assigned values according to the following convension. If an expression evaluates to NULL, its type must be set to void.</p> Nodetype Type Description CONST int/str For interger and string constants. As a special case, if the constant is NULL, the type is set to void. ID int/str/user-defined type For all variable literals. PLUS/MINUS/MUL/DIV int For arithmetic operators '+', '-', '*', '/', '%'.  'ptr1' and 'ptr2' must be of type int and set to the AST's of the left and the right operands respectively. GT/LT/GE/LE boolean For relational operators '&gt;', '&lt;', '&gt;=', '&lt;='. 'ptr1' and 'ptr2' must be of type int and set to the AST's of the left and the right operands respectively. EQ/NE boolean For relational operator '==' or '!='. 'ptr1' and 'ptr2' must be set to AST of the left and the right operands respectively and both must be of the same type. IF void For the conditional construct 'if'. 'ptr1' must be set to the AST of the logical expression and must be of type 'boolean', 'ptr2' must be set to the AST of list of statements corresponding to the 'then part' and 'ptr3' must be  set to the AST of list of statements corresponding to the 'else part'. WHILE void For conditional construct 'while'. 'ptr1' is set to the conditional logical expression and 'ptr2' is set to AST of list of statements under the body of while construct. READ void For input statement 'read', 'ptr1' must have nodetype ID or FIELD and type of 'ptr1' must be either 'int' or 'str'. WRITE void For output statement 'write', 'ptr1' must be of type 'int' and 'str' and must be set to AST of the expression whose value is to be written to the standard output. ASGN void For assignment statement (&lt;var&gt; = &lt;expr&gt;).  'ptr1' must be set to an AST of nodetype ID or FIELD and 'ptr2' must be set to an AST of expression whose value will be assigned to lvalue given by 'ptr1'. The types of the variable and the expression must match. SLIST void To form a tree with multiple statements. The execution semantics is that the sequence of statements represented by the left subtree 'ptr1' must be evaluated before evaluating 'ptr2'. BODY int/str/user-defined type For body of a function, type indicates the return type of the function. This is created when the definition of a function is processed. RET int/str/user-defined type For return statement of a function. FUNCTION int/str/user-defined type For function calls. The type must be same as the return type of the function. The field 'arglist' must be set to list of arguments for the function. MAIN int For main function. FIELD int/str/user-defined type For user-defined types,( to handle expressions of the form ID . ID, ID . ID . ID , etc)."},{"location":"data_structures/abstract-syntax-tree/#illustration","title":"Illustration","text":"<p>Consider the following program <pre><code>decl\n    int result,factorial(int n);\nenddecl\nint factorial(int n){\n    decl\n        int f;\n    enddecl\n    begin\n        if( n==1 || n==0 ) then\n            f = 1;\n        else\n            f = n * factorial(n-1);\n        endif;\n        return f;\n    end\n}\nint main(){\n    decl\n        int a;\n    enddecl\n    begin\n        read(a);\n        result = factorial(a);\n        write(result);\n        return 1;\n    end\n}\n</code></pre></p> <ol> <li> <p>Lets construct the abstract syntax tree step by step. The AST for conditional expression <code>n==1</code> (in line 9) will be as follows:     </p> </li> <li> <p>Similarly we have AST fot <code>n==0</code> (in line 9) as follows.</p> <p></p> </li> <li> <p>Next consider the complete conditional expression <code>n==1 || n==0</code>.</p> <p></p> </li> <li> <p>Next we will form the AST for assignment statement <code>f = 1</code> (in line 10).</p> <p></p> </li> <li> <p>Next, lets consider the statement <code>f = n * factorial(n-1)</code> which consists of arthimetic expressions with operands '-','*' and an assignment statement.     AST for <code>n-1</code> is as follows.</p> <p></p> <p>AST for <code>n * factorial(n-1)</code> is as follows.</p> <p></p> <p>AST for <code>f = n * factorial(n-1)</code> is as below.</p> <p></p> </li> <li> <p>Following is the AST for the if condition.</p> <p></p> </li> <li> <p>The AST for return statement is as folows</p> <p></p> </li> <li> <p>Finally the AST for the factorial function will be as follows.</p> <p></p> </li> </ol>"},{"location":"data_structures/global-symbol-table/","title":"Global Symbol Table","text":""},{"location":"data_structures/global-symbol-table/#introduction","title":"Introduction","text":"<p>The global symbol table stores information pertaining to all the global variables and functions in an ExpL program.</p>"},{"location":"data_structures/global-symbol-table/#structure","title":"Structure","text":"<p>The structure of Global Symbol Table(GST) is as follows:</p> <pre><code>struct Gsymbol{\n    char *name;               //name of the variable or function\n    struct Typetable *type;   //pointer to the Typetable entry of variable type/return type of the function\n    struct Classtable *Ctype;  //THIS FIELD IS REQUIRED ONLY FOR OEXPL\n    int size;                 //size of an array. (The sizes of all other variables in 1)\n    int binding;              //stores memory address allocated to the variable\n    struct Argstruct *arglist;//pointer to the head of argument list in case of functions\n    struct ASTNode *fbinding; //pointer to the root of the abstract syntax tree of the function\n                            //In case of compiler, the call address must be stored in fbinding\n    struct Gsymbol *next;     //points to the next Global Symbol Table entry\n};\n</code></pre> <p>Note</p> <p><code>flabel</code> is a placeholder for the starting address of the function's code in memory. Any call to the function must translate into an assembly level call to this address. When the compiler makes the symbol table entry for a function during function declaration, the actual starting address is not determined, and instead a pseudo address is assigned to flabel. A call to the function will be initially translated by the compiler to a call to this pseudo address. The actual memory address will be determined later (often in a separate pass) and the compiler will replace all pseudo labels with the correct addresses. Here, we assume that the compiler assigns for each function a unique integer in the flabel field of the global symbol table as its function identifier or \"pseudo-address\". Thus, the pseudo-address can be used to identify the function during the label translation phase. When the compiler generates code, more human readable labels like F0, F1, F2, F3, ... are assigned to functions whose flabel field is set to pseudo-addresses 0, 1,2,3,...</p> <p><code>Paramlist</code> is used to store information regarding the types and names of the parameters. ParamStruct has the following structure. <pre><code>struct Paramstruct{\n    char *name;          //stores the name of the parameter\n    struct Typetable *type;  //pointer to type table entry of parameter type\n    struct Paramstruct *next;  //pointer to the next parameter\n};\n</code></pre></p>"},{"location":"data_structures/global-symbol-table/#associated-methods","title":"Associated Methods","text":"<ul> <li><code>struct Gsymbol* GInstall(char *name,struct Typetable *type, int size, struct ParamStruct *paramlist)</code>: Creates a Global Symbol entry of given 'name', 'type', 'size' and 'parameter list' and assigns a static address('binding') to the variable (or label for the function).</li> <li><code>struct Gsymbol* GLookup(char *name)</code> : Search for a GST entry with the given 'name', if exists, return pointer to GST entry else return NULL.</li> </ul>"},{"location":"data_structures/global-symbol-table/#illustration","title":"Illustration","text":"<p>Continuing with earlier example, let us add Global declaration section to it.</p> <pre><code>type\n    linkedlist{\n        int data;\n        linkedlist next;\n    }\n    marklist{\n        str name;\n        linkedlist marks;\n    }\nendtype\ndecl\n    str studentname;\n    int rollno,average,findaverage(linkedlist marks);\n    marklist studentmarks;\nenddecl\n</code></pre> <ol> <li> <p>As soon as the compiler encounters the global declaration of a variable or funtion, it is installed into the Global Symbol Table.     Subsequently, the parameters are attached to the entry in the case of functions. Following is how GST looks when studentname is installed.</p> <p></p> </li> <li> <p>Similarly for rollno,average,findaverage(linkedlist marks), symbol table entries are formed and installed.  </p> <p></p> </li> <li> <p>The final Global Symbol table looks as follows:  </p> <p></p> </li> </ol>"},{"location":"data_structures/local-symbol-table/","title":"Local Symbol Table","text":""},{"location":"data_structures/local-symbol-table/#introduction","title":"Introduction","text":"<p>In addition to the global symbol table, the ExpL compiler maintains a separate local symbol table for each function for storing information regarding the arguments and local variables. Each function has its own list of local variables. So each function has its own Local Symbol Table.</p>"},{"location":"data_structures/local-symbol-table/#structure","title":"Structure","text":"<pre><code>struct Lsymbol{\n    char *name;               //name of the variable\n    struct Typetable *type;   //pointer to the Typetable entry of variable type\n    int binding;              //stores memory address allocated to the variable\n    struct Lsymbol *next;     //points to the next Local Symbol Table entry\n};\n</code></pre>"},{"location":"data_structures/local-symbol-table/#associated-methods","title":"Associated Methods","text":"<ul> <li><code>struct Lsymbol* LInstall(char *name,struct Typetable *type)</code>:  Creates a local symbol table with given 'name' and 'type' and also sets its 'binding'.</li> <li><code>struct Lsymbol* LLookup(char *name)</code> : search the LST and if any entry with given 'name' is found ,return the entry,else returns NULL.</li> </ul> <p>Memory is allocated for local variables of a function from a seperate memory area called the stack. Hence, the binding for a local variable is the relative address of the variable with respect to the base of the activation record for the function. A machine register called the base pointer points to the base of an activation record of a function. The binding is added to the base pointer to obtain the address of a variable in the stack.</p>"},{"location":"data_structures/type-table/","title":"TypeTable","text":""},{"location":"data_structures/type-table/#introduction","title":"Introduction","text":"<p>The Type Table stores information regarding the various user defined types in the source program. The compiler creates an entry in the Type Table for each user defined type. In addition to this, there are default entries created for primitive types (int, str, boolean) and special entries null and void for the internal purposes of the compiler. The default and special entries are made beforehand whereas entries for user defined types are made as the Type Definition section of the input ExpL program is processed.</p>"},{"location":"data_structures/type-table/#structure","title":"Structure","text":"<p>The structure of Type Table is as follows: <pre><code>struct Typetable{\n    char *name;                 //type name\n    int size;                   //size of the type\n    struct Fieldlist *fields;   //pointer to the head of fields list\n    struct Typetable *next;     // pointer to the next type table entry\n};\n</code></pre></p> <p>The variable 'fields' is a pointer to the head of 'fieldlist'. Here 'fieldlist' stores the information regarding the different fields of a user-defined type. <pre><code>struct Fieldlist{\n  char *name;              //name of the field\n  int fieldIndex;          //the position of the field in the field list\n  struct Typetable *type;  //pointer to type table entry of the field's type\n  struct Fieldlist *next;  //pointer to the next field\n};\n</code></pre></p>"},{"location":"data_structures/type-table/#associated-methods","title":"Associated Methods","text":"<ul> <li><code>void TypeTableCreate()</code>: Function to initialise the type table entries with primitive types (int,str) and special entries_(boolean,null,void).</li> <li><code>struct Typetable* TLookup(char *name)</code> : Search through the type table and return pointer to type table entry of type 'name'. Returns NULL if entry is not found.</li> <li><code>struct Typetable* TInstall(char *name,int size, struct Fieldlist *fields)</code> : Creates a type table entry for the (user defined) type of 'name' with given 'fields' and returns the pointer to the type table entry. The field list must specify the field index, type and name of each field. TInstall returns NULL upon failure. This routine is invoked when the compiler encounters a type definition in the source program.</li> <li><code>struct Fieldlist* FLookup(Typetable *type, char *name)</code>: Searches for a field of given 'name' in the 'fieldlist' of the given user-defined type and returns a pointer to the field entry. Returns NULL if the type does not have a field of the name.</li> <li><code>int GetSize(Typetable * type)</code> : Returns the amount of memory words required to store a variable of the given type.</li> </ul>"},{"location":"data_structures/type-table/#illustration","title":"Illustration","text":"<p>Let us consider the following sample code: <pre><code>type\n  linkedlist{\n    int data;\n    linkedlist next;\n  }\n  marklist{\n    str name;\n    linkedlist marks;\n  }\nendtype\n//...Global Declarations..\n//...Functions....\n</code></pre></p> <ol> <li> <p>The type table is first created and initialised to contain the default entries for each of the primitive and internal datatypes.     This is done through a call to the function TypeTableCreate() from main function before yyparse() is called to start parsing the code.     After the execution of TypeTableCreate() , the type table will be as follows:</p> <p></p> <p>Note</p> <p>The size field has been left out in the figure below.</p> </li> <li> <p>After entry is created for linked list, the type would appear as shown below.</p> <p></p> </li> <li> <p>Similar actions are carried out for user-defined type marklist as well.</p> <p></p> </li> <li> <p>Once the type declaration section in the input ExpL program, the type table is fully created and will not be changed later.</p> </li> </ol>"},{"location":"feedback/nitc-winter-2017/","title":"Winter 2017, B.Tech Semester 6 Compiler Lab, NIT Calicut","text":"<p>Total number of students crediting the course: 30. </p> <p>Duration of the course: One semester (13 weeks). Credit Units: 3 </p> <p>A feedback questionnaire was circulated to all the students who credited the course one week before the end of the semester. The responses are summarized below.</p> <p>Major stages of the Project (Each Stage subsumes the previous Stages):</p> <ul> <li>Stage 4: Imperative programs without functions. Data types: variables and arrays of integer/string type.</li> <li>Stage 5: Imperative programs with functions and recursion. Data types: variables and arrays of integer/string types.</li> <li>Stage 6: Imperative programs with support for user defined types and dynamic memory allocation.</li> <li>Stage 8: Object oriented programming support for classes and single inheritance.</li> </ul>"},{"location":"feedback/nitc-winter-2017/#q1-student-performance-how-many-stages-of-the-project-did-you-complete","title":"Q1. Student Performance: How many stages of the project did you complete?","text":"<p>Note</p> <p>Every student who completed stage 7 also completed stage 8.</p>"},{"location":"feedback/nitc-winter-2017/#q2-time-management-how-many-hours-of-work-did-you-put-into-the-project-per-week-on-an-average-to-complete-up-to-what-you-have-done","title":"Q2. Time Management: How many hours of work did you put into the project per week on an average to complete up to what you have done?","text":"All Students Students who finished stage 5 or above"},{"location":"feedback/nitc-winter-2017/#q3-effectiveness-of-road-map-what-percentage-of-work-could-be-done-without-having-to-refer-to-material-outside-the-roadmapdocumentation-of-project","title":"Q3. Effectiveness of road map: What percentage of work could be done without having to refer to material outside the roadmap/documentation of project ?","text":"All Students Students who finished stage 5 or above"},{"location":"feedback/nitc-winter-2017/#q4-contribution-to-understanding-of-theory-how-much-did-the-lab-help-to-improve-your-understanding-of-compiler-design-theory","title":"Q4: Contribution to understanding of theory: How much did the lab help to improve your understanding of compiler design theory?","text":"All Students Students who finished stage 5 or above"},{"location":"feedback/nitc-winter-2017/#q5-contribution-to-programming-skills-how-far-did-this-lab-contribute-to-the-improvement-of-your-coding-software-development-skills","title":"Q5: Contribution to Programming skills: How far did this lab contribute to the improvement of your coding / software development skills?","text":"All Students Students who finished stage 5 or above"},{"location":"feedback/nitc-winter-2017/#q6-student-background-was-your-background-sufficient-for-doing-the-lab-if-not-in-which-pre-requisite-subjects-did-you-have-inadequate-prior-training","title":"Q6. Student background: Was your background sufficient for doing the lab ? If not, in which pre-requisite subjects did you have inadequate prior training.","text":"All Students Students who finished stage 5 or above"},{"location":"feedback/nitc-winter-2017/#q7-learning-experience-which-stage-gave-more-useful-insights","title":"Q7. Learning experience: Which stage gave more useful insights?.","text":"All Students Students who finished stage 5 or above"},{"location":"feedback/nitc-winter-2017/#general-observations","title":"General Observations","text":"<ol> <li>87% of students who responded that their programming background was sufficient could complete up to Stage 5 or beyond.</li> <li>77% of the students who reached Stage 6 went on to complete all the stages up to Stage 8.</li> <li>87% of the students who completed Stage 5 or beyond noted that 90% or more of the project work can be done only by referring to the project documentation and roadmap.</li> <li>91% of the students who completed Stage 5 or above noted that every student with average programming skills,     willing to put in 5-10 hours of work per week should be able to complete the first five stages of the project within one semester.</li> </ol>"},{"location":"feedback/nitc-winter-2021/","title":"Winter 2021, B.Tech Semester 6 Compiler Lab, NIT Calicut","text":"<p>Total number of students crediting the course: 28.</p> <p>Duration of the course: One semester (13 weeks). Credit Units: 3</p> <p>A feedback questionnaire was circulated to all the students who credited the course one week before the end of the semester. The responses are summarized below.</p> <p>Major stages of the Project (Each Stage subsumes the previous Stages):</p> <ul> <li>Stage 4: Imperative programs without functions. Data types: variables and arrays of integer/string type.</li> <li>Stage 5: Imperative programs with functions and recursion. Data types: variables and arrays of integer/string types.</li> <li>Stage 6: Imperative programs with support for user defined types and dynamic memory allocation.</li> <li>Stage 8: Object oriented programming support for classes and single inheritance.</li> </ul>"},{"location":"feedback/nitc-winter-2021/#q1-student-performance-how-many-stages-of-the-project-did-you-complete","title":"Q1. Student Performance: How many stages of the project did you complete?","text":"<p>Note</p> <p>Every student has completed atleast until Stage 5.</p>"},{"location":"feedback/nitc-winter-2021/#q2-time-management-how-many-hours-of-work-did-you-put-into-the-project-per-week-on-an-average-to-complete-up-to-what-you-have-done","title":"Q2. Time Management: How many hours of work did you put into the project per week on an average to complete up to what you have done?","text":""},{"location":"feedback/nitc-winter-2021/#q3-effectiveness-of-road-map-what-percentage-of-work-could-be-done-without-having-to-refer-to-material-outside-the-roadmapdocumentation-of-project","title":"Q3. Effectiveness of road map: What percentage of work could be done without having to refer to material outside the roadmap/documentation of project ?","text":""},{"location":"feedback/nitc-winter-2021/#q4-contribution-to-understanding-of-theory-how-much-did-the-lab-help-to-improve-your-understanding-of-compiler-design-theory","title":"Q4: Contribution to understanding of theory: How much did the lab help to improve your understanding of compiler design theory?","text":""},{"location":"feedback/nitc-winter-2021/#q5-contribution-to-programming-skills-how-far-did-this-lab-contribute-to-the-improvement-of-your-coding-software-development-skills","title":"Q5: Contribution to Programming skills: How far did this lab contribute to the improvement of your coding / software development skills?","text":""},{"location":"feedback/nitc-winter-2021/#q6-student-background-was-your-background-sufficient-for-doing-the-lab-if-not-in-which-pre-requisite-subjects-did-you-have-inadequate-prior-training","title":"Q6. Student background: Was your background sufficient for doing the lab ? If not, in which pre-requisite subjects did you have inadequate prior training.","text":""},{"location":"feedback/nitc-winter-2021/#q7-learning-experience-which-stage-gave-more-useful-insights","title":"Q7. Learning experience: Which stage gave more useful insights?.","text":""},{"location":"oexpl_data_structures/class-table/","title":"Class Table","text":""},{"location":"oexpl_data_structures/class-table/#introduction","title":"Introduction","text":"<p>The class table stores information pertaining to all the classes declared in an ExpL program. For a class it stores member fields, member functions, name of the class and parent class pointer.</p>"},{"location":"oexpl_data_structures/class-table/#structure","title":"Structure","text":"<p>The structure of Class Table(CT) is as follows:</p> <p><pre><code>struct Classtable {\n    char *Name;                           //name of the class\n    struct Fieldlist *Memberfield;        //pointer to Fieldlist\n    struct Memberfunclist *Vfuncptr;      //pointer to Memberfunclist\n    struct Classtable *Parentptr;         //pointer to the parent's class table\n    int Class_index;                      //position of the class in the virtual function table\n    int Fieldcount;                       //count of fields\n    int Methodcount;                      //count of methods\n    struct Classtable *Next;              //pointer to next class table entry\n};\n</code></pre> Memberfield list is used to store the information regarding the type, name, fieldindex and type of class of all the member fields of that class. <pre><code>struct Fieldlist{\n    char *Name;         //name of the field\n    int Fieldindex;         //position of the field\n    struct Typetable *Type;     //pointer to typetable\n    struct Classtable *Ctype;   //pointer to the class containing the field\n    struct Fieldlist *Next;     //pointer to next fieldlist entry\n};\n</code></pre></p> <p>Memberfunc list is used to store the information regarding the type, name of the function, argument list, it's flabel and it's position. <pre><code>struct Memberfunclist {\n    char *Name;                      //name of the member function in the class\n    struct Typetable *Type;          //pointer to typetable\n    struct Paramstruct *paramlist;   //pointer to the head of the formal parameter list\n    int Funcposition;                //position of the function in the class table\n    int Flabel;                      //A label for identifying the starting address of the function's code in the memory\n    struct Memberfunclist *Next;     //pointer to next Memberfunclist entry\n};\n</code></pre></p>"},{"location":"oexpl_data_structures/class-table/#associated-methods","title":"Associated Methods","text":"<ul> <li> <p><code>struct Classtable* CInstall(char *name,char *parent_class_name)</code></p> <p>Creates a class table entry of given 'name' and extends the fields and the methods of parent class.</p> </li> <li> <p><code>struct Classtable* CLookup(char *name)</code></p> <p>Search for a class table entry with the given 'name', if exists, return pointer to class table entry else return NULL.</p> </li> <li> <p><code>void Class_Finstall(struct Classtable *cptr, char *typename, char *name)</code></p> <p>Installs the field into the given class table entry which is given as an argument.</p> </li> <li> <p><code>void Class_Minstall(struct Classtable *cptr, char *name, struct Typetable *type, struct Paramstruct *arglist)</code></p> <p>Installs the method into the given class table entry which is given as an argument.</p> </li> </ul>"},{"location":"oexpl_data_structures/class-table/#illustration","title":"Illustration","text":"<p>Here is an example illustrating it. <pre><code>class\nPerson{\n    decl\n        str name;\n        int age;\n        int printDetails();\n        str findName();\n        int createPerson(str name, int age);\n    enddecl\n    int printDetails(){\n        decl\n        enddecl\n        begin\n            write(self.name);\n            write(self.age);\n            return 1;\n        end\n    }\n    str findName(){\n        decl\n        enddecl\n        begin\n            return self.name;\n        end\n    }\n    int createPerson(str name, int age){\n        decl\n        enddecl\n        begin\n            self.name=name;\n            self.age=age;\n            return 1;\n        end\n    }\n}     /*end of Person class */\nStudent extends Person{\n\n    decl\n        int rollnumber;               /*  The members name and age are inherited from the parent class */\n        str dept;\n        int printDetails();\n        int createStudent(str name, int age,int rollNo, str dept);\n    enddecl\n    int createStudent(str name, int age,int rollNo, str dept){\n        decl\n        enddecl\n        begin\n            self.name =name;\n                self.age = age;\n                    self.rollnumber = rollNo;\n                    self.dept = dept;\n                    return 1;\n        end\n    }\n    int printDetails(){  /* This function is also overridden in the derived class */\n        decl\n        enddecl\n        begin\n            write(self.name);\n            write(self.age);\n            write(self.rollnumber);\n            write(self.dept);\n            return 1;\n        end\n    }         /**  The derived class inherits the findName() function from the parent **/\n}  /* end of student class */\nendclass\n</code></pre></p> <ol> <li> <p>As soon as the compiler encounters the class name , it installs the class name and the parent class name if present into the class table.     Subsequently, If there is an extension to the parent class, all the member fields and methods of parent class are inherited.     Following is how class table looks when person is installed.</p> <p></p> </li> <li> <p>Following is how class table looks when student class is installed.  </p> <p></p> </li> </ol>"},{"location":"oexpl_runtime_data_structures/virtual_function_table/","title":"Virtual Function Table","text":""},{"location":"oexpl_runtime_data_structures/virtual_function_table/#introduction","title":"Introduction","text":"<p>This document explains how the control flow is happening from the calling object when there is inheritance,subtype polymorphism and method overriding. For a virtual function table of a class, 8 blocks of memory is allocated.</p>"},{"location":"oexpl_runtime_data_structures/virtual_function_table/#illustration","title":"Illustration","text":"<pre><code>class\nA\n{\n  decl\n    int f1();\n    int f2();\n  enddecl\n  int f1() {                   /*Newly defined method*/\n      begin\n       write(\"In class A f1\");\n       return 1;\n      end\n  }\n  int f2() {                   /*Newly defined method*/\n      begin\n        write(\"In class A f2\");\n        return 1;\n      end\n  }\n}                       /*End of Class Definition A*/\nB extends A\n{\n  decl\n    int f1();\n    int f3();\n  enddecl\nint f1() {                    /*f1 of class A is overridden by this method */\n     begin\n       write(\"In class B f1\");\n       return 1;\n     end\n}\nint f3() {                    /*Newly defined method*/\n     begin\n       write(\"In class B f3\");\n       return 1;\n     end\n}\n/* Class B inherits f2 from Class A */\n\n}                       /*End of Class Definition B*/\nC extends B\n{\n  decl\n    int f1();\n    int f3();\n    int f4();\n  enddecl\nint f1() {                /*f1 of Class B is overridden by this method*/\n     begin\n       write(\"In class C f1\");\n       return 1;\n     end\n}\nint f3() {                /*f3 of Class B is overridden by this method */\n    begin\n       write(\"In class C f3\");\n       return 1;\n    end\n}\nint f4() {                /*Newly defined method*/\n    begin\n       write(\"In class C f4\");\n       return 1;\n    end\n}\n\n/*Class C inherits f2 from Class A */\n\n}                        /*End of Class Definition C*/\nendclass\n</code></pre> <ol> <li> <p>Virtual function table start at 4096 in the stack, and it grows with the increase in number of the classes.     After creating the virtual function table, the we will allocate the space for global declarations.     By using the class index, the starting address in virtual function table for that particular class is known.     Starting at index 4096, the class index * 8 + 4096 is the address of the current class virtual function table. The class index starts from 0.     For every method declaration, a new label is alloted.     In class A, the function f1 gets an funcposition 0 and say flabel f1 and     the function f2 gets an funcposition 1 and say a flabel f2.</p> <p>Following is how virtual function table looks in the stack when class A is installed using the pointer to the member function list of class A. So, the member function list of class A looks as shown in the below figure :  </p> <p></p> <p>So, the virtual function table of class A looks as shown in the below figure. It is constructed using member function list of class A as shown in the above figure :</p> <p></p> </li> <li> <p>In class B, there are two methods f1() and f3() and it is extending class A.     When a class extends other class, all the member fields and methods of the parent class are inherited by the derived class.     Suppose as in this example, if the method signatures of the parent class and the derived class match, then method overriding occurs.     Method Overriding means the definition of the method that belongs to     parent class is replaced by the definition of the method which is already present in the derived class.     Here, f1() method of class B overrides the f1() method of class A. Let us see how the process of method overriding     occurrs, how the member function list is updated for the derived class. This is demonstrated using the classes B     and A of this OExpL program. Here, class B is extending class A. So, all the member fields and methods of class A     is inherited by class B. So, now the member function list looks as shown in the figure below.  Here method f1()     derived from class A, will be overridden by the method f1() of class B. As stated above, a new label will be alloted,     for the f1() method of class B. Now, we need to update the member func list entry of the f1() method in class B,     by new flabel given to the method f1() of class B. Similarly, the member func list for class C will be constructed.</p> <p></p> </li> </ol>"},{"location":"oexpltestprograms/test1/","title":"Test Program 1 : Binary Search Tree","text":"<p>This test program inserts elements into a binary search tree and prints the elements in inorder, preorder and postorder traversal. The program stops taking input elements (that are to be inserted in Binary Search Tree) when the user enters 0.</p>"},{"location":"oexpltestprograms/test1/#input","title":"Input","text":"<p>The elements that are to be inserted into a Binary Search Tree and a 0 at last (indicating the end of input).</p>"},{"location":"oexpltestprograms/test1/#output","title":"Output","text":"<p>The inorder, preorder and postorder traversal of the tree.</p> <p>This program test the iteration, recursion, conditional, arrays and passing of user-defined datatype as return value of function.</p>"},{"location":"oexpltestprograms/test1/#code","title":"Code","text":"<pre><code>type\n    bst{\n        int a;\n        bst left;\n        bst right;\n    }\nendtype\nclass\n    bstclass{\n        decl\n            bst root;\n            int init();\n            bst getroot();\n            int setroot(bst n1);\n            bst getnode(int key);\n            bst insert(bst h, int key);\n            int inOrder_fun(bst h);\n            int preOrder_fun(bst h);\n            int postOrder_fun(bst h);\n        enddecl\n        int init(){\n            begin\n                self.root=null;\n                return 1;\n            end\n        }\n        bst getroot(){\n            begin\n                return self.root;\n            end\n        }\n        int setroot(bst n1){\n            begin\n                self.root=n1;\n                return 1;\n            end\n        }\n        bst getnode(int key){\n            decl\n                bst temp;\n            enddecl\n            begin\n                temp=alloc();\n                temp.a=key;\n                temp.left=null;\n                temp.right=null;\n                return temp;\n            end\n        }\n        bst insert(bst h, int key){\n            begin\n                if (h == null) then\n                    h = self.getnode(key);\n                else\n                    if (key &lt; h.a) then\n                        h.left = self.insert(h.left, key);\n                    else\n                        if (key &gt; h.a) then\n                            h.right = self.insert(h.right, key);\n                        endif;\n                    endif;\n                endif;\n                return h;\n            end\n        }\n        int inOrder_fun(bst h){\n            decl\n                int in;\n            enddecl\n            begin\n                if(h!= null) then\n                    in=self.inOrder_fun(h.left);\n                    write(h.a);\n                    in=self.inOrder_fun(h.right);\n                endif;\n                return 1;\n            end\n        }\n        int preOrder_fun(bst h){\n            decl\n                int in;\n            enddecl\n            begin\n                if(h!= null) then\n                    write(h.a);\n                    in=self.preOrder_fun(h.left);\n                    in=self.preOrder_fun(h.right);\n                endif;\n                return 1;\n            end\n        }\n        int postOrder_fun(bst h){\n            decl\n                int in;\n            enddecl\n            begin\n                if(h!= null) then\n                    in=self.postOrder_fun(h.left);\n                    in=self.postOrder_fun(h.right);\n                    write(h.a);\n                endif;\n                return 1;\n            end\n        }\n    }\nendclass\ndecl\n    bstclass obj;\nenddecl\nint main(){\n    decl\n        bst Root;\n        int x,in,val;\n    enddecl\n    begin\n        x=initialize();\n        obj = new(bstclass);\n        x=obj.init();\n        read(val);\n        Root = obj.getroot();\n        while(val!=0) do\n            Root = obj.insert(Root,val);\n            read(val);\n        endwhile;\n        x = obj.setroot(Root);\n        in = obj.inOrder_fun(obj.getroot());\n        in = obj.preOrder_fun(obj.getroot());\n        in = obj.postOrder_fun(obj.getroot());\n        return 0;\n    end\n}\n</code></pre>"},{"location":"oexpltestprograms/test2/","title":"Test Program 2 : Linked list","text":"<p>This test program reads elements into a linked list and prints them.</p>"},{"location":"oexpltestprograms/test2/#input","title":"Input","text":"<p>Value of length of list and list of values from standard input.</p>"},{"location":"oexpltestprograms/test2/#output","title":"Output","text":"<p>The list of values stored in linked list.</p> <p>This program test the working of dynamic memory allocation functions like Initialize(), Alloc() and Free().</p>"},{"location":"oexpltestprograms/test2/#code","title":"Code","text":"<pre><code>type\n    list{\n        int data;\n        list next;\n    }\nendtype\nclass\nlinkedlist{\ndecl\nlist head;\nlist tail;\nint length;\nint getlength();\nint init();\nlist insert(int data);\nint printlinkedlist();\nenddecl\nint getlength(){\nbegin\nreturn self.length;\nend\n}\nint init(){\nbegin\nself.head=null;\nself.tail=null;\nself.length=0;\nreturn 1;\nend\n}\nlist insert(int data){\ndecl\nlist temp;\nenddecl\nbegin\ntemp=alloc();\ntemp.data=data;\ntemp.next=null;\nif(self.head== null)then\nself.head=temp;\nself.tail=temp;\nelse\nself.tail.next=temp;\nself.tail=temp;\nendif;\nself.length=self.length+1;\nreturn temp;\nend\n}\nint printlinkedlist(){\ndecl\nlist temp;\nenddecl\nbegin\ntemp=self.head;\nwhile(temp!= null)do\nwrite(temp.data);\ntemp=temp.next;\nendwhile;\nreturn 1;\nend\n}\n}\nendclass\ndecl\nlinkedlist obj;\nenddecl\nint main(){\ndecl\nint x,y,z;\nlist a;\nenddecl\nbegin\nx=initialize();\nobj=new(linkedlist);\nx=obj.init();\nread(x);\nwhile(x!=0)do\nread(y);\na=obj.insert(y);\nx=x-1;\nendwhile;\nwrite(obj.getlength());\nx=obj.printlinkedlist();\nreturn 1;\nend\n}\n</code></pre>"},{"location":"oexpltestprograms/test3/","title":"Test Program 3 : Sum of Factorials","text":"<p>This test program reads an element and finds the sum of factorials of all the numbers till that element.</p>"},{"location":"oexpltestprograms/test3/#input","title":"Input","text":"<p>Value of n.</p>"},{"location":"oexpltestprograms/test3/#output","title":"Output","text":"<p>Sum of factorials of all the numbers till n.</p> <p>This program tests the declaration of a member field which is an object of another class. This program also tests the recursion, parameter passing, calling a function inside the call of another function.</p>"},{"location":"oexpltestprograms/test3/#code","title":"code","text":"<pre><code>class\nfact{\ndecl\nint x;\nint findfactorial(int n);\nenddecl\nint findfactorial(int n){\ndecl\nint p;\nenddecl\nbegin\nif(n&lt;=1)then\np=1;\nelse\np=n*self.findfactorial(n-1);\nendif;\nreturn p;\nend\n}\n}\ntestfactsum{\ndecl\nfact o1;\nint testfun(int n);\nenddecl\nint testfun(int n){\ndecl\nint sum;\nenddecl\nbegin\nself.o1=new(fact);\nsum=0;\nwhile(n!=0)do\nsum=sum+self.o1.findfactorial(n);\nn=n-1;\nendwhile;\nreturn sum;\nend\n}\n}\nendclass\ndecl\ntestfactsum obj;\nenddecl\nint main(){\ndecl\nint x,n;\nenddecl\nbegin\nx=initialize();\nobj=new(testfactsum);\nread(n);\nwrite(obj.testfun(n));\nreturn 1;\nend\n}\n</code></pre>"},{"location":"oexpltestprograms/test4/","title":"Test Program 4","text":"<p>This program tests the runtime binding of the variables of a class.</p>"},{"location":"oexpltestprograms/test4/#input-if-any-input-0","title":"Input: If any input &gt; 0","text":""},{"location":"oexpltestprograms/test4/#output","title":"Output","text":"<pre><code>In A F1\n0\n</code></pre>"},{"location":"oexpltestprograms/test4/#input-if-any-input-0_1","title":"Input : If any input &lt;= 0","text":""},{"location":"oexpltestprograms/test4/#output_1","title":"Output :","text":"<pre><code>In B F1\n1\n</code></pre> <p>This program uses the concepts of inheritance and subtype polymorphism.</p> <pre><code>class\nA\n{\ndecl\nint i;\nint f0();\nint f1();\nenddecl\nint f0() {\ndecl\nint c;\nenddecl\nbegin\nc = self.f1();\nwrite(self.i);\nreturn 1;\nend\n}\nint f1() {\ndecl\nenddecl\nbegin\nself.i=0;\nwrite(\"In A F1\");\nreturn 1;\nend\n}\n}\nB extends A\n{\ndecl\nint f1();\nenddecl\nint f1() {\ndecl\nenddecl\nbegin\nself.i=1;\nwrite(\"In B F1\");\nreturn 1;\nend\n}\n}\nendclass\ndecl\nint n;\nA obj;\nenddecl\nint main() {\ndecl\nenddecl\nbegin\nn=initialize();\nread(n);\nif(n&gt;0) then\nobj = new(A);\nelse\nobj = new(B);\nendif;\nn = obj.f0();\nreturn 1;\nend\n}\n</code></pre>"},{"location":"oexpltestprograms/test5/","title":"Test Program 5","text":"<p>This program tests the correct set up of the virtual function table by the compiler.</p>"},{"location":"oexpltestprograms/test5/#input-if-n-0","title":"Input : If n &lt; 0","text":""},{"location":"oexpltestprograms/test5/#output","title":"Output","text":"<pre><code>In A F0\n</code></pre>"},{"location":"oexpltestprograms/test5/#input-if-n-0_1","title":"Input : If n == 0","text":""},{"location":"oexpltestprograms/test5/#output_1","title":"Output","text":"<pre><code>In B F0\n</code></pre>"},{"location":"oexpltestprograms/test5/#input-if-n-0_2","title":"Input : If n &gt; 0","text":""},{"location":"oexpltestprograms/test5/#output_2","title":"Output","text":"<pre><code>In C F0\n</code></pre> <p>This program uses the virtual function table, inheritance and subtype polymorphism.</p> <pre><code>class\nA\n{\ndecl\nint f0();\nint f1();\nenddecl\nint f0() {\nbegin\nwrite(\"In class A f0\");\nreturn 1;\nend\n}\nint f1() {\nbegin\nwrite(\"In class A f1\");\nreturn 1;\nend\n}\n}\nB extends A\n{\ndecl\nint f0();\nint f2();\nenddecl\nint f0() {\nbegin\nwrite(\"In class B f0\");\nreturn 1;\nend\n}\nint f2() {\nbegin\nwrite(\"In class B f2\");\nreturn 1;\nend\n}\n}\nC extends B\n{\ndecl\nint f0();\nint f2();\nint f4();\nenddecl\nint f0() {\nbegin\nwrite(\"In class C f0\");\nreturn 1;\nend\n}\nint f2() {\nbegin\nwrite(\"In class C f2\");\nreturn 1;\nend\n}\nint f4() {\nbegin\nwrite(\"In class C f4\");\nreturn 1;\nend\n}\n}\nendclass\ndecl\nA obj ;\nA test_obj;\nenddecl\nint main() {\ndecl\nint temp,n;\nenddecl\nbegin\ntemp= initialize();\nread(n);\nif(n &lt; 0)then\nobj = new(A);\nelse\nif(n == 0)then\nobj = new(B);\nelse\nif(n &gt; 0)then\nobj = new(C);\nendif;\nendif;\nendif;\ntest_obj = obj;\nwrite(test_obj.f0());\nreturn 1;\nend\n}\n</code></pre>"},{"location":"oexpltestprograms/test6/","title":"Test program 6","text":"<p>This program tests the implementation of inheritance and subtype polymorphism.</p>"},{"location":"oexpltestprograms/test6/#input","title":"Input","text":"<pre><code>1\nlength\nbreadth\n</code></pre>"},{"location":"oexpltestprograms/test6/#output","title":"Output","text":"<pre><code>length * breadth\n</code></pre>"},{"location":"oexpltestprograms/test6/#input_1","title":"Input","text":"<pre><code>2\nlength\n</code></pre>"},{"location":"oexpltestprograms/test6/#output_1","title":"Output","text":"<pre><code>length * length\n</code></pre> <p>This test program uses the concepts of inheritance.</p> <pre><code>class\nRectangle\n{\ndecl\nint length;\nint breadth;\nint set_dimensions();\nint area();\nenddecl\nint area() {\ndecl\nenddecl\nbegin\nreturn self.length * self.breadth;\nend\n}\nint set_dimensions() {\ndecl\nenddecl\nbegin\nwrite(\"Enter length \");\nread(self.length);\nwrite(\"Enter breadth\");\nread(self.breadth);\nreturn 0;\nend\n}\n}\nSquare extends Rectangle\n{\ndecl\nint set_dimensions();\nenddecl\nint set_dimensions() {\ndecl\nenddecl\nbegin\nwrite(\"Enter side sq\");\nread(self.length);\nself.breadth = self.length;\nreturn 0;\nend\n}\n}\nendclass\ndecl\nRectangle obj;\nenddecl\nint main() {\ndecl\nint x;\nenddecl\nbegin\nx=initialize();\nwrite(\"Enter\");\nwrite(\"1.Rectangle\");\nwrite(\"2.Square\");\nread(x);\nif(x==1) then\nobj = new(Rectangle);\nelse\nobj = new(Square);\nendif;\nx = obj.set_dimensions();\nwrite(obj.area());\nreturn 0;\nend\n}\n</code></pre>"},{"location":"oexpltestprograms/test7/","title":"Test program 7","text":"<p>This program tests the implementation of inheritance and subtype polymorphism.</p>"},{"location":"oexpltestprograms/test7/#input-0","title":"Input : &gt; 0","text":""},{"location":"oexpltestprograms/test7/#output","title":"Output","text":"<pre><code>Rogers\n37\n</code></pre>"},{"location":"oexpltestprograms/test7/#input-0_1","title":"Input : &lt;= 0","text":""},{"location":"oexpltestprograms/test7/#output_1","title":"Output :","text":"<p><pre><code>Mathew\n35\n999\nCS\n</code></pre> This program tests the concepts of inheritance, subtype polymorphism and virtual function table.</p>"},{"location":"oexpltestprograms/test7/#code","title":"code","text":"<pre><code>class\nPerson{\ndecl\nstr name;\nint age;\nint printDetails();\nstr findName();\nint createPerson(str name, int age);\nenddecl\nint printDetails(){\ndecl\nenddecl\nbegin\nwrite(self.name);\nwrite(self.age);\nreturn 1;\nend\n}\nstr findName(){\ndecl\nenddecl\nbegin\nreturn self.name;\nend\n}\nint createPerson(str name, int age){\ndecl\nenddecl\nbegin\nself.name=name;\nself.age=age;\nreturn 1;\nend\n}\n}\nStudent extends Person{\ndecl\nint rollnumber;\nstr dept;\nint printDetails();\nint createStudent(str name, int age,int rollNo, str dept);\nenddecl\nint createStudent(str name, int age,int rollNo, str dept){\ndecl\nenddecl\nbegin\nself.name =name;\nself.age = age;\nself.rollnumber = rollNo;\nself.dept = dept;\nreturn 1;\nend\n}\nint printDetails(){\ndecl\nenddecl\nbegin\nwrite(self.name);\nwrite(self.age);\nwrite(self.rollnumber);\nwrite(self.dept);\nreturn 1;\nend\n}\n}\nendclass\ndecl\nint n,temp;\nstr name;\nPerson first;\nStudent second;\nPerson arbitrary;\nenddecl\nint main(){\ndecl\nenddecl\nbegin\nn = initialize();\nfirst=new(Person);\ntemp = first.createPerson(\"Rogers\", 37);\nsecond=new(Student);\ntemp = second.createStudent(\"Mathew\", 35, 999, \"CS\");\nread(n);\nif (n&gt;0) then\narbitrary = first;\nelse\narbitrary = second;\nendif;\nn = arbitrary.printDetails();\nreturn 0;\nend\n}\n</code></pre>"},{"location":"roadmap/","title":"Roadmap","text":"<p>This roadmap is divided into several stages, to be done in sequential order. Incrementally you will build a compiler for the ExpL language according to its specification. Links are provided for background reading material wherever appropriate. It will be assumed that you have background in C programming, Data Structures and Principles of Computer Organization.</p> <p> Stage 0 : Installation  Stage 1 : CodeGeneration for Arithmetic Expressions  Stage 2 : Introduction to static storage allocation  Stage 3 : Adding Flow Control Statements  Stage 4 : User Defined Variables and arrays  Stage 5 : Adding Functions  Stage 6 : User defined types and Dynamic Memory Allocation  Stage 7 : Adding Objects \u2013 Data encapsulation  Stage 8 : Inheritance and Sub-type Polymorphism</p>"},{"location":"roadmap/stage-00/","title":"Stage 0 : Installation and Preparation","text":"<p>Time estimate</p> <p>2 weeks, 5-10 hours/week</p> <p>Pre-requisite Reading</p> <p>NIL</p> <p>In this stage, you will download and familiarize yourself with the simulation package and learn the compiler design software tools LEX and YACC. Follow the instructions below.</p> <ol> <li> <p>Install the LEX, YACC and the XSM simulator package. Follow the instructions here</p> <p>You need to learn two software tools - YACC and LEX which you will use in the project. These tools are somewhat sophisticated. Fortunately, understanding what is enough for the purpose of our compiler project is not very difficult. The following tutorials will help you through this process.</p> <p>If you are not already familiar with the tools LEX and YACC do the following:</p> </li> <li> <p>Complete the LEX tutorial.</p> </li> <li> <p>Complete the YACC tutorial.</p> </li> <li> <p>Complete the Using YACC with LEX tutorial.</p> </li> <li> <p>Complete the GDB Tutorial</p> <p>The next step is to understand the target machine envionment. You must carefully go through the following tutorial before proceeding to the next stage of this roadmap.</p> </li> <li> <p>Complete the XSM execution environment tutorial.</p> </li> </ol> <p>With this, you are ready with all the required pre-requisites to proceed further in this roadmap.</p>"},{"location":"roadmap/stage-01/","title":"Stage 1 : Code generation for Arithmetic Expressions","text":"<p>Time estimate</p> <p>0.5 week, 5-10 hours/week</p> <p>Prerequisites</p> <ol> <li>You must be comfortable with LEX and YACC. ( If you are not, you must first do LEX tutorial, YACC Tutorial and Using Lex with Yacc tutorials.)</li> <li>You must have completed the XSM environment tutorial including all the exercises before staring this stage.</li> </ol> <p>Learning Objectives</p> <p>In this stage, you will:</p> <ol> <li>Parse an input arithmetic expression and create an expression tree using YACC and LEX.</li> <li>Recursively traverse the tree and generate assembly language code. The allocation of     registers for storing results of intermediate computations will be handled enroute.</li> </ol> <p>A compiler is a software that takes as input a high level program and produces a machine recognizible target program as output. The high level program typically allows variables, expressions, conditionals, iterative constructs, user defined types, functions etc. The low level target program on the other hand will be a sequence of assembly level instructions that can be run on a target machine (which is the XSM simulator in this project).</p> <p>The strategy of the roadmap is to help you build the compiler in stages. We start here by building a very simple compiler whose input (high level) program contains only simple arithmetic expressions. In subsequent stages, we will add more and more constructs to the input language one by one, learning the relevant theoretical concepts along the way.</p> <p>We assume that you have implemented the library routine for handling console output, which you were asked to do in the XSM execution environment tutorial.</p> <p>Consider arithmetic expressions with the following syntax.</p> <pre><code>E : E + E | (E) | NUM\n</code></pre> <p>Where the lexeme NUM correspond to integers. Assume left associativity for <code>+</code>, Thus, the tokens relevant are <code>NUM</code> and <code>+</code>. The attribute value associated with a number is the number read. Assume that the input file is passed as argument to the <code>main()</code> function in YACC.</p> <p>The lexer must pack the attribute into a tree node of the following structure:</p> <pre><code>typedef struct tnode{\n    int val;\n    char *op; //indicates the name of the operator for a non leaf node\n    struct tnode *left, *right; //left and right branches\n} tnode;\n\n#define YYSTYPE tnode*\n</code></pre> <p>Since the semantics actions in the parser must build the tree, the following function must be written:</p> <pre><code>/*Make a leaf tnode and set the value of val field*/\nstruct tnode* makeLeafNode(int n);\n\n/*Make a tnode with operator, left and right branches set*/\nstruct tnode* makeOperatorNode(char op,struct tnode *l,struct tnode *r);\n</code></pre> <p>Task 1</p> <p>Build the expression tree for the given input.</p> <p>Exercise 1</p> <p>Output the prefix and postfix forms of the expression from the tree.</p> <p>Note</p> <p>You would have already completed this task if you have done the Using Yacc With Lex tutorial</p> <p>Now, comes the next task - to generate assembly language program equivalent for the expression and write it out into an executable file in the XEXE format. Once this is done, you can use the simulator to load the XEXE file into the memory of the XSM machine and execute it as outlined in the XSM run time environment tutorial.</p> <p>To do this, one needs to know the following:</p> <ol> <li>The machine model and the instruction set of the target machine.</li> <li>Format of the executable file.</li> <li> <p>You need to know the address in the memory (in the target machine) where each instruction you     generate will be loaded (by the OS loader). This is because program control instructions like     <code>JMP</code>, <code>CALL</code> etc., requires specification of the jump address.</p> <p>As already outlined in the XSM run time environment tutorial, the header will be loaded into addresses 2048-2055. The first instruction generated by you will be loaded to the address 2056. Each XSM instruction occupies 2 memory words. Hence, the next instruction will be loaded at address 2058 and so on. The entry point field of the header must contain the address of the first instruction to be fetched and executed.</p> </li> <li> <p>You need to fix the memory addresses where variables and other data is stored. For example, for     each variable in the program, the compiler will have to allocate storage space in memory. The ABI     stipulates that the region for this is the stack region.     Thus each variable must be stored in some address between 4096 and 5119.</p> </li> <li> <p>Since XSM machine stipulates that arithmetic and logic instructions can be done only when operands     are loaded into machine registers, we need to load the contents of variables/constants in the     program into the machine registers before processing them. This brings in the problem of     register allocation. The XSM machine makes available 20 registers (<code>R0</code>-<code>R19</code>) for the compiler.</p> </li> </ol> <p>Of the above, the XSM execution environment tutorial has already explained (1) and (2). Evaluation of expressions do not involve either storage allocation or program control transfer (<code>JMP</code>). Hence, we will not take up (3) and (4) at this stage. However, we need to solve (5) now.</p>"},{"location":"roadmap/stage-01/#what-must-be-the-evaluation-strategy","title":"What must be the evaluation strategy?","text":"<p>Let us take an example: If you are given a two node expression tree as shown below corresponding to the expression (3+2):</p> <p></p> <p>The evaluation strategy will be:</p> <ol> <li>Store 3 in a register \u2013 say R0.</li> <li>Store 2 in a register \u2013 say R1.</li> <li>ADD R0, R1.</li> </ol> <p>The result will be stored in R0 and is sufficient for us. To generate code for the above tasks and write it into a <code>target_file</code>, you must write code as:</p> <pre><code>fprintf(target_file, \"MOV R0, 3\");\nfprintf(target_file, \"MOV R1, 2\");\nfprintf(target_file, \"ADD R0, R1\");\n</code></pre> <p>However, life becomes complicated if we have an expression like <code>(3+2)+(5+6)</code> resulting in the following tree.</p> <p></p> <p>Of course, we can \u201chand craft\u201d this case also. But the strategy will not generalize. The basic issue is that your compiler does not know the input expression before-hand. Technically speaking, the issue is that the \u201cexpression is not available at compile time, but only known at run time\u201d. Your code generation module must be more \"intelligent\" to handle arbitrary expressions.</p> <p>The root of the problem with the above code is that R0 and R1 were picked by you and not by your compiler. Thus, we must have a register assignment policy (basically a function) that returns a free register whenever we require one. That is, you must design the following functions:</p> <pre><code>int getReg() // Allocate a free register\n</code></pre> <p>That returns the register number of an unallocated register, so that your code for adding 3 and 2 would look like: <pre><code>int p = getReg();\nint q = getReg();\nfprintf(target_file, \"MOV R%d, 3\", p);\nfprintf(target_file, \"MOV R%d, 2\", q);\nfprintf(target_file, \"ADD R%d, R%d\", p, q);\n</code></pre></p> <p>In addition to allocating registers, you must also have mechanism to release a register back into the register pool. In the above example, after the ADD instruction is generated R1 can be released and send back to the register pool.</p> <p>For this purpose, you will write a function</p> <pre><code>freeReg() // Releases a register.\n</code></pre> <p>To make the allocation strategy simple, we suggest that you generate target code in such a way that the result of a CPU instruction involving two registers will be always stored in the register with lower index. In the code above the result of the computation is kept in <code>R0</code> and not <code>R1</code> so that the register with the higher index value can be released. As a consequence, the <code>freeReg()</code> function does not require any arguments. Instead, <code>freeReg()</code> and <code>getReg()</code> can be designed to keep track of the highest numbered register allocated so far and hence can keep track of the correct register that must be allocated or freed.</p> <p>The following summarizes the register allocation strategy:</p> <ol> <li> <p>Whenever a register is needed, allocate the lowest numbered register that is free.     (Thus, give R0 if possible, otherwise R1 etc.)</p> </li> <li> <p>Whenever we free a register, always release the highest used register that was     allocated previously. (Thus, if R0, R1 and R2 were allocated, <code>freeReg()</code> must release R2).</p> </li> </ol> <p>Finally, we must design a code generation module. The strategy here is to start with an expression tree and do the following:</p> <ol> <li>At the leaf nodes of the tree (corresponding to a NUM), Allocate a new register and store the number to the register.</li> <li> <p>At the intermediete nodes:</p> <p>a. Generate code for the left subtree (recursively). Find out the register holding the result.</p> <p>b. Evaluate the right subtree (recursively). Find out the register holding the result.</p> <p>c. ADD the contents of the two registers and store the result in the lower numbered register.</p> <p>d. Release the higher numbered register and return.</p> </li> </ol> <p>In the above box, as step 2.a and 2.b requires finding the index of the register which stores the result of expression evaluation. The simplest strategy is to design a <code>codeGen()</code> function that can take as input an expression tree and generates code for the expression, returning the index of the register storing the result:</p> <pre><code>#define reg_index int;\nreg_index codeGen( struct node *t) {\n    ..\u2003\n    ..\n    return register number storing result\n}\n</code></pre> <p>The codeGen() function takes as input a pointer to the root of an expression tree and generates code for the subtree rooted at that node. After generating code, the function must return the index of the register storing the result. See this link for furthur details.</p> <p>Task 2</p> <p>Complete the simple compiler for expression evaluation and generate the executable file. The result of expression evaluation may be stored in the first location of the stack region \u2013 memory address 4096. This value may be printed out using the write system call. Note that the XEXE executable format must be adhered so that the XSM simulator can load and execute the file.</p> <p>Note</p> <p>To run the simulator, you must prepare the library.lib together with the XEXE executable file. Please follow instructions in the XSM environment tutorial.</p> <p>Exercise 2</p> <p>Modify the grammar to <pre><code>E : E + E | E*E | E-E| E/E | (E) | NUM\n</code></pre> Assume standard rules of precedence and associativity.</p> <p>Exercise 3</p> <p>Redo Exercise 2 assuming that the input expression is given in prefix from.</p> <p>Note</p> <p>Here we assumed that machine registers never get exhausted. XSM provides 20 general purpose registers and these registers are sufficient for all practial purposes. However, if all registers are exhausted, then space will have to be allocated in memory. We will not address this contingency in this roadmap. If register pool is exhausted, your compiler may stop compilation and flag \"Out of registers\" error.</p>"},{"location":"roadmap/stage-02/","title":"Stage 2. Introduction to static storage allocation","text":"<p>Time estimate</p> <p>0.5 week, 5-10 hours/week</p> <p>Prerequisites</p> <ol> <li>You must be comfortable with LEX and YACC. (If you are not, you must first do     LEX tutorial, YACC Tutorial and YACC+LEX tutorial.)</li> <li>You must have completed the XSM environment tutorial     before starting this stage.</li> </ol> <p>Learning Objectives</p> <p>In this stage, you will extend the expression evaluator of the previous stage to support a set of pre-defined variables with Input/Output and assignment statements. You will get introduced to the notion of static storage allocation enroute. You will also learn to differentiate between statements and expressions and also construct an abstract syntax tree representation for a program.</p> <p>Consider a simple programming language with the following syntax:</p> <pre><code>Program ::= BEGIN Slist END | BEGIN END\n\nSlist ::= Slist Stmt | Stmt\n\nStmt ::= InputStmt | OuptputStmt | AsgStmt\n\nInputStmt ::= READ(ID);\n\nOutputStmt ::== WRITE(E);\n\nAsgStmt ::== ID = E;\n</code></pre> <p>Apart from the literal tokens, BEGIN, END, READ, and WRITE are tokens corresponding to keywords \"begin\", \"end\", \"read\" and \"write\". ID is a token for variables. We will permit only variables <code>[a-z]</code> in this stage.</p> <p>To support variables to appear in expressions, you must add the rule <code>E := ID</code> to the expression syntax used in Stage 1. The above syntax defines a small programming language that permits just straight line programs (programs without conditionals, loops, jumps or such control transfer constructs). There are only 26 pre-defined variables that are supported \u2013 a, b,c,..,z. A typical program would look like:</p> <pre><code>begin\n    read (a);\n    read (b);\n    d = a + 2 * b;\n    write (a+d);\nend;\n</code></pre> <p>We will assume that variables can store only integers. Handling variables of multiple types will be taken up in subsequent stages.</p> <p>A conceptual point to note here is that apart from the addition of variables, the extended language now has two kinds of constructs \u2013 expressions and statements. While an expression evaluates to a value (in this case, we limit ourselves to integer expressions), a statement commands the execution of some action by the machine. For example, the statement <code>read(a);</code> instructs the action of reading a variable from the console into a variable a. <code>write(a+d);</code> instructs evaluation of the expression <code>(a+d)</code> and printing the result into the console output.</p> <p>Another important conceptual point to note is that the introduction of variables also demand binding them to storage (memory) locations. The storage location associated with a variable must hold the value of the variable at each point of program execution. A statement (like the assignment statement or a read statement) that alters the value of a variable must result in a change the value stored in the corresponding storage location.</p> <p>In the present case, the compiler can fix the address for each variable in memory right at the time of program compilation. Since the ABI stipulate that storage allocation must be done in the stack region, we can pre-allocate the first 26 memory locations in the stack region of memory for the variables a-z. Thus, variable <code>a</code> will refer to contents of address 4096, <code>b</code> to contents of address 4097 and so on. Any time the compiler encounters the variable \u2013 say <code>a</code>, the address to be looked at is fixed \u2013 in this case <code>4096</code>. Such allocation policy is called static allocation. In later stages you will encounter situations where it will not be possible for the compiler to fix memory address of a variable at compile time. This leads to run time and dynamic memory allocation policies. For now, we will be content with static allocation.</p> <p>To implement the above, your compiler must:</p> <ol> <li> <p>Fix the storage location for each variable. As noted above, the first 26 locations of the     stack region starting at address 4096 may be assigned for a to z. Note that the XSM machine     can store an integer in a single memory location. Hence, for each variable we need to allocate     only 1 memory word. Note that \"allocation\" here means that while generating code, the compiler     assumes that the variable <code>a</code> is stored in location <code>4096</code>, b in location <code>4097</code> and so forth.</p> <p>Note</p> <p>Some programming languages stipulate that variables must be initialized to zero. In that case, the compiler must generate code to <code>MOV 0</code> to each of these locations before generating code for statements in the program. Some machines provide machine instructions that support initializing memory to zero. Certain operating systems would have initialized all memory regions (except those to which code is loaded into) to zero at load time. We will not pursue these issues here.</p> </li> <li> <p>To translate an assignment statement, the compiler must generate code to evaluate the expression     and then MOV the contents of the register storing the result to the memory location allocated for the variable.</p> </li> <li>To translate a Read statement, the compiler must generate code to invoke the     library function for read, passing the address     of the variable as argument. Write is implemented similarly.</li> </ol> <p>But before getting into code generation, we must create an abstract syntax tree (AST) for the program. An abstract syntax tree is a tree representation of the program, just like an expression tree for expressions. An abstract syntax tree for the above program would look like the following:</p> <p></p> <p>Observe that each node now needs to store distinguishing information like:</p> <ol> <li>Whether it corresponds to a variable, constant, operator, assignment statement, write statement     or read statement.</li> <li>In case of operators, the information on the operator must be present. In the case of constants,     the value must be stored in the node. In the case of variables, the node must contain the variable name.</li> <li>There are also connector nodes which simply join two subtrees of statements together.</li> </ol> <p>This leads to the definition of the following node structure:</p> <pre><code>typedef struct tnode {\n    int val;        // value of a number for NUM nodes.\n    int type;       // type of variable\n    char* varname;  // name of a variable for ID nodes\n    int nodetype;   // information about non-leaf nodes - read/write/connector/+/* etc.\n    struct tnode *left,*right;  // left and right branches\n}tnode;\n\n/*Create a node tnode*/\nstruct tnode* createTree(int val, int type, char* c, struct tnode *l, struct tnode *r);\n</code></pre> <p>Task 1</p> <p>Use Yacc and Lex to generate abstract syntax tree representation of a program. A file containing the source program will be input to your program.</p> <p>Thus, after parsing, we use the syntax directed translation scheme of YACC to construct an intermediate representation \u2013 namely, the abstract syntax tree. This phase of compilation is sometimes called the front end of the compiler. The next step is to recursively traverse the expression tree to generate executable code. This is typically called the back end. The output of the front end is generally a machine independent intermediate representation like the AST. The back end of course will be dependent on the target platform.</p> <p>Task 2</p> <p>Modify <code>CodeGen()</code> function of Stage 1 to generate code for the abstract syntax tree generated as Task 1 above.</p> <p>In the next stage, we will see how program control instructions like if-then-else can be incorporated into the language.</p> <p>Note</p> <p>An abstract syntax tree is an intermediate representation of the source program in a tree form suitable for code generation. There are several other forms of intermediate representations like the three address code form, the static single assignment form etc. This roadmap will be based on the abstract syntax tree representation.</p> <p>In commercial strength compilers, the source is first translated to intermediate forms like the three address form which is a lower level representation (that is the intermediate form is closer to machine code) than the AST. Typically machine independent code optimizations are performed on the intermediate code and only then the back-end code generation is run. This step is followed by another set of machine dependent code optimizations before the target file is finally generated. As these issues are beyond the scope of our project, we will not dwell into these matters further in this roadmap.</p> <p>Exercise 1</p> <p>Build an evaluator for the program. (Hint: Your front end does not change. But, instead of generating code from the AST, you can recursively \"evaluate\" it. For storage allocation of variables, you can simply declare an array that can store 26 integers and allocate one entry for each variable).</p> <p>Note</p> <p>The compiler generates target code which must be executed by the target machine. In our case,  the compiler you wrote as Task 2 actually is a cross compiler. This means that your compiler generated target code that is not for your host system, but on some other target platform \u2013 which in our case the simulated XSM machine. The evaluator done in Exercise 1 actually does not generate \"code\" for any machine. Instead, it executes the program in \"then and there\". Such a program could be classified as an interpreter. (Unfortunately, the standard terminology in literature associated with the term \"interpreter\" seems to be contradictory to this classification).</p>"},{"location":"roadmap/stage-03/","title":"Stage 3: Adding Flow Control statements","text":"<p>Time estimate</p> <p>1 week, 5-10 hours/week</p> <p>Prerequisites</p> <p>You must read the label translation tutorial before proceeding with this stage.</p> <p>Learning Objectives</p> <p>In this stage, you will extend the straight-line-program compiler of Stage 2 to support control flow constructs like if-then-else, while-do, break and continue. You will encounter integer and boolean expressions and the notion of type enroute. You will also learn the use of labels for handling control flow constructs.</p> <p>The if-then-else and the while-do constructs can be added to the source language of Stage 2 by adding the grammar rule:</p> <pre><code>Ifstmt  ::= IF (E) then Slist Else Slist ENDIF\n        | IF (E) then Slist ENDIF;\nWhilestmt ::= WHILE (E) DO Slist ENDWHILE;\n</code></pre> <p>To permit logical expressions, we need to add to the grammar the following productions:</p> <pre><code>E ::= E &lt; E | E &gt; E | E &lt; =E | E &gt;= E | E != E | E == E;\n</code></pre> <p>A simple program in this language to find the largest among three numbers would look like the following:</p> <pre><code>read(a);\nread(b);\nread(c);\nif (a &lt; b) then\n    if (b &lt; c) then Write(c); else Write(b); endif;\nelse\n    if (a &lt; c) then Write(c); else Write(a); endif;\nendif;\n</code></pre> <p>Note that we continue to assume that variables hold only integer values. The first task in  translation is to complete the front end.</p> <p>There is one important conceptual point to understand here before proceeding to the front end  implementation. With the introduction of logical expressions, there are two types of  expressions in the language \u2013 arithmetic expressions and logical expressions.  An arithmetic expression evaluates to an integer value whereas a logical expression  evaluates to a boolean value \u2013 that is true/false.</p> <p>The guard of an if-else statement or a while-do statement must be a boolean expression. On the  other hand, the expression on the right side of an assignment statement must be of integer type as variables are assumed to hold integer values only.  In other words, the statements given below are invalid.</p> <pre><code>if (a+b) then Write(c);\n\u2003\u2003OR\na = b &lt; c;\n</code></pre> <p>Your compiler must flag a \"type mismatch\" error if such constructs are encountered during the  AST construction process. A program with type errors must not pass the compiler's type check scrutiny and the compiler must report error without generating code. Type analysis is a part of the responsibilities of a compiler (normally classified under semantic analysis).</p> <p>A simple way to handle this issue is to annotate each node in the AST with a type attribute that indicates what is the type of the expression (or subexpression) with this node as the root.</p> <p>For example, consider the AST for the following erratic expression. <pre><code>d = ( a + b ) + ( c &lt; 3 )\n</code></pre></p> <p></p> <p>Here, the root of the AST is an assignment node which is typeless. (statements have no type, only expressions have a type associated with them). The left subtree of the root is a variable, and hence has type integer. The right subtree is a + node of type integer. Hence, at the root, there is no type mismatch. However, the right child of the right subtree has type boolean and does not match the operand type for the + operator. Hence the compiler must terminate compilation flagging error \"type mismatch\". Note that the compiler can stop processing when the first error is encountered without proceeding further with the tree construction.</p> <p>To implement type checking, add a type field in the AST node structure.</p> <pre><code>#define inttype 1\n#define booltype 0\ntypedef struct tnode{\n    int val;        // value (for constants)\n    int type;       // type of the variable\n    char* varname;  // variable name (for variable nodes)\n    int nodetype;   // node type - asg/opertor/if/while etc.\n    struct tnode *left,*right;  //left and right branches\n}tnode;\n\n\n/*Create a node tnode*/\nstruct tnode* createTree(int val, int type, char* varname, int nodetype, struct tnode *l, struct tnode *r);\n</code></pre> <p>At the leaf nodes of the tree, since you have either constants or variables, the type must be set to integer. Next, while constructing the tree for intermediate nodes, check whether the types of the children are compatible with the operator at the root. For instance, for the addition operation, the check could be as the following:</p> <pre><code>E :== E+E {\n            if (($1-&gt;type != inttype) || ($2-&gt;type != inttype)) {\n                error(\"type mismatch\");\n                exit();\n            } else {\n                $$-&gt;type = inttype);\n            }\n         }\n</code></pre> <p>If there is no mismatch, you must annotate root node <code>($$-&gt;type)</code> with the proper type (integer in the above case).</p> <p>Note</p> <p>The above check is better done inside the <code>TreeCreate()</code> function so that the  YACC file is not cluttered with C statements.</p> <p>The essential idea is that the type of each node can by synthesized from the types of the subtrees. At any stage, the compiler may terminate flagging error if a type error is found.</p> <p>Task 1</p> <p>Complete the front-end module (AST construction) for the programming language. You need to</p> <ol> <li>add additional lexical tokens for the new constructs</li> <li>make appropriate modifications in the tree node structure including provision for storing type attribute</li> <li>modify the TreeCreate() function to have three subtrees passed (for if-then-else) etc.</li> </ol> <p>Exercise 1</p> <p>To test the implementation of Task 1, implement an evaluator for the expression tree. Test with simple programs like those for finding the largest of 3 numbers, sum of n numbers (n read from input) etc.</p> <p>The next task is to complete the back-end code generation phase. For better clarity, we will split the task into two steps.</p> <p>Step 1: Generate code with labels. At this stage labels will be placed at various control flow points of the target assembly code so that a JMP instruction will only indicate the label corresponding to the instruction to which transfer of program flow must happen.</p> <p>Step 2: Replace the labels with addresses.</p> <p>Important note</p> <p>You must have read the label translation tutorial before  proceeding any further.</p> <p>We will now look at Subtask 1. Consider the following statement:</p> <pre><code>while (a &lt; b) {\n\u2003\u2003a = a + 1;\n}\n</code></pre> <p>The expression tree for the above statement would look like:</p> <p></p> <p>Suppose variable a is bound to address 4096, b to address 4097, then our plan is to generate code that would look like the following:</p> <pre><code>L1:\nMOV R0, [4096]  // transfer a to R0\nMOV R1, [4097]  // transfer b to R1\nLT R0, R1       // a&lt;b\nJZ R0,L2        // if (a&lt;b) is false goto L2\nMOV R0, [4096]  // transfer a to R0\nADD R0, 1       // add 1\nMOV [4096], R0  // transfer sum back to a\nJMP L1          // goto next iteration.\nL2:\n... Next Instruction ...\n</code></pre> <p>Note the use of labels L1 and L2 indicating control flow points in the above code. A while statement involves two jumps and two labels. The labels are just symbols that are placed at the start of instructions to which jump instructions must branch to. Placing labels in the code relieves us from bothering about the exact memory address to which jump must be made. Of course, this is only a temporary measure. The final target code must not contain labels.</p> <p>Our strategy here is to first generate code with labels and then replace the labels with addresses. To implement the plan, we may name labels in the program <code>L0</code>, <code>L1</code>,... We must design an <code>int GetLabel()</code> function that returns the index of the next unused label. Thus the first call to <code>GetLabel()</code> returns <code>0</code>, next call returns <code>1</code> and so forth.</p> <p>The code generation strategy for the while-do statement is illustrated by the following pseudo-code.</p> <pre><code>int label_1 = getLabel();\nint label_2 = getLabel();\nfprintf (target_file \"L%d\", Label_1)        // Place the first label here.\nGenerate code for the guard expression.\nGenerate code to compare the result to zero and if so jump to label_2   // loop exit\nGenerate code for the body of the while loop.\nfprintf(target_file, \"JMP L%d\", label_1);   // return to the beginning of the loop.\nfprintf(target_file, \"L%d\", label_2);       // Place the second label here\n</code></pre> <p>Task 2</p> <p>Complete the code generation with labels for while-do, if-then and if-then-else constructs.</p> <p>Now, we must complete Step 2 of replacing the labels with the correct addresses. This is explained in the label translation documentation.</p> <p>Task 3</p> <p>Read the link specified above and complete the label translation for if-then, if-then-else and the while-do statement.</p> <p>Exercise 2</p> <p>Test your Task 3 code with the following programs:</p> <ol> <li>program to find the largest for a, b, c (values read from input)</li> <li>program to read numbers till 0 is input and output the sum.</li> </ol> <p>Task 4</p> <p>Add break and continue statements. Code for these statements need be generated only if they appear inside some while loop. Otherwise, the compiler may simply ignore these statements, generating no code. (The primary task is to keep track of which label to jump to when one of these statements is encountered).</p> <p>Exercise</p> <p>Add <code>repeat-until</code> and <code>do-while</code> statements to the language with standard semantics.</p> <p>Reading Exercise</p> <p>Please read the GNU Debugger (GDB) tutorial ,before proceeding to the next stage for learning the GDB debugger.</p> <p>Note</p> <p>Often in practice, programming languages allow a program to be split into different functions, written in different source files. In such cases, each file is separately compiled and the compiler generates target code with labels without translating them into addresses. Even variable references will be symbolic and the actual addresses may not be determined. Such target files are called object files. The compiler will include symbol table information in the object file for translation later. A separate software called the linker will collect the information in all the symbol tables and combine the object files into a single executable file replacing labels and symbolic variable references with actual addresses.</p>"},{"location":"roadmap/stage-04/","title":"Stage 4: User Defined Variables and arrays","text":"<p>Time estimate</p> <p>1 week, 5-10 hours/week</p> <p>Learning Objectives</p> <p>You will extend the language of Stage 3 to permit users to declare and use variables of integer and string types. You will learn symbol table management enroute.</p> <p>In this stage, we allow the program to contain variable declarations of the following syntax:</p> <pre><code>Declarations ::= DECL DeclList ENDDECL | DECL ENDDECL\n\nDeclList ::= DeclList Decl | Decl\n\nDecl ::= Type VarList ;\n\nType ::= INT | STR\n\nVarList ::= Varlist , ID | ID\n</code></pre> <p>We will assume hereafter that all variables used in a program must be declared in the declaration section of the program (between the decl and enddecl keywords). Since string type variables are allowed, we will allow string constants as well. (See ExpL specification for details).</p> <p>A simple program in this language to find the sum of numbers entered from the console (until a zero is entered) would look like the following:</p> <pre><code>decl\n\u2003\u2003int num, sum;\n\u2003\u2003str mesg;\nenddecl\n\nread(num);\nsum = 0;\nwhile (num != 0) do\n\u2003\u2003sum = sum + num;\n\u2003\u2003read(num);\nendwhile;\nwrite(\"sum is:\");\nwrite(sum);\nmesg = \"good bye\";\nwrite(mesg);\n</code></pre> <p>It is the responsibility of the compiler to track for various semantic errors as:</p> <ol> <li>Flag error if any variable not declared is used.</li> <li>Flag error if a type mismatch involving any variable is found.</li> </ol> <p>To this end, while parsing declarations, the compiler transfers the information about variables in a compile time data structure called the symbol table. The symbol table stores the following information about each variable:</p> <ol> <li>Name of the variable (known at the time of declaration).</li> <li>Type (For the present stage, only integer/string).</li> <li>Size (For the time being, we will assume that all variables have size one).</li> <li>The memory binding of each variable \u2013 that is, static memory address determined by the compiler for the variable.</li> </ol> <p>The first three entries are determined by the declaration of the variable. For the fourth, a simple strategy would be to allocate the first address (4096) for the variable declared first, <code>4097</code> for the next variable and so on. Note that here too we are fixing the address of each variable at compile time (static allocation).</p> <p>The following structure may be used for a symbol table entry: <pre><code>struct Gsymbol {\n\u2003\u2003char* name;       // name of the variable\n\u2003\u2003int type;         // type of the variable\n\u2003\u2003int size;         // size of the type of the variable\n\u2003\u2003int binding;      // stores the static memory address allocated to the variable\n\u2003\u2003struct Gsymbol *next;\n}\n</code></pre></p> <p>The symbol table entries for the program above would look as below:</p> <p></p> <p>To implement the symbol table, you must write two functions. For a simple implementation, a linear linked list suffices. In modern compilers, hash tables are maintained to make search efficient.</p> <pre><code>struct Gsymbol *Lookup(char * name);            // Returns a pointer to the symbol table entry for the variable, returns NULL otherwise.\nvoid Install(char *name, int type, int size);   // Creates a symbol table entry.\n</code></pre> <p>Note</p> <p>You must check before installing a variable whether the variable is already present. If a variable is declared multiple times, the compiler must stop the compilation and flag error.</p> <p>Task 1</p> <p>Complete the program to parse declarations and set up the symbol table entries and print out the contents of the symbol table.</p> <p>The next task is to make necessary modifications to the AST construction and code generation. These are straightforward. Add a an additional field to the tree node structure</p> <pre><code>typedef struct tnode{\n    int val;                    // value of the constant\n    char* varname;              // name of the variable\n    int type;                   // type of the variable\n    int nodetype;               // node type information\n    struct Gsymbol *Gentry;     // pointer to GST entry for global variables and functions\n    struct tnode *left,*right;  // left and right branches\n}tnode;\n</code></pre> <p>While constructing the tree, if a variable is encountered, keep a pointer to the corresponding symbol table entry. Set the type field as well to the correct type. The rest of the type checking steps are exactly as in the previous stage. The AST of while loop present in the above code is as follows (the relevant part of the code is shown below for easy reference): <pre><code>.\n.\n.\nwhile (num != 0) do\n    sum = sum + num;\n    read(num);\nendwhile;\n.\n.\n.\n</code></pre></p> <p></p> <p>There is no serious change to the code generation process, except that for variables, the binding address is obtained from the symbol table.</p> <p>Important Note</p> <p>The XSM architecture is unrealistic in that allows a memory word to hold a string. Normally, in a real system, a string would require storing the characters one after another in consecutive memory locations as in an array. You will anyway learn array allocation immediately.</p> <p>Task 2</p> <p>Complete the AST construction and code generation steps.</p>"},{"location":"roadmap/stage-04/#adding-arrays","title":"Adding arrays","text":"<p>The next step is to allow declaration of arrays like: <pre><code>decl\n    ---\n    int a[100];\n    str names[20];\n    ---\nenddecl\n</code></pre></p> <p>The declaration syntax must permit:</p> <pre><code>Varlist ::= Varlist , ID[NUM] | ID[NUM]\n</code></pre> <p>To implement this, for each variable, you must reserve as much static space as specified by the declaration and set the size field in the symbol table to indicate the number of words allocated. The next variable must be allocated space only below this space allocated.</p> <p>For instance, for the declaration,</p> <pre><code>decl\n\u2003\u2003int a[10], b;\nenddecl\n</code></pre> <p>The binding field in the symbol table for the variable a may be set to address 4096. The size entry set to 10. This means that we are allocating locations 4096-4105 for the array. The next variable, b can be bound to the address 4106.</p> <p></p> <p>Task 2</p> <p>Complete the implementation of single dimensional arrays.</p> <p>Exercise 1</p> <p>Permit two dimensional arrays like: <pre><code>    int a[10][10];\n</code></pre> Test your implementation with a program for multiplying two <code>n x n</code> matrices.</p> <p></p> <p>Exercise 2</p> <p>Permit <code>pointer type</code> variables as in the following declaration as in the C programming language. <pre><code>decl\n\u2003\u2003int x, *p;\n\u2003\u2003str p, *q;\nenddecl\n</code></pre> If you permit assignments like <code>p=&amp;x;</code> and <code>q=&amp;p;</code> , pointer variables may also be permitted in expressions like <code>*p=*q+1;</code> for referring to the data pointed to, as permitted in the C programming language.</p> <p>Semantic rules as in the C programming language may be assumed.</p> <p>Note</p> <p>Right now, you are not equipped to do dynamic memory allocation for pointer variables (as done by the <code>malloc()</code> function of C). Hence, a pointer type variable can be used as a pointer to another statically declared variable of the corresponding type. Dynamic memory allocation will be discussed in later stages.</p>"},{"location":"roadmap/stage-04/#test-programs","title":"Test Programs","text":"<p>Check your implementation with the following test cases :</p> <ol> <li> <p>Bubblesort (iterative)</p> <p>This test program reads elements into an array and sorts them using the classic bubblesort algorithm. (iterative version)</p> <p>Input : 1. Number of elements to be sorted from standard input. 2. Elements to be sorted</p> <p>Output : A sorted array of elements.</p> <p>To get the code for this test program click here.</p> </li> <li> <p>Nth Fibonacci Number(iterative)</p> <p>This test program prints the nth fibonacci number</p> <p>Input : 1.An integer n Output : nth fibonacci number</p> <p>To get the code for this test program click here.</p> </li> <li> <p>Is Prime or Not</p> <p>This program tests if a given integer is prime or not.</p> <p>Input : 1.An integer n Output : Prime if n is prime else not a prime.</p> <p>To get the code for this test program click here.</p> </li> <li> <p>Sum of n factorials (iterative)</p> <p>This program prints the sum to n factorial for a given n.</p> <p>Input : 1.An integer n Output : sum of factorial of all integers 1 to n.</p> <p>To get the code for this test program click here.</p> </li> </ol>"},{"location":"roadmap/stage-05/","title":"Stage 5: Adding Functions","text":"<p>Time estimate</p> <p>2 weeks, 5-10 hours/week</p> <p>Prerequisites</p> <p>You must read the following documents before proceeding with this stage:</p> <ol> <li>The main page of the document Run time allocation.</li> <li>Run time stack Allocation.</li> </ol> <p>Learning Objectives</p> <p>You will extend the language of Stage 4 by adding functions with support for recursion. Addition of functions to the language requires handling scope of variables. Support for recursion demands run-time storage allocation. Only integer and string type variables will be supported.</p> <p>This is the first major stage in the ExpL project. A skeletal outline of the syntax rules for defining the extension of the language of Stage 4 to support subroutines is as below. You are required to fill in rules required to complete the grammar. Note that variables may be only of type integer/string.</p> <pre><code>Program ::= GDeclBlock FdefBlock MainBlock\n\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003| GdeclBlock MainBlock\n\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003| MainBlock\n\nGdeclBlock ::= DECL GdeclList ENDDECL | DECL ENDDECL\n\nGdeclList ::= GDeclList GDecl | GDecl\nGDecl ::= Type GidList ;\n\nGidList ::= GidList , Gid | Gid\n\nGid ::= ID\n\u2003\u2003\u2003\u2003\u2003| ID\\[NUM\\]\n\u2003\u2003\u2003\u2003\u2003| ID(ParamList)\n--------------------------------------------------------------------------------------\nFDefBlock ::= FdefBlock Fdef | Fdef\n\nFdef ::=Type ID ( ParamList ) { LdeclBlock Body }\n\nParamList ::= ParamList , Param | Param\n\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003| \u2003\u2003/\\*param can be empty\\*/\n\nParam ::= Type ID\n\nType ::= INT | STR\n-----------------------------------------------------------------------------------------\n\nLdeclBlock ::= DECL LDecList ENDDECL | DECL ENDDECL\n\nLDecList ::= LDecList LDecl | LDecl\n\nLDecl ::= Type IdList ;\n\nIdList ::= IdList, ID | ID\n\nType ::= INT | STR\n\nSince a function call is treated as an expression (whose value is the return value of the function), the following rules must be added:\n\nE ::= ID () | ID(ArgList)\n\nArgList ::= ArgList, E | E\n</code></pre> <p>Here is an example for a program with a function. We will take up semantic analysis and AST representation before proceeding to code generation.</p> <p>Each function requires a declaration. The declaration of functions must be made along with the global declarations. The declaration of a function must specify the types and names of the formal parameters and the return type of the function. The compiler must store the declaration information in the global symbol table. For example, the declaration</p> <pre><code>decl\n..\n..\n\u2003int factorial(int n);\n..\n..\nenddecl\n</code></pre> <p>specifies that factorial is a function that takes as input one integer argument and returns an integer. This is sometimes called the signature of the function. Conceptually, to invoke the factorial function, the caller must know:</p> <ol> <li>The memory address to which the function call must be directed (binding).</li> <li>The types and names of the formal parameters to the function and the order in which the actual arguments must be given as input to the function.</li> <li>The return type of the function.</li> </ol> <p>This precisely is the information that the symbol table stores.</p> <p>A function definition contains:</p> <p>a. The function's signature. b. The declaration of local variables of the function. c. The code of the function.</p> <p>For example, the definition of the factorial function could be as: <pre><code>int factorial(int n){\n\u2003decl\n\u2003\u2003int f;\n\u2003enddecl\n\u2003begin\n\u2003\u2003if( n==1 || n==0 ) then\n\u2003\u2003\u2003f = 1;\n\u2003\u2003else\n\u2003\u2003\u2003f = n * factorial(n-1);\n\u2003\u2003endif;\n\u2003return f;\n\u2003end\n}\n</code></pre></p> <p>Local variables declared in a function are visible only within the function. We say that the scope of a local declaration is limited to the function. Moreover, if a global variable is redeclared inside a function, the local declaration overrides the global declaration.</p> <p>Thus, we have two kinds of variables. Global variables that are visible \"everywhere\" (or having a global scope) and local variables that are visible only within the functions (or having a local scope) where they are declared.</p> <p>The compiler needs to know the binding addresses and types of the local variables for translation of statements of the function to assembly code. However, this information is irrelevant outside the function.</p> <p>To keep track of the local variable and scope information, our strategy is to keep global and local variables in different symbol tables. We will have</p> <ul> <li> <p>1. A single global symbol table storing the (name, type, size, binding) information of global variables as well as (name, type, parameters, binding) information for functions. The following structure is suggested for storing a global symbol table entry.</p> <p>struct Gsymbol{ char *name; //name of the variable or function \u2003\u2003int type; //type of the variable:(Integer / String) \u2003\u2003int size; //size of an array \u2003\u2003int binding; //static binding of global variables \u2003\u2003struct Paramstruct *paramlist;//pointer to the head of the formal parameter list \u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003\u2003 //in the case of functions \u2003\u2003int flabel; //a label for identifying the starting address of a function's code \u2003\u2003struct Gsymbol *next; //points to the next Global Symbol Table entry };</p> </li> <li> <p>2. Several local symbol tables - one for each function containing the (name, type, binding) information for each local variable of the function. (Note that since the language does not permit arrays to be defined within a function, the size value of local variables is always 1, hence the field is not required). A local symbol table entry can be stored in the following structure:</p> </li> </ul> <p>struct Lsymbol{ char *name;\u2003\u2003\u2003\u2003 //name of the variable \u2003\u2003int type; \u2003\u2003 //type of the variable:(Integer / String) \u2003\u2003int binding;\u2003\u2003\u2003\u2003 //local binding of the variable \u2003\u2003struct Lsymbol *next;\u2003\u2003 //points to the next Local Symbol Table entry };</p> <p>Note: As noted in the run time storage allocation documentation, local variables cannot be assigned static memory addresses. Hence, the binding of a local variable is a relative address within the function's activation record. We will discuss this matter in detail later.</p> <p>What is the stored in flabel? When the compiler generates code for the function, a label is placed at the start of the function. A call to the function is translated to a low-level CALL to the corresponding label. Later, the label has to be replaced by the address of the instruction during the label translation phase.</p> <p>The simple scheme we suggest here is to put the label F0 before the code of the first function declared in the program, F1 before the code of the second and so on. Hence, in the flabel field of the first function, store 0. Similarly, store 1 in the flabel field of the second function and so on. A call to the first function must be translated to CALL F0 and so on.</p> <p>With this, the global symbol table for the program would be as below.</p> <p></p> <p>Continuing with the above example, we need two local symbol tables \u2013 one for the main function and one for the factorial function. The local symbol table holds the (name, type, binding) triple for each formal parameter as well as local variables of the function. We will discuss the binding of formal parameters and local variables later. The local symbol tables of main and factorial would look as the following:</p> <p></p> <p></p> <p>See LINK for more details. For now, ignore the type table pointer in the structure given in the link. This will be discussed in the next stage.</p> <p>Task 1: Complete the program to build the global symbol table. Test your program by printing out all global declarations in the program by displaying the contents of the symbol table. You must not permit two variables/functions (or a function and a variable) to have the same name.</p> <p>Our next aim is to perform semantic analysis, build the AST and then generate code. The strategy will be the following:</p> <ul> <li>1. First, parse global declarations and create the global symbol table entries for functions andglobal variables (Already completed as Task 1)</li> <li>2. For each function for which code is not yet generated<ul> <li>a) Check for name equivalence of the formal parameters of the function definition with the declaration. Name equivalence requires that the type and name of each formal parameter of the function in the declaration and the definition must agree.</li> <li>b) Create local symbol table containing local variables and parameters.</li> <li>c) Build AST for the function. (Do type-checking when the tree is being built, as was done in the previous stages.)</li> <li>d) Recursively traverse the tree and generate code for the function in the target file.</li> </ul> </li> </ul> <p>After generating code for a function, the local symbol table and the abstract syntax tree for the function can be deallocated. Proceed to step 2 for the next function.</p> <p>Note that the code and the local variables of a function are not visible outside the function. Hence, the local symbol table and the AST for a function are not required once the code is generated. To generate code for calling one function from another function, only the global symbol table information of the callee is needed. The global symbol table is maintained throughout the compilation process. Note that the main function is just like any other function except that it has no arguments, its name must be main and return type must be int as per the specification.</p> <p>The only non-trivial part about semantic analysis and AST construction pending discussion is how to build AST for a function call.</p> <p>We start with an example. Suppose we have the following declarations:</p> <p>int Compute(int p, int q); int find(int x);</p> <p>A call to the function would occur as in:</p> <p>t = Compute(a+b,find(a-b));</p> <p>The statement is semantically valid provided a, b, and c integer type variables. Note that the call might occur in the code of any function (including the same function \u2013 as in the case of a recursive call).</p> <p>The expression tree for this could look as below:</p> <p></p> <p>A tree node for a function call contains a pointer to a list of expressions, one expression for each argument. The compiler must type check each argument and match it with the type of the corresponding formal parameter of the called function.</p> <p>To get an overall picture of what is going on, you may read the documentation on compile time data structures at this juncture. Ignore type table entries for now as we permit only integer/string variables in the present stage.</p> <p>The expression tree structure given HERE can be used (again, ignore type table pointer) The details of implementation are left to you.</p> <p>With this information, the task of completing type checking and building expression tree for a function is straightforward.</p> <p>Task 2: Construct AST for each function after checking type and scope rules (semantic analysis). Right now, we are concerned just with type and scope analysis and not code generation. Note that a variable appearing in a function must first be searched for in the local symbol table of the function and then in the global symbol table, if not found in the local symbol table. Note that local declaration overrides global declaration. The compiler must report an error if the types, names and number of arguments in each function declaration are not matching with the function definition.</p> <p>Now we turn to the code generation step.</p> <p>The dynamics of a function call can be understood easily by dividing the process into the following three stages.</p> <ul> <li>Step 1. Code executed in the calling function (caller) before the transfer of control to the called function (callee):<ul> <li>a) The caller must save the registers in use so that even if the callee changes the values later, the original values can be recovered after return from the callee.</li> <li>b) The caller must evaluate the arguments to the callee and store it somewhere in a way that the callee can access those values.</li> <li>c) The caller must create some space for the callee to place the return value at the end of the call.</li> <li>d) The caller must transfer control to the binding address of the callee.</li> </ul> </li> <li>Step 2. Actions executed by the called function (callee):<ul> <li>a) The callee must allocate space for its local variables.</li> <li>b) Execute the callee code.</li> <li>c) When encountering a return instruction, the return value must be computed and stored in the appropriate place specified by the caller (step 1.c above).</li> <li>d) Return control to the caller.</li> </ul> </li> <li>Step 3. Actions executed by the caller after the callee returned control back to the caller.<ul> <li>a) Recover the return value stored by the callee.</li> <li>b) Deallocate space allocated for arguments for the call in step 1(b).</li> <li>c) Recover the machine registers stored before the call in step 1(a).</li> </ul> </li> </ul> <p>The machine code for actions in Step 1 and Step 3 must be generated when the compiler encounters a function call in the caller's code. The compiler generates code for Step 2 while generating code for the callee function.</p> <p>To implement the above plan, we need to create storage space whenever a function call is encountered. We will be focusing on generating code containing labels. Translation of labels to actual addresses can be easily done at the end as was done in Stage 4 following the Label Translation Documentation.</p> <p>Implementation Strategy.</p> <p>The fundamental strategy for space allocation is to create an activation record for the callee in the stack when a function call is encountered. The compiler must generate code for creating the activation record at run-time when the call is encountered. Since the storage requirements for arguments, local variables and the return value of a function are known at compile time, the compiler knows exactly how much space must be allocated for each function. We propose following general organization for activation records:</p> <ul> <li>1. Each activation record must have a base (memory location) which is determined at run time. The machine register BP (base pointer) is generally used to point to the base of the activation record of the function executing currently.</li> <li>2. Relative to the base, the address of each argument, each local variable, the address where the return value is stored etc are fixed by the compiler statically (at compile time).</li> <li>3. Initially, the activation record for the main function is created in the stack. BP is initialized to the base of this activation record and the main function starts execution.</li> <li>4. If function A calls function B, a new activation record is created in the stack for function B above the activation record of function A. The BP is made to point to the base of activation record of B. Upon return from B, the activation record of B is popped off the stack and BP is set back to the activation record of A.</li> <li>5. If function A calls function B, the address of the instruction in A to resume execution (return address \u2013 value of current-IP +2 in XSM machine- why?) upon return from B must be saved. Similarly, the base pointer of the caller (BP value) of A must be saved in the stack before BP is changed to point to the base of B. Both the return address and BP values will be stored in pre-defined locations of the activation record of B.</li> <li>6. In addition to the above, one additional space must be reserved in the activation record of B to store the return value.</li> </ul> <p>A thorough reading of this page is absolutely essential to proceed any further. Suppose a function has n arguments (arg_1, arg_2,...,arg_n) and m local variables (loc_1, loc_2, ..., loc_m), its activation record in the stack may look as the following.(The stack is assumed to grow downwards.)</p> <p></p> <p>In this scheme, the following code must be generated by the caller when a call to the above function is encountered:</p> <ul> <li>1. Generate code to push registers in use into the stack. After this, the callee's activation record begins.</li> <li>2. Evaluate arg_n and push the value to the stack. Now evaluate and push arg_n-1 and so on till arg_1. The arguments are pushed in reverse order. (You can do it in any order as long as the same convention is followed everywhere).</li> <li>3. Push one empty space in the stack for the callee to store the return value.</li> <li>4. Generate Call instruction to the binding (label) of the function. (The call instruction will push IP+2 into the stack and jump to label.)</li> </ul> <p>Stack before the call instruction :</p> <p></p> <p>Stack after the call instruction :</p> <p></p> <p>Figure: Actions in the stack done by the caller before the call</p> <p>Once the call is made, the next instruction in the caller will be executed only after the callee executes a return statement. The caller must proceed from here assuming that the callee would have placed the return value in the location in the stack designated for it. The caller must generate code to extract the return value and clean up the stack.</p> <ul> <li>5. Allocate a new register and store the returned value into the register.</li> <li>6. Pop out arguments from the stack. (The arguments may be discarded now.)</li> <li>7. Restore registers saved in the stack in step 1.</li> </ul> <p>The above actions are sufficient to generate code for handling a function invocation. Note that to generate code for a call, only the callee's declaration information (argument information and call label) needs to be known. All that the caller needs to know is the callee's interface, and the calling convention (convention regarding in what order arguments must be pushed, where should the return value be stored etc. See also link).</p> <p>Now, we turn to the actions to be done by the callee. The callee must generate the following code before proceeding to the remaining instructions:</p> <ul> <li>1.Save the BP of the caller by pushing the BP register into the stack.</li> <li>2.Set BP to the present value of SP register.</li> <li>3. Push enough space in the stack for storing the local variables.</li> </ul> <p>Relative to the BP value set in step 2 above, [BP-2] is the address to which the return value must be stored. [BP-3] stores arg_1, [BP-4] stores arg_2 and so on. [BP+1] is for loc_1, [BP+2] for loc_2 and so on. Thus, after seeing the local variable declarations, the compiler can set the binding values for local variables relative to the base of activation record (BP) value as:</p> <p></p> <p>With this convention, the code for each instruction inside a function can be generated following the rule: local variables/arguments are to be dereferenced a by adding the binding value to the contents of the BP register. Almost every modern architecture supports function calls by providing an explicit base pointer register.</p> <p>Finally, the code for a return statement must:</p> <ol> <li>Pop out the local variables from the stack.</li> <li>Calculate the return expression and store the value in [BP-2].</li> <li>set BP to the old value of BP in the stack.</li> <li>Execute the RET instruction to pass control back to the caller.</li> </ol> <p>In the calling convention which we described above, the arguments were pushed in reverse order, space for the return value was allocated by the caller, BP of the caller was saved to the stack by the callee, and so on. Space created in the stack by either the callee or the caller must be eventually reclaimed by the same party.</p> <p>IMPORTANT NOTE</p> <p>In our calling convention, the caller was required to save the registers in use before the call. What if instead, we design a calling convention where the callee had to push the registers in use? The problem here is that the callee does not know (and does not have to know) the caller and hence do not know at each call which were the registers in use. Hence, the callee will have to save all machine registers, wasting time and space. Hence, the convention of the caller storing registers in use is superior. However, there are situations where this is not possible. For instance, in hardware interrupt routines, control is transferred to the callee without the caller executing a call. In such cases, the callee will have to save (all) the machine registers for a successful return.</p> <p>You have enough background now to complete the final task of this stage.</p> <p>Task 3</p> <p>Complete code generation for functional calls.</p> <p>Exercise 1</p> <p>Modify the function semantics to permit pointer type variables of Stage 4 (Exercise 2) to be passed as arguments to functions. This will allow a function to pass the address of a local variable to another function as an argument so that the callee can modify the contents. Modify the syntax and semantics rules appropriately. This feature must allow you to write functions like:</p> <p><code>int swap(int *p, int *q)</code></p> <p>Note that functions need to be permitted to return pointer type variables. (Returning a pointer to local variable from a function is not advisable \u2013 Why?).</p> <p>Exercise 2</p> <p>Hard work, but insightful</p> <p>Suppose you want to extend the language with facility of tuples. By a tuple, we mean an object declared as below:</p> <pre><code>decl\n..\n..\n\u2003tuple tnme(type fname\\_1, type fname\\_2, .... ,type fname\\_n) var\\_1, var\\_2 .. var\\_k;\n..\n..\nenddecl\n</code></pre> <p>Note that tuple is introduced as a new keyword. For example, we could have:</p> <pre><code>decl\n\n\u2003tuple student (str name, int roll\\_no, str branchname, int year\\_of\\_admission) a, b, c, \\*sptr;\n\u2003tuple faculty (str name, int employee\\_id, str dept) x, y, z, \\*fptr;\n\nenddecl\n</code></pre> <p>To access a tuple you must introduce the \".\" operator. Here is an example:</p> <pre><code>read(a.name);\nread(x.name);\nif (a.name == x.name) then\n\u2003write(\"They have same names\");\nendif;\n</code></pre> <p>You must also permit assignment of a tuple type variable to another, provided the variables are of the same tuple type.</p> <p>Design the syntax and semantics rules, make necessary modifications to the lexer, parser, symbol table and AST structures to incorporate the addition of tuples and change the code generation module accordingly. For now, assume that tuples cannot be passed as arguments to functions or be returned by functions. However, you must permit local tuple declarations. Note that you have considerable freedom in deciding on the grammar rules and data structures, and even the features permitted.</p> <p>Exercise 3</p> <p>Hard work, optional, but insightful. Can be done only after Exercise 1 and Exercise 2 are completed</p> <p>Allow tuples and pointers to tuples to be passed as arguments to functions. (Allowing the whole tuple to be passed creates more work in parameter passing, though not difficult in principle). Functions may be permitted to return tuples as return values. Permit a function that takes an argument/returns a tuple or pointers to tuple type to be declared only after the declaration of the concerned tuples (this is to avoid the forward reference problem). Design syntax, semantics and code generation strategies appropriately.</p>"},{"location":"roadmap/stage-05/#test-programs","title":"Test Programs","text":"<p>Check your implementation with the following test cases :</p> <ul> <li>Test Program 1 : Bubblesort (recursive)</li> <li>Test Program 2 : Factorial (recursive)</li> <li>Test Program 3 : Quicksort (recursive)</li> <li>Test Program 4 : Constant Program (recursive)</li> <li>Test Program 5 : Fibonacci (recursive)</li> <li>Test Program 6 : Extended Euclid(with a Function)</li> <li>Test Program 7 : BubbleSort (iterative)</li> <li>Test Program 8 : Extended Euclid(iterative)</li> </ul>"},{"location":"roadmap/stage-06/","title":"Stage 6: User defined types and Dynamic Memory allocation","text":"<p>Time estimate</p> <p>2 weeks, 5-10 hours/week</p> <p>Prerequisites</p> <ol> <li>Read the ExpL specification.</li> <li>Read about Dynamic memory allocation.</li> </ol> <p>Learning Objectives</p> <p>You will extend the language of Stage 5 by adding support for user-defined types and dynamic memory allocation. Issues of Heap management will be encountered en route.</p> <p>This is the second major stage of the ExpL compiler project and will be implemented in two parts. In the first part, we will see how user defined types can be added to the language syntax and how semantic analysis can be performed. The ExpL specification demands storage for user-defined types dynamically. We will discuss how dynamic memory allocation can be achieved in the second part.</p> <p>See the ExpL language specification for an informal description of the language. It is suggested that you design your own grammar using the outline provided here as a reference. The following link provide examples of ExpL programs containing user defined types.</p> <p>We will now take up the front end - semantic analysis and AST representation - before proceeding to code generation and dynamic memory allocation.</p>"},{"location":"roadmap/stage-06/#part-i-front-end","title":"Part I: Front End","text":"<p>Every user defined type requires a type definition. Type definitions are placed at the beginning of a program, ahead of global declarations. A user-defined type in ExpL essentially defines an aggregate type. The member fields of a user defined type may have arbitrary types (subject to certain constraints \u2013 to be discussed soon).</p> <p>Consider the type definition:</p> <pre><code>type\n    bst {\n        int a;\n        bst left;\n        bst right;\n    }\nendtype\ndecl\n    int in,opt;\n    bst insert(bst h, int key);\n    int inOrder(bst h);\n    int preOrder(bst h);\n    int postOrder(bst h);\nenddecl\n</code></pre> <p>This type definition specifies the node structure for a binary search tree. The member field a has  type integer, whereas left and right have type bst. Note the recursive nature of the type  definition. The declaration section shows functions which take as  input a bst or returns a bst. Here is another type definition:</p> <pre><code>type\n    linkedList {\n        int data;\n        linkedList next;\n    }\n    markList{\n        str name;\n        linkedList marks;\n    }\nendtype\ndecl\n    markList mList,temp;\nenddecl\n</code></pre> <p>Note here that in the type markList, the member field marks is of the type linkedList.  ExpL stipulates that the member fields of a user defined type, if not of type integer or string, can only be of the same type or one of a previously defined type.</p> <p>The compiler must keep track of the type definitions in some data structure. For this purpose, we will maintain a type table storing the type definition information. Each user defined type will have a type table entry. In addition to user-defined types, the type table will also store \"default\" entries for int, str, bool and void type. (Since logical expressions evaluate to a boolean value, they may be assigned boolean type. The ExpL constant NULL can be assigned to a variable of any user-defined type. Hence, having a NULL type is useful from a purely implementation perspective. Note here that boolean is an implicit type in the language. The language does not allow the programmer to declare a variable of type boolean).</p> <p>The type table entry for a user-defined type must provide information about the names and types of its member fields. For each member field, a pointer to its type table entry must  be maintained. This link gives you a simple type table implementation scheme. (You have to fill in missing details).</p> <p>Symbol table must also be modified to handle user-defined-types information. The type field of the symbol table entry of a variable/function shall refer to the type table entry of the corresponding type (Recall that in the case of a function, the type of a function is its return type). The following link illustrates the organization of the global symbol table. The type entry of each formal parameter of a function must also refer to the corresponding type table entry. Local symbol tables of functions will require similar modification.</p> <p>The next question is how to assign memory for user defined type variables. We will defer this issue temporarily and hence, for now, will not discuss how to assign bindings to variables of user-defined types right now. This will be discussed in Part II.</p> <p>We must now discuss how to use the symbol table and type table for completing semantic analysis of the input program. Let us look at an example.</p> <p>Consider the declaration of the type markList in the example above. The language now permits statements like:</p> <pre><code>temp = mList.next;\nif (mList.marks.data &gt; mList.next.marks.data) then\n    write(\"first student performed better in the first subject\");\nendif;\n</code></pre> <p>Note that the operands in expressions can now be member fields of user-defined-type variables. Similarly, the left side of an assignment statement or the variable for a read statement can now be a member field. The grammar rules for various statements in the language are outlined here. You must try to design your own grammar, keeping the grammar  above as a guideline. Many details are (deliberately) left out in the outline given to you.</p> <p>In the following, we use the term field generically to refer to any member field of any  variable (of any user-defined type).</p> <p>What must be the type of a field? The type of mList.next in the above example must be the type of the member field next of the user defined type markList. Once this information is extracted  from the symbol table, the type of any statement, expression or variable can be determined correctly. Thus, an assignment statement is valid provided the types of the right side expression matches with that of the left side variable. The only exception to this rule is that the constant NULL can be assigned to any variable of any user-defined type.</p> <p>Stated formally,</p> <pre><code>Field :: = Field '.' ID { $$.type = $3. type; }\n\u2003\u2003\u2003\u2003\u2003\u2003\u2003 | ID '.' ID { $$.type = $3.type; }\n</code></pre> <p>While constructing the AST, the type entry for any field may be recursively computed using the  formal rule noted above. This information can be used for effective semantic analysis. Arguments to functions must also be type checked against formal parameters of their declaration.</p> <p>A plausible tree node structure and associated functions for  AST construction are described here.</p> <p>Note</p> <p>ExpL specification demands a rigid type analysis by name equivalence. This differs from the more liberal structural equivalance in the C programming language.</p> <p>With this background, the front end of the ExpL compiler can be completed.</p> <p>Task 1</p> <p>Complete the syntax and semantic analysis and construct AST for ExpL language. (Specification, Grammar Outline)</p>"},{"location":"roadmap/stage-06/#part-ii-back-end","title":"Part II: Back End","text":"<p>We will first discuss the underlying concepts before getting into the back-end implementation details.</p> <p>The ExpL specification stipulates that the storage for a variable of a user-defined-type is allocated through the Alloc() function. Each user-defined-type variable in ExpL must store the reference to its actual memory store. The actual memory may be allocated by Alloc() when a call to the function is encountered at run time.</p> <p>From an implementation point of view, a variable of a user-defined-type must be designed to hold the address of its actual memory store. Whenever the Alloc() function is invoked for the variable, a memory region sufficient for holding all the member fields of the variable must be allocated \"somewhere\" in memory and Alloc() must return the starting address of that memory region. The compiler must generate code to invoke Alloc() and store the return value into the variable. Thus, the variable will essentially store a pointer to the memory region allocated by Alloc(). This is easy to do, provided we have the Alloc() function at our disposal.</p> <p>A variable of a user-defined-type must be allocated at compile time one memory word to store an address (basically an integer) returned by Alloc() at run time. The allocation could be static or run-time. ExpL specification does not permit arrays of user-defined type.</p> <p>Once the memory is allocated for a user-defined type variable, member field references can be  translated easily. The details are left to you.</p> <p>The next problem is to design and implement the Alloc() function. We will also take up the  issue of designing the Free() function (to de-allocate some previously allocated memory).  This problem is known as the dynamic memory allocation problem. (The malloc() and free() functions of the C library are dynamic memory allocation routines of the C programming language.)</p> <p>The strategy of Alloc() is to maintain a memory pool called heap memory. Alloc() will need to manage a large run-time memory pool. To make matters simple, we will assume that Alloc() divides the whole memory into fixed size blocks, each of size eight words. In this case, the strategy is very simple:</p> <ol> <li>Before the start of the program, reserve a large area of the address space for heap.     The ExpOS memory model suggests that the address     region 1024-2047 may be used for this purpose.</li> <li>Organize the heap into a linear linked list of blocks of size 8.     We will design a heap initializer function Initialize() specifically for this.</li> <li>When an Alloc() request comes, return the start address of the first     free block in the list (and remove the block from the free list).</li> <li>When a Free(address) request comes (assuming address refers to the start address of a     block already allocated), return the block pointed to by address back to the memory pool.</li> </ol> <p>The pragmatic restriction imposed by such a simple implementation is that a user-defined type cannot have more than eight-member fields. Of course, we could have increased the block size to \u2013 say sixteen \u2013 in which case the number of member fields can be upto 16. For now, we will be content with the simple fixed block size scheme.</p> <p>With this, we can design our compiler to generate code for Alloc(), Free() and Initialize() functions along with the target code. Techniques of Stage 5 suffices to build an executable file.</p> <p>However, there is a better way of doing things when OS support for shared library is available. Note that we have been using the shared library for console input, output etc. Since the routines Alloc(), Free() and Initialize() will be used by every ExpL program (that uses user-defined types), it would be profitable to write these routines once and add them as part of the library. Since the OS loader loads the shared library to the memory region 0-1023 of the address space of each program, the code for Alloc(), Free() and Initialize() too will be available to the program. The library interface must be defined so that the calling conventions for invoking each of the above functions are clearly specified.</p> <p>With this strategy, when an ExpL program is compiled, the compiler will not generate code to implement Alloc(), Free() or Initialize(). Instead, the compiler will generate a CALL to the library (using the library interface) with appropriate arguments so that the corresponding library routine is invoked. You need to modify the library code so that the assembly code for Alloc(), Free() and Initialize() are added to the library. The advantage of this method is that the code implementing Alloc(), Free() and Initialize() need not be part of the the code of every executable program, saving both load-time and system memory. The technical jargon calls such a library a run time loading library.</p> <p>The ABI stipulates that calls to the dynamic memory functions shall be directed through the Library. Thus, you must add Alloc(), Free() and Initialize() as library functions. As noted previously, the region of memory between address 1024 and 2047 must be used for heap memory allocation.</p> <p>It is absolutely necessary to read and understand Dynamic memory allocation (except Buddy System Allocation) to proceed further. An overall picture of the ExpOS library design is outlined in the library implementation documentation. We are now ready to complete the back end.</p> <p>Task 2</p> <p>Complete the back-end adding Alloc(), Free() and Initialize() functions to the ExpOS library and complete the implementation of adding user defined types to ExpL. Assume fixed block size of 8 words for memory allocation. The compiler must flag an error \"too many member fields\" if a user-defined type definition has more than 8 member fields. Note that the fixed block allocator is pretty simple to be written directly in assembly language. Read the note below before proceeding with the implementation.</p> <p>Important Note</p> <p>Your library functions will need to modify registers and hence before a library call, ensure that registers in current use are saved in the stack (as was done with function calls in the previous stage).</p> <p>Exercise 1</p> <p>Extend ExpL to permit arrays of user-defined type.</p> <p>If you want to do variable sized block allocation, more complex allocation schemes like the Buddy System Algorithm will be required. One would also need to understand the issue of memory fragmentation that can arise when variable sized allocation is done.</p> <p>Exercise 2: (Optional)</p> <p>Modify Alloc() and Free() library functions to implement the Buddy memory allocator described here. You will have to modify Initialize() appropriately. The buddy system allocator is too complex to write in assembly language. Hence write them in ExpL itself and modify your label translation scheme to generate target addresses correctly.</p>"},{"location":"roadmap/stage-06/#test-programs","title":"Test Programs","text":"<p>Check your implementation with the following test cases:</p> <ul> <li>Test Program 1: Linked List</li> <li>Test Program 2: Binary Search Tree</li> <li>Test Program 3: Extended Euclid Algorithm using linkedlist</li> <li>Test Program 4: Extended Euclid Algorithm using Userdefined types</li> </ul>"},{"location":"roadmap/stage-07/","title":"Stage 7: Adding Objects \u2013 Data encapsulation","text":"<p>Time estimate</p> <p>2 weeks, 5-10 hours/week</p> <p>Prerequisites</p> <ol> <li>Read the OExpL specification     (except for the section on inheritance, which may be read before the next stage).</li> </ol> <p>Learning Objectives</p> <p>You will extend the language of Stage 6 by adding support to classes (except for inheritance) to make ExpL an object based language.</p> <p>In this stage, we will extend ExpL to provide support for data encapsulation by supporting classes. Inheritance will be added in the next stage.</p> <p>From an implementation view-point, a class is similar to a user defined type that, apart from member fields, also contain member functions or methods. The access rules of class members and methods are more stringent. Read the (OExpL specification carefully for access semantics.) Here, we will focus on how support for classes can be added to the compiler.</p>"},{"location":"roadmap/stage-07/#part-i-syntax-and-semantic-analysis","title":"Part I: Syntax and Semantic Analysis","text":"<p>The grammar outline for class definitions is given here. The following grammar rule allowing class extension (in Class Definitions) will not be supported in this stage.</p> <pre><code>Cname : ID Extends ID { Cptr = Cinstall($1-&gt;Name,$3-&gt;Name); }\n</code></pre> <p>Support for class extension will be introduced in the next stage.</p> <p>The compiler must maintain a class table to store the information pertaining to each class defined in an OExpL program. Class definitions appear after type definitions. Each class definition specifies the member fields and methods of the class. Member field declarations must precede method declarations.</p> <p>For simplifying the implementation, we will assume here that a class may contain at most 8 member fields and at most 8 methods. Hence, fixed size allocation of dynamic memory will be sufficient, as in the 6th stage.</p> <p>Each class table entry stores information pertaining to a class. The names and types of each member field along with its position index must be stored in the class table (In any class, the method defined first will be assigned position index as 0, the method defined next will be assigned position index as 1 and so on). For each method, the signature of the method (method name, return type, types and names or arguments) along with the binding (label of the method \u2013 a call to the method must be translated to a call to this label) needs to be stored. The type field for a variable/method must contain a pointer to the corresponding type table entry. An exceptional case is when a member field is of a previously defined class. In this case, a pointer to the class table entry of the member field must be maintained.</p> <p>A thorough reading of the details of class table implementation is necessary to proceed further. In this stage, we will not support class extension. Hence, the parent class pointer entry for each class must be set to NULL.</p> <p>For now, we will focus on syntax and semantics. Code generation will be taken up subsequently.</p> <p>When a variable of a class is declared (in the global declaration section), a pointer to the class table entry must be mainted in the global symbol table entry of the variable. Hence, a new class table pointer field may be added to the global symbol table structure. Note that the global symbol table entry for a global variable will have either a class table pointer entry or a type table pointer entry, but not both.</p> <p>The following scope rules must be carefully checked to ensure correct semantic analysis:</p> <ol> <li>Methods of a class variable are accessed as self.method_name(..args..). (If a member is of a     previously class, self.field_name.method_name(..args..)).</li> <li>A member field in a class shall be accessed only within a method of the same class. The access     syntax will be self.field_name. (Note: if field_name is variable of another class (or the same class),     accessing member fields of the member using syntax self.field_name.sub_field.name is not be permitted \u2013 why?)</li> <li>A method of one class is generally not permitted to access methods of other classes.     However, if a class contains a member field of another class, then the methods accessible     through the member field can be invoked as noted in point 1 above.</li> <li>There is exactly one method carrying a name in a class.     Thus, function overloading is not permitted.</li> </ol> <p>These rules are not difficult to check once the class table is properly constructed from the class definitions. All variable and function declarations visible to a method are contained in the class table entry of the relevant class.</p> <p>Task 1</p> <p>Complete the front end - lexical, syntax and semantic analysis for the extended language with classes.</p>"},{"location":"roadmap/stage-07/#part-ii-code-geneeration","title":"Part II: Code geneeration","text":"<p>Code generation is not hard, once the access semantics of self is understood. The basic observation is that the code for any method can be generated immediately as the definition of the method is processed. This is true because a method's access is limited to its member fields and previously declared methods of the class. This information would be already entered into the class table entry for the class.</p> <p>When a method declaration is encountered, a unique label must be generated for the method and the label must be entered into the class table entry of the method. Thus, the call address to any method can be determined from the class table entry of the corresponding class. (In the next stage, we will see that a more sophisticated strategy will be needed to support inheritance).</p> <p>Storage allocation for class variables is equally simple. Just as was done for user defined types, a call to 'new' must allocate a block of 8 words in the heap for storing the member fields of the variable. The start address of this block must be assigned to the variable.</p> <p>Other matters being routine, the non-trivial point pending is the deferencing of the self reference \u2013 in <code>self.field_name</code>.</p> <p>The following paragraphs summarize the key ideas:</p> <ol> <li> <p>How to get the address of self? First observe that a reference to self will occur only within     a member function of a class variable. Second, all variables of the same class share the code of     all the methods of the class. Thus, at run time, a method must be told which is the variable for     which the current call is made. In other words, the address of self can be determined only      at run-time (why? - ensure that you digest this point clearly before proceeding further!)</p> <p>The standard way to resolve this reference is to set the convention that before a call to a  method, the caller must push the address of self (for the particular call) as an argument  into the stack. The convention we suggest is to push the address of self before pushing the  arguments during method invocations. Note that self is an implicit argument, not found either in the declaration or the definition of the method. In the next stage, we will need to  push one more implicit argument for each method invocation. It is instructive to have a quick look at the run-time-stack management documentation for OExpL at this stage</p> </li> <li> <p>The local symbol table of a method must contain an entry for self along with the other     arguments to the function. The binding field of this entry must be the relative address     (with respect to BP in the stack) where the address of self must be pushed by the caller.     For example, if this value is -k, then the compiler expects that the caller would have pushed t     o stack corresponding to <code>[BP-k]</code> the address of the heap block holding the member fields of the variable.</p> </li> </ol> <p>The task of completing code generation phase is now straightforward.</p> <p>Task 2</p> <p>Complete code generation for this stage.</p> <p>Exercise 1</p> <p>What modifications must be done to allow class variables to be passed as arguments to functions?</p> <p>Exercise 2</p> <p>What modifications must be done to allow functions to have locally declared variables of class?</p>"},{"location":"roadmap/stage-07/#test-programs","title":"Test Programs","text":"<p>Check your implementation with the following test cases :</p> <ul> <li>Test Program 1: Binary Search Tree using Classes</li> <li>Test Program 2: Linked list in OExpL</li> <li>Test Program 3: Sum of factorials</li> </ul>"},{"location":"roadmap/stage-08/","title":"Stage 8: Inheritance and Sub-type Polymorphism","text":"<p>Time estimate</p> <p>1 week, 5-10 hours/week</p> <p>Prerequisites</p> <ol> <li>A rigorous reading of the OExpL specification</li> </ol> <p>Learning Objectives</p> <p>You will extend the language of Stage 7 by adding support for single inheritance and subtype polymorphism to make OExpL an object oriented language.</p> <p>In this stage, we will extend ExpL to provide support for  single inheritance and  subtype polymorphism.  These features qualifies OExpL to be called an object oriented language.</p> <p>Addition of support for inheritance and polymorphism involves some intellectual complexity.  Fortunately, once the underlying conceptual issues are understood, the implementation is not difficult.</p>"},{"location":"roadmap/stage-08/#part-i-syntax-and-semantics","title":"Part I: Syntax and Semantics","text":"<p>The definition of a class could now be by extention of a previously defined class.</p> <pre><code>Cname : ID {Cptr = Cinstall($1-&gt;Name,NULL);}\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0| ID Extends ID {Cptr = Cinstall($1-&gt;Name,$3-&gt;Name);}\n</code></pre> <p>An additional field called the parent class pointer must be added to each class table entry.  If the class is defined by extention of another class, the parent class pointer entry must point to the class table entry of the parent class. If the class is not an extention of any other class, this entry must be NULL. (See class table structure). An outline of the grammar is given here.</p> <p>An extended class inherits all the member fields and methods of the parent class. The descendent class is permitted to do additional definitions as specified below.</p> <ol> <li> <p>The only member field declarations in the descendent class shall be for the new member fields     that are not present in the parent. (The descendent cannot re-declare or remove any of the parent's     member fields.) Additionally, in our current implementation plan, the number of member fields</p> <ul> <li>including those inherited from the parent - must not exceed 8 (because our memory allocation policy allocates only 8 words for storing a class object). From an implementation perspective, whenever the definition of a class by extension of another class is encountered, the compiler must copy all the member field information of the parent to the descendent class. The member fields may be listed in the same order as they appear in the parent. Additional entries must be created for new members specific to the descendent class.</li> </ul> </li> <li> <p>The descendent class may define new methods or override     one or more of the parent's methods. OExpL allows a class to contain only one definition for a function.     Once a method is over-ridden, the method of the parent class will no longer be visible inside the descendent class.     Moreover, the signature of the overridden method must be identical with the signature of the method in     the parent class (in both the number and the types of arguments).     In other words, function overloading     is not permitted. (Exercise 1 at the end asks you to relax this condition).</p> </li> </ol> <p>From an implementation perspective, the compiler may initially copy the signatures of all methods of the parent to the class table entry of the descendent. New entries will have to be created for methods that defined in the descendent, but not present in the parent. Finally, the present implementation restricts the number of methods in a class ( including inherited methods ) to 8.</p> <p>What about the labels of the methods of the descendent class? If a method is over-ridden or defined new in a class, the compiler must assign a new label for the method and store this label in the Flabel field of the method in the class table entry. Otherwise, the class inherits the parent's method and the label of the method in the parent class ( specified by the Flabel field of the parent class ) must be copied into the Flabel field of the method in the descendent class ( See Memberfunclist in the class table ).</p> <p>Once the class table entries are created as described above, syntax and semantic analysis phases of compilation can be completed easily.</p> <p>An assignment of the form a = b; between class variables is valid if either a and b are variables of the same class or b is a variable of a descendent class of the class a. Similarly <code>a=new(class_name);</code> is valid if the class identified by <code>class_name</code> is a descendent class of the class to which a belongs to. Thus, a variable of a certain class can hold a reference to any object of the same or descendent classes. Since the class table contains adequate information to perform this check, syntax and sematic analysis can be completed now.</p> <p>Task 1: Complete the front end - lexical, syntax and Semantic analysis.</p>"},{"location":"roadmap/stage-08/#part-ii-code-generation","title":"Part II: Code Generation","text":"<p>The key differences between the language of Stage 7 and the present stage are the following:*</p> <p>a. A variable of a parent class may hold a reference to an object of any descendent class. b. The class to which the referred object belongs to at run time cannot be determined at compile time (why?) c. When a method is invoked using the variable of the parent class, if the method is over-ridden by the child class, then the method of the child class must be invoked.</p> <p>Assume that A, B, C are classes such that B extends A and C extends B. Let x be a variable of class A. Consider the program segment:</p> <pre><code>...\nRead(n);\nif (n&gt;0) then\n\u00a0\u00a0x = new(B);\nelse\n\u00a0\u00a0x = new(C);\nendif\n\u00a0\u00a0retval = x.fun();\n...\n</code></pre> <p>Let <code>fun()</code> be a function defined in class A. Let us assume that the label for the function in the class table is L1. Suppose that B does not over-ride fun(), but C over-rides fun().  Let the label for the over-ridden function be L2.</p> <p>Important Note : Unless fun() is defined in class A, the call x.fun() should result in a  compilation error even if B and C contains the declaration for fun(). This is because if a  variable of a parent class holds the reference to an object of a descendent class, only methods  defined in the parent class are allowed to be invoked using the variable of the parent class.</p> <p>The call x.fun(); must translate to CALL L1 if (n&gt;0) whereas x.fun() must translate  to CALL L2 otherwise. The value of n is known only at run-time and the compiler can't hope to guess it. What will the compiler do now?!</p> <p>It turns out that there is a remarkably simple and elegant way to handle the issue by maintaining  what are known as function tables (called virtual function tables in OOP jargon) at run time.</p> <p>The key to the solution to the problem is that the variable x must carry the information about which class is it referring to at run time, and this information must be used to dereference the function call at run time.</p> <p>The implementation details are outlined below: 1. For each class, we will maintain a table of size 8 in the memory, listing labels of the     methods of the class. (Recall that we permit a class to have at most 8 methods). The labels     may be listed in the order in which the methods are defined in the class. This table is called     the virtual function table for the class. Since all the class definitions are known at compile     time, the compiler can generate initial code to set up all the class tables in the stack region of     the program. (Typically, at the beginning of the stack, allocating space before global variables.)</p> <ol> <li> <p>The label for a method in the virtual function table will be set to the method's label in the     corresponding class table entry. Consequently, the label of a method in a descendent class will     be the label of the method in the parent class if the method is not over-ridden. Referring to the     example above, the label for the method fun() in the virtual function tables of classes A and B     will be L1, whereas, the label will be L2 in the virtual function table of class C.</p> </li> <li> <p>The position of the label of a method in the virtual function tables of the parent class and all     the descendent classes in a class hierarchy must be the same. Referring to the above example,     if the label of the method fun() is listed third in the virtual function table of A, then it must be     listed third in the virtual function tables of classes B and C. Thus the index of a method's     entry in the virtual function table will be the same for every class in a class hierarchy.     The advantage of this convention is that while translating, **the position of a method's label     relative to the base address of the virtual function table is completely determined at compile time.     ** Note that since the language does not permit function overloading, the entry for a     given method name in a virtual function table will be unique.</p> </li> <li> <p>In view of the above, to translate x.fun(), all that needs to be determined at run time is     the base address of the correct virtual function table. To keep track of this information, the     compiler must allocate two memory locations for each class variable - One for the usual pointer to     the memory block allocated in the heap for storing the object's member fields .     The second, to store a pointer to the virtual function table of the class to which     the current object stored in the variable belongs to.</p> </li> </ol> <p>Conceptually, each class variable holds a pair <code>[MemberFieldPointer, VirtualFunctionTablePointer]</code>. The statement <code>x=new(B);</code> in the example above should do the following:</p> <ul> <li> <p>Allocate a block of 8 words in the heap and store the start address in the MemberFieldPointer field of x.</p> </li> <li> <p>set the VirtualFunctionTablePointer field of x to the base address of the virtual function table of class B.</p> </li> </ul> <p>An assignment of the form y=x, if valid semantically, will result in both the pointers of x being copied into the corresponding pointers of y.</p> <p>Note that once the base of the correct virtual function table is known, invoking the right function simply involves adding the offset of the function to the base and making a call to the address (label) stored in the virtual function table entry.</p> <p>Note that the labels will be automatically translated to actual addresses during the label translation phase.</p> <p>To implement virtual function tables on the eXpOS ABI, the suggested method is to allocate space (8 words each) for storing the virtual function tables of each class in the stack before allocating space for global variables.</p> <p>Read the OExpL run time data structures documentation before proceeding further.</p> <p>Task 2: Complete the OExpL compiler.</p>"},{"location":"roadmap/stage-08/#test-programs","title":"Test Programs","text":"<p>Check your implementation with the following test cases :</p> <ul> <li>Test Program 1: Testing the runtime binding of the variables of a class</li> <li>Test Program 2: Testing the correct set up of the virtual function table</li> <li>Test Program 3: Testing the implementation of inheritance and subtype polymorphism</li> <li>Test Program 4: Testing the implementation of inheritance and subtype polymorphism</li> </ul> <p>Exercise 1</p> <p>This exercise asks you to add a limited form of function overloading support to the language. Here, when a descendent class overrides a method of a parent class, it can re-define the function with a signature that is possibly different from that of the parent class. In this case, both the definitions will be active in the child class; with the compiler translating the call to the correct address (label) looking at the arguments. Make necessary modifications to the language syntax to support this form of function overloading.</p> <p>Note</p> <p>Overloading and subtype polymorphism are two polymorphism types typiclly supported by most object oriented langauges. A third important type of polymorphism called parametric polymorphism (templates in C++) has not been touched upon in this project.</p>"},{"location":"run_data_structures/heap/","title":"Heap Allocation","text":""},{"location":"run_data_structures/heap/#introduction","title":"Introduction","text":"<p>ExpL specification stipulates that variables of user defined types are allocated dynamically using the alloc() function. The alloc() function has the following syntax:</p> <pre><code>user_defined_type_var = alloc();\n</code></pre> <p>The ExpL compiler must internally determine the allocation size (amount of continuous memory words) required for storing a variable of user_defined_type_var and must translate the requirement to a call to the Alloc() function of the ExpL library.</p> <p>The library function Alloc() expects three arguments - function code=2 and the allocation size. Hence, the code generated by an ExpL compiler to invoke the library for an allocation size = 8 may typically look like the following:</p> <p></p> <p><pre><code>PUSH \"Alloc\"    //Function Code for Alloc\nMOV R0, 8       //Mov the allocation_size=8 to a register\nPUSH R0         //Push Argument Size\nPUSH R0         //Argument 2 Empty\nPUSH R0         //Argument 3 Empty\nPUSH R0         //Empty space for RETURN VALUE\nCALL 0          //Pass the control to virtual address 0.\n</code></pre> Since the memory model stipulates that the library is loaded to memory address zero of the address space, the library is invoked through the machine instruction CALL 0.</p> <p>Similarly, memory allocated to a user defined variable may be freed by a call to the library function Free(). The library function Initialize() initializes the memory allocator of the library.</p> <p>The ExpL library code, must be designed to be loaded to memory location 0 of the address space, and must be capable of processing memory allocation requests.</p> <p>This document explains how the library functions must handle memory allocation and de-allocation requests.</p> <p>The library allocates memory from the the heap. The memory model stipulates that the heap is located between addresses 1024 and 2047 of the address space. Hence, when a memory request comes, the Alloc() function of the library must allocate sufficient memory from this memory area and return the starting address of the allocated space.</p> <p>The library has three functions relating to dynamic memory management. Initialise(), Allocate() and Free(). The Initialise() function sets up the heap data structures initially. Each memory request is processed by Alloc() and Free() de-allocates a previously allocated memory block.</p> <p>In the following we discuss two sets of algorithms for implementing these functions. First we will describe a simple fixed size allocator assuming that the Alloc() function always allocates a fixed sized memory block irrespective of the allocation size of the request. Such allocation, however is possible only if the maximum size of a request is known in advance. Later we describe the buddy system allocator which can handle requests of arbitrary size subject to a maximum limit.</p>"},{"location":"run_data_structures/heap/#fixed-memory-allocation","title":"Fixed Memory Allocation","text":"<p>In this algorithm, the chunk size allocated is fixed. Lets call the fixed size as HB_SIZE, say 8. The heap is considered here as a list of blocks of HB_SIZE.</p> <p>Note</p> <p>Since the member fields of user-defined-type variables are allocated space in the heap, when fixed block size allocation is done, a user defined type variable must not be permitted to have more than <code>HB_SIZE</code> member fields. The compiler must flag error if a type definition with more than <code>HB_SIZE</code> member fields is encountered.</p> <p>The first block in the list is reserved. Initially, the first index of reserved block stores the index of first free block. The first index of every free block stores the index of next available free block. The last block stores -1 in the first index. This is how it looks initially(after the call to initialize() function).</p> <p></p> <p>Following is the allocation algorithm.</p> <ol> <li>First index of reserved block is checked, let the value be v.</li> <li>If v is -1,     \u00a0\u00a0\u00a0return -1 indicating no free blocks are available.</li> <li>Else,     \u00a0\u00a0\u00a0allocate the free block at v,     \u00a0\u00a0\u00a0copy the next free block index stored at v to the reserved block. Return v.</li> </ol> <p>Following is the deallocation algorithm.</p> <ol> <li>The argument passed : starting address of the block(say s) to be deallocated</li> <li>The block s is cleared.</li> <li>The value in the first index of reserved block is copied to first index of block s.</li> <li>The first index of reserved block is set with starting address of block s.</li> </ol>"},{"location":"run_data_structures/heap/#illustration","title":"Illustration","text":"<p>This section shows how the heap looks after each step of allocation or free. This is for the better understanding of the algorithms.</p> <ul> <li> <p>x = alloc();</p> <p></p> </li> <li> <p>y = alloc();</p> <p></p> </li> <li> <p>z = alloc();</p> <p></p> </li> <li> <p>dealloc(x);</p> <p></p> </li> <li> <p>dealloc(z);</p> <p></p> </li> <li> <p>z = alloc();</p> <p></p> </li> </ul>"},{"location":"run_data_structures/heap/#buddy-memory-allocation-optional","title":"Buddy Memory Allocation (optional)","text":"<p>In this technique, memory is divided into partitions to try to satisfy a memory request as suitably as possible. This technique makes use of splitting memory into halves to give a best-fit.</p> <p>Every memory block in this technique has an order, a number ranging from 0 to a specified upper limit. The size of block of order n is 2<sup>n</sup>. So the blocks are exacly twice the size of blocks of one order lower. Power-of-two block sizes makes address computation simple, because all buddies are aligned on memory address boundaries that are powers of two. When a larger block is split, it is divided into two smaller blocks, and each smaller block becomes a unique buddy to the other. A split block can only be merged with its unique buddy block, which then reforms the larger block they were split from.</p> <p>Starting off, the size of the smallest possible block is determined, i.e. the smallest memory block that can be allocated. The smallest block size is then taken as the size of an order-0 block, so that all higher orders are expressed as power-of-two multiples of this size. In our implementation, we consider the smallest memory block size to be 8. So, the memory block sizes will be 8, 16, 32, 64, and so on. In our implementation, we take the heap of size 1024.</p> <p>In our implementation, we have a heap of size 1024. The smallest block size possible in the heap is 8 (order 0). The highest block size of 2<sup>n</sup> that is free is 1024. We maintain a free list for all possible block sizes. So we have freelists for sizes 8, 16, 32, 64, 128, 256, 512 and 1024, i.e, we maintain eight freelists.</p> <ul> <li>We have only one block of size 1024 and so the size of freelist for 1024 is 1(2<sup>0</sup>).</li> <li>In the 1024 sized heap, we have two blocks of size 512, starting at 1024 and 1536 respectively (heap starts at 1024). Note that, both blocks cannot be free at the same time. If both blocks are free, they will be merged to a free block of size 1024(whose information will be maintained in the freelist for blocks of 1024 size). So at a time, maximum number of blocks that are free of size 512 is 1 ( 2<sup>0</sup>).</li> <li>Similarly in case of blocks of size 256, 1024 sized heap has 4 blocks of size 256, starting at 1024, 1280, 1536 and 1792 (say a,b,c and d in their respective order).     a and b are buddies of each other, of which both cannot be free at a time due to merging, so only one of them can be free.     Similarly in case of c and d, only one of them can be free. 1 + 1 , 2 ( 2<sup>1</sup>) is the maximum size of free list for blocks of 256.</li> <li>Similarly, there are 8 blocks of 128 in 1024 (a,b,c,d,e,f,g and h). (a,b)(c,d)(e,f)(g,h) are buddy pairs and only one of each pair can be free.     So the maximum size of freelist for blocks of 128 is 4 ( 2<sup>2</sup>).</li> <li>Similarly, the maximum size of freelist for blocks of sizes 64,32,16 and 8 are 8 ( 2<sup>3</sup>),16( 2<sup>4</sup>),32( 2<sup>5</sup>) and 64( 2<sup>6</sup>) respectively.</li> </ul> <p>So, the size of the complete freelist is 2<sup>0</sup> + 2<sup>0</sup> + 2<sup>1</sup> + 2<sup>2</sup> + 2<sup>3</sup> + 2<sup>4</sup> + 2<sup>5</sup> +2<sup>6</sup> = 128.</p> <p>We will maintain the freelist inside the heap, So initially we won't have the complete heap of 1024 free. We need not require a freelist for size 1024. We will store the complete freelist in a 128 sized block. Therefore, initially we have the first 128 block(0-127) of the heap reserved for freelist maintainence. Then we have a 128 sized free block(128-255), then a 256 block(256-511) and then a free block of 512 size(512-1023). Following is the diagrammatic representation of the heap initial status.</p> <p></p> <p>The free-list in the heap has to be initialised as above. Also, the first index of each allocated block through alloc function will store the size of allocated block. This is to figure out the size that has been allocated when the dealloc function is called for a variable, which provides only the starting address of the block that has been allocated.</p> <p>Following is the allocation algorithm : (argument : Request for a block of size 'A')</p> <ul> <li>Look for a memory slot of suitable size(i.e, the minimal 2<sup>k</sup> block that is larger or equal to that of the requested memory A + 1, a plus one as first index is used to store the size of block allocated), lets call the ceiled size as 'B'.<ol> <li>If found, the starting index of the allocated block is returned to the program after removing it from the freelist.</li> <li>If not, it tries to make a suitable memory slot by following the below steps<ol> <li>Split a the next larger suitable free memory slot into half.(Remove the next larger suitable free memory slot from it free list and add both the halves to the corresponding freelist).(Note : of there is no larger free memory slot - return -1 indicating that no free space is available).</li> <li>If the required size 'B' is reached, one of the halves is allocated to the program.</li> <li>Else go to the step a and repeat it until the memory slot of required size 'B' is found.</li> </ol> </li> </ol> </li> </ul> <p>Following is the deallocation algorithm (argument : the starting address of the allocated block)</p> <ol> <li>Get the size, say 's' of the block from the first index of the block. Free the complete block.</li> <li>Check if the buddy of the block is free by checking the whether the buddy's starting address is present in the free list for blocks of size 's' .</li> <li>If the buddy is not free, add the current freed block to its free list.</li> <li>If the buddy is free, remove the buddy from the freelist and combine the two, and go back to step 2 to check for the buddy of merged block. Repeat this process until the upper limit is reached or buddy is not free.</li> </ol>"},{"location":"run_data_structures/heap/#illustration_1","title":"Illustration","text":"<p>For a better understanding purpose, we will have a simple illustration of how heap memory looks like through a set of some allocations and deallocations.</p> <p>For illustration, we will have 64-sized heap and smallest block size as 8. So we free lists for sizes 8,16 and 32 of lengths 4 ,2 and 1. So we will use a 8-size block to store the free-list.</p> <ol> <li> <p>The heap looks initially as follows.</p> <p></p> </li> <li> <p>Request for memory of size 5. Lets call this request as A. The nearest 2^k value for 5 is 8. We search for a 8 sized free block. We have one such! Allocate it!</p> <p></p> </li> <li> <p>Next we will have a reuqest B of size 14.</p> <p></p> </li> <li> <p>Now we have a request C of size 7.</p> <p></p> <p></p> <p></p> </li> <li> <p>Now, C releases its memory.</p> <p></p> <p></p> <p></p> </li> </ol>"},{"location":"run_data_structures/register/","title":"Temporary Allocation","text":"<p>Registers are allocated and released for the temporary storage of intermediate computation through two simple functions.</p> <ul> <li><code>int get_register()</code>: Allocates a free register from the register pool (R0 - R19) and returns the index of the register, returns -1 if no free register is available.</li> <li><code>int free_register()</code>: Frees the last register that was allocated,returns 0 if success, returns -1 if the function is called with none of the registers being allocated.</li> </ul>"},{"location":"run_data_structures/run-time-stack/","title":"Run Time Stack Allocation","text":""},{"location":"run_data_structures/run-time-stack/#introduction","title":"Introduction","text":"<p>During run-time, when an ExpL function is invoked, space has to be allocated for storing</p> <ul> <li>the arguments to the function,</li> <li>return value of the function,</li> <li>local variables declared in the function.</li> </ul> <p>For this, an activation record is created in the stack for each function call (and the stack grows). The activation record is also used to save the state (registers in use) of the invoking function and some control information (like the return address of the calling program).</p> <p>Each activation record has a base, and the base pointer (BP) is a machine register that points to the base of the activation record of the currently executing function. When one function invokes another, the base pointer value of the caller is pushed on to the stack and BP is set to point to the new activation record base. Upon return, the activation record is popped off the stack and old value of base pointer is restored. The stack pointer (SP) must always point to the top of the stack.</p> <p>The calling convension fixes in what order arguments to a function must be pushed by the caller to the called function, the place in the activation record where the return value is expected to be written by the callee etc. The structure of the activation record explained below will clarify the calling convension.</p> <p>The stack is assumed to grow downwards.</p> <p></p> <p>When a function is invoked, a part of the activation record is set up by the caller and the rest is set up after invocation of the function. Similarly, when a function returns, the callee and the caller are responsible for removing the parts they have set up.</p> <p>The following sequence of actions occur when a function A calls another function B.</p> <p>1. A pushes its machine state (registers in use) into the stack so that the registers are free for use in B.</p> <p>2. A pushes the arguments to B in the order they appear in the declaration.</p> <p>3. A pushes one empty space in the stack for B to place its return value.</p> <p>4. A invokes B. (This results in generation of a CALL instruction which results in pushing the instruction pointer into the stack and transfer of control to B).</p> <p>Inside B, the following space allocations take place:</p> <p>5.  B saves the BP value of A to the stack and sets BP to the top of the stack.</p> <p>6.  B allocates space for local variables (in the order in which they appear in the delcaration).</p> <p>This completes the activation record for B. If B later calls another function C, then it starts saving its registers, pushes arguments to C and so on.</p> <p>When B completes execution the following sequence of actions take place:</p> <p>1.  B computes the return value and stores it in the space allocated for it in the stack.</p> <p>2.  B pops out the local variables.</p> <p>3.  The old BP value is popped off and saved into BP.</p> <p>4.  B returns (this results in generation of a RET instruction which results in setting the instruction pointer to the value saved in the stack).</p> <p>On re-entry, A does the following:</p> <p>5.  Retrieve the return value from stack and save it to a new register. This is the result of the function call.</p> <p>6.  Pop off the arguments.</p> <p>7.  Restore the saved register context.</p>"},{"location":"run_data_structures/run-time-stack/#illustration","title":"Illustration","text":"<p>Consider the following example: <pre><code>decl\n    int result,factorial(int n);\nenddecl\nint factorial(int n){\n    decl\n        int f;\n    enddecl\n    begin\n        if( n==1 || n==0 ) then\n            f = 1;\n        else\n            f = n * factorial(n-1);\n        endif;\n        return f;\n    end\n}\nint main(){\n    decl\n        int a;\n    enddecl\n    begin\n        read(a);\n        result = factorial(a);\n        write(result);\n        return 1;\n    end\n}\n</code></pre></p> <ol> <li> <p>The global variables are allocated statically in the initial portion of the stack. Note that stack begins at <code>4096</code> according to the ABI specification.</p> <p></p> </li> <li> <p>Assuming that user inputs 3 resulting in <code>a=3</code>, the main functions sets up stack locations for its local variables and calls the function <code>factorial(3)</code> after setting up a part of the callee's activation record.</p> <p></p> </li> <li> <p><code>factorial(3)</code> saves the old Base pointer and sets up locations for its local variables.</p> <p></p> </li> <li> <p><code>factorial(3)</code> calls <code>factorial(2)</code> and the activation record of <code>factorial(2)</code> is setup similar to the above steps.</p> <p>The register <code>R0</code> is assumed to be used for temporary storage of the value of n in the expression <code>n * factorial(n-1)</code> i.e, 3.</p> <p></p> </li> <li> <p>Activation record for <code>factorial(1)</code> (called by <code>factorial(2)</code>) is setup similarly.</p> <p></p> </li> <li> <p><code>factorial(1)</code> calculates the result and returns it by setting the value at return value location and pops off it local variables and sets back the base pointer.</p> <p></p> </li> <li> <p>Similarly, <code>factorial(2)</code> calculates the steps and pops off its activation record till the result value after setting back the old base pointer.</p> <p></p> </li> <li> <p>Similarly, <code>factorial(3)</code> also calculates the result and returns it to the main function.</p> <p></p> </li> <li> <p>Main function calculates and sets the <code>result</code> variable.</p> <p></p> </li> </ol>"},{"location":"run_data_structures/static-allocation/","title":"Static Allocation","text":""},{"location":"run_data_structures/static-allocation/#introduction","title":"Introduction","text":"<p>As noted previously, global variables are allocated statically. In our interpreter, the initial portion of the stack will be used for static allocation. The rest of the stack memory region will be used for run time allocation. The amount of static storage required is known from the variable declarations.</p>"},{"location":"run_data_structures/static-allocation/#illustration","title":"Illustration","text":"<p>TODO</p>"},{"location":"testprograms/","title":"Test Programs","text":"<p>TEST PROGRAMS</p>"},{"location":"testprograms/#test-programs","title":"TEST PROGRAMS","text":""},{"location":"testprograms/#test-program-1-bubblesort-iterative","title":"Test Program 1 : Bubblesort (iterative)","text":"<p>This test program reads elements into an array and sorts them using the classic bubblesort algorithm. (iterative version)</p> <p>Input : 1. Number of elements to be sorted from standard input. 2. Elements to be sorted</p> <p>Output : A sorted array of elements.</p> <p>This program test the iteration, conditional and arrays.</p> <p>The code for the test progam can be found here</p>"},{"location":"testprograms/#test-program-2-extended-euclid-algorithm-iterative-version-and-with-functions","title":"Test Program 2 : Extended Euclid algorithm (iterative version and with functions)","text":"<p>This test program calculates the GCD (Greatest Common Divisor) of two numbers along with Bezout co-efficients. (iterative version)</p> <p>Input : Two numbers</p> <p>Output : GCD of the given two numbers and Benoud co-efficients.</p> <p>This program test the iteration, parameter passing, passing of user-defined datatype as return value of function.</p> <p>The code for the test progam can be found here</p>"},{"location":"testprograms/#test-program-3-bubblesort-recursive","title":"Test Program 3 : Bubblesort (recursive)","text":"<p>This test program reads elements into an array and sorts them using the classic bubblesort algorithm. (recursive version)</p> <p>Input : 1. Number of elements to be sorted from standard input. 2. Elements to be sorted</p> <p>Output : A sorted array of elements.</p> <p>This program test the recursion, conditional and arrays.</p> <p>The code for the test progam can be found here</p>"},{"location":"testprograms/#test-program-4-extended-euclid-algorithm-recursive","title":"Test Program 4 : Extended Euclid algorithm (recursive)","text":"<p>This test program calculates the GCD (Greatest Common Divisor) of two numbers along with Bezout co-efficients. (recursive version)</p> <p>Input : Two numbers</p> <p>Output : GCD of the given two numbers and Benoud co-efficients.</p> <p>This program test the recursion, parameter passing, passing of user-defined datatype as return value of function.</p> <p>The code for the test progam can be found here</p>"},{"location":"testprograms/#test-program-5-factorial-recursive","title":"Test Program 5 : Factorial (recursive)","text":"<p>This test program calculates and prints out the factorial of the first n numbers.</p> <p>Input : Value of n read from standard input.</p> <p>Output : Value of n!.</p> <p>This program test the working of recursive functions.</p> <p>The code for the test progam can be found here</p>"},{"location":"testprograms/#test-program-6-quicksort-recursive","title":"Test Program 6 : Quicksort (recursive)","text":"<p>This test program reads elements into an array and sorts them using the classic quicksort algorithm. (recursive version)</p> <p>Input : 1. Number of elements to be sorted from standard input. 2. Elements to be sorted</p> <p>Output : A sorted array of elements.</p> <p>This program test the recursion, conditional and arrays.</p> <p>The code for the test progam can be found here</p>"},{"location":"testprograms/#test-program-7-constant-function","title":"Test Program 7 : Constant Function","text":"<p>This test program calculates the value of a function f(x) given by : f(x) = \u00a0\u00a091 \u00a0\u00a0\u00a0\u00a0\u00a0if x&gt;=91; \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0f(f(x+11)) \u00a0\u00a0\u00a0\u00a0\u00a0 if x&lt;91 So, the value of the function is always 91 for any given input number.</p> <p>Input : A number</p> <p>Output : 91.</p> <p>This program test the recursion, parameter passing, calling a function inside the call of another function.</p> <p>The code for the test progam can be found here</p>"},{"location":"testprograms/#test-program-8-linked-list","title":"Test Program 8 : Linked List","text":"<p>This test program reads elements into a linked list and prints them.</p> <p>Input : Value of length of list and list of values from standard input.</p> <p>Output : The list of values stored in linked list.</p> <p>This program test the working of dynamic memory allocation functions like Initialize(), Alloc() and Free().</p> <p>The code for the test progam can be found here</p>"},{"location":"testprograms/#test-program-9-binary-search-tree","title":"Test Program 9 : Binary Search Tree","text":"<p>This test program inserts elements into a binary search tree and prints the elements in inorder, preorder and postorder traversal. The program stops taking input elements (that are to be inserted in Binary Search Tree) when the user enters 0.</p> <p>Input : The elements that are to be inserted into a Binary Search Tree and a 0 at last (indicating the end of input).</p> <p>Output : The inorder, preorder and postorder traversal of the tree.</p> <p>This program test the iteration, recursion, conditional, arrays and passing of user-defined datatype as return value of function.</p> <p>The code for the test progam can be found here</p>"},{"location":"testprograms/#test-program-10-fibonacci-series","title":"Test Program 10 :Fibonacci Series","text":"<p>This program prints the nth fibonacci number.</p> <p>Input : An integer n.</p> <p>Output : Printing the nth fibonacci number.</p> <p>This program test the recursion, conditional.</p> <p>The code for the test progam can be found here</p>"},{"location":"testprograms/#test-program-11-extended-euclid-algorithm-using-linkedlist","title":"Test Program 11 :Extended Euclid Algorithm using linkedlist","text":"<p>This program finds gcd of two numbers given by using Extended Euclid Algorithm and stores result in a linkedlist.</p> <p>Input : Two numbers a and b.</p> <p>Output : A list of numbers in every iteration of the algorithm a,b,d,s,t such that as+bt=d in each iteration are stored in a linkedlist and are printed finally by iterating the linked list.</p> <p>This program test the iteration, recursion, conditional, passing of user-defined datatype as return value of function.</p> <p>The code for the test progam can be found here</p>"},{"location":"testprograms/#test-program-12-extended-euclid-algorithm-iterative-version-without-functions","title":"Test Program 12 :Extended Euclid Algorithm (Iterative version without functions)","text":"<p>This test program calculates the GCD (Greatest Common Divisor) of two numbers along with Bezout co-efficients. (iterative version)</p> <p>Input : Two numbers</p> <p>Output : GCD of the given two numbers and Benoud co-efficients.</p> <p>This program tests the iteration.</p> <p>The code for the test progam can be found here</p>"},{"location":"testprograms/test-program-01/","title":"Test Program 1: Bubblesort(iterative)","text":"<p>This test program reads elements into an array and sorts them using the classic bubblesort algorithm. (iterative version)</p>"},{"location":"testprograms/test-program-01/#input","title":"Input","text":"<ol> <li>Number of elements to be sorted from standard input.</li> <li>Elements to be sorted</li> </ol>"},{"location":"testprograms/test-program-01/#output","title":"Output","text":"<p>A sorted array of elements.</p> <p>This program test the iteration, conditional and arrays.</p> <pre><code>decl\n   int n,arr[50],i,j,dup;\nenddecl\n\nint main()\n{\n  begin\n  read(n);\n\n  i=0;\n  while(i&lt;n) do\n    read(arr[i]);\n    i = i+1;\n  endwhile;\n\n  i=0;\n  while(i&lt;n) do\n    j=i;\n    while(j&lt;n) do\n      if(arr[i]&gt;arr[j]) then\n        dup = arr[i];\n        arr[i] = arr[j];\n        arr[j] = dup;\n      endif;\n      j = j + 1;\n    endwhile;\n    i = i+1;\n  endwhile;\n\n  i=0;\n  while(i&lt;n) do\n    write(arr[i]);\n    i = i+1;\n  endwhile;\n\n  return 0;\n  end\n}\n</code></pre>"},{"location":"testprograms/test-program-02/","title":"Test Program 2 : Extended Euclid algorithm (iterative version and with functions)\u00b6","text":"<p>This test program calculates the GCD (Greatest Common Divisor) of two numbers along with Bezout co-efficients. (iterative version)</p>"},{"location":"testprograms/test-program-02/#input","title":"Input","text":"<p>Two numbers</p>"},{"location":"testprograms/test-program-02/#output","title":"Output","text":"<p>GCD of the given two numbers and Benoud co-efficients.</p> <p>This program test the iteration, parameter passing, passing of user-defined datatype as return value of function.</p> <pre><code>decl\n int ExtendedEuclid(int a,int b);\nenddecl\n\nint ExtendedEuclid(int a,int b)\n{\n decl\n  int r0,r1,s0,s1,t0,t1,qi,ri,si,ti;\n enddecl\n\n begin\n  r0 = a;\n  r1 = b;\n  s0 = 1;\n  s1 = 0;\n  t0 = 0;\n  t1 = 1;\n\n  while(r1 != 0) do\n   qi = r0/r1;\n   ri = r0 - (qi*r1);\n   si = s0 - (qi*s1);\n   ti = t0 - (qi*t1);\n   r0 = r1;\n   r1 = ri;\n   s0 = s1;\n   s1 = si;\n   t0 = t1;\n   t1 = ti;\n  endwhile;\n\n  write(r0);\n  write(s0);\n  write(t0);\n\n  return 0;\n end\n}\n\nint main()\n{\n decl\n  int a,b,c;\n enddecl\n\n begin\n  read(a);\n  read(b);\n  c = ExtendedEuclid(a,b);\n  return 0;\n end \n}\n</code></pre>"},{"location":"testprograms/test-program-03/","title":"Test Program 3 : Bubblesort (recursive)","text":"<p>This test program reads elements into an array and sorts them using the classic bubblesort algorithm. (recursive version)</p>"},{"location":"testprograms/test-program-03/#input","title":"Input","text":"<ol> <li>Number of elements to be sorted from standard input.</li> <li>Elements to be sorted</li> </ol>"},{"location":"testprograms/test-program-03/#output","title":"Output","text":"<p>A sorted array of elements.</p> <p>This program test the recursion, conditional and arrays.</p> <pre><code>decl\n  int n,arr[10],i,j,dup, BubbleSort(int first, int last);\nenddecl\n\nint BubbleSort(int first, int last)\n{\n  decl\n    int temp;\n  enddecl\n\n  begin\n    if((first &lt; last) AND (last &gt; 0)) then\n\n      if(arr[first] &gt; arr[first+1]) then\n        temp = arr[first];\n        arr[first] = arr[first+1];\n        arr[first+1] = temp;\n      endif;\n\n      dup = BubbleSort(first+1, last);\n      dup = BubbleSort(first, last-1);\n    endif;\n\n    return 0;\n  end\n}\n\nint main()\n{\n  decl\n    int r;\n  enddecl\n\n  begin\n    read(n);\n\n    i=0;\n    while(i&lt;n) do\n      read(arr[i]);\n      i = i+1;\n    endwhile;\n\n    r = BubbleSort(0,n-1);\n\n    i=0;\n    while(i&lt;n) do\n      write(arr[i]);\n      i = i+1;\n    endwhile;\n\n    return 0;\n  end\n}\n</code></pre>"},{"location":"testprograms/test-program-04/","title":"Extended Euclid(User defined types)","text":"<pre><code>type\n  node\n  {\n    int d;\n    int s;\n    int t;\n  }\nendtype\n\ndecl\n  node y,z,gcd(int a,int b);\nenddecl\n\nnode gcd(int a,int b)\n{\n  decl\n    int q,r,temp;\n  enddecl\n\n  begin\n    if(b==0) then\n      y.d = a;\n      y.s = 1;\n      y.t = 0;\n    else\n      q = a/b;\n      r = a%b;\n      z = gcd(b,r);\n      temp = z.s;\n      y.s = z.t;\n      y.t = temp - (q*z.t);\n    endif;\n\n  return y;\n  end\n}\n\nint main()\n{\n  decl\n    node res;\n    int a,b,c;\n  enddecl\n\n  begin\n    c = initialize();\n    y = alloc();\n    read(a);\n    read(b);\n    res = gcd(a,b);\n    write(res.d);\n    write(res.s);\n    write(res.t);\n\n  return 0;\n  end\n}\n</code></pre>"},{"location":"testprograms/test-program-05/","title":"Factorial (recursive)","text":"<pre><code>decl\n  int fact(int n);\nenddecl\n\nint fact(int n)\n{\n  decl\n    int f;\n  enddecl\n\n  begin\n    if(n&lt;=1) then\n      f=1;\n    else\n      f=n*fact(n-1);\n    endif;\n\n    return f;\n  end\n}\n\nint main()\n{\n  decl\n    int a,res;\n  enddecl\n\n  begin\n    read(a);\n    res = fact(a);\n    write(res);\n\n    return 0;\n  end\n}\n</code></pre>"},{"location":"testprograms/test-program-06/","title":"Quicksort(recursive)","text":"<pre><code>decl\n  int a,b,n,arr[10];\n  int swap(int index, int newindex);\n  int readarr(int temp);\n  int writearr(int temp);\n  int partition (int low, int high);\n  int quicksort(int low,int high);\nenddecl\n\nint swap(int index ,int newindex)\n{\n  decl\n    int s;\n  enddecl\n\n  begin\n    s = arr[index];\n    arr[index] = arr[newindex];\n    arr[newindex] = s;\n\n    return s;\n  end\n}\n\nint readarr(int temp)\n{\n  decl\n    int count;\n  enddecl\n\n  begin\n    count=0;\n\n    while(count &lt; temp) do\n      read(arr[count]);\n      count=count+1;\n    endwhile;\n\n    return count;\n  end\n}\n\nint writearr(int temp)\n{\n  decl\n    int count;\n  enddecl\n\n  begin\n    count = 0;\n\n    while(count &lt; temp) do\n      write(arr[count]);\n      count = count+1;\n    endwhile;\n\n    return count;\n  end\n}\n\nint partition (int low, int high)\n{\n  decl\n    int pivot,t;\n    int i,j;\n  enddecl\n\n  begin\n    pivot = arr[high];\n    j = low;\n    i = low;\n\n    while(i &lt; high) do\n      if (arr[i] &lt;= pivot) then\n      t = swap (i , j);\n      j = j+1;\n      endif;\n      i=i+1;\n    endwhile;\n\n    i = swap (j , high);\n\n    return j;\n  end\n}\n\n\n\nint quicksort (int low , int high)\n{\n  decl\n    int pp,temp,t;\n  enddecl\n\n  begin\n\n    if (low &lt; high) then\n      pp = partition (low , high);\n      temp = quicksort(pp+1,high);\n      t = quicksort(low , pp-1);\n    endif;\n\n    return 1;\n  end\n}\n\nint main()\n{\n  decl\n    int junk;\n    int temp;\n  enddecl\n\n  begin\n\n    read(n);\n    junk = readarr(n);\n    temp = quicksort(0,n-1);\n    junk = writearr(n);\n\n    return junk;\n  end\n}\n</code></pre>"},{"location":"testprograms/test-program-07/","title":"Constant Function","text":"<pre><code>decl\n int fun(int x),a;\nenddecl\n\nint fun(int x)\n{\n begin\n  if(x &gt;= 91) then\n   a = 91;\n  else\n   a = fun(fun(x+11));\n  endif;\n\n  return a;\n end\n}\n\nint main()\n{\n decl\n  int b,c;\n enddecl\n\n begin\n  read(b);\n  c = fun(b);\n  write(c);\n\n  return 0;\n end\n}\n</code></pre>"},{"location":"testprograms/test-program-08/","title":"Linked List","text":"<pre><code>type\n  List\n  {\n    int data;\n    List next;\n  }\nendtype\n\ndecl\n    List head;\nenddecl\n\nint main()\n{\n  decl\n    int length, x;\n    List p, q;\n  enddecl\n\n  begin\n    x = initialize();\n\n    head=null;\n    read(length);\n\n    q=head;\n    while (length!=0)  do\n      read(x);\n      p=alloc();\n      p.data=x;\n      p.next=null;\n\n      if (head==null) then\n      head=p;\n      q=p;\n      else\n      q.next=p;\n      q=q.next;\n      endif;\n\n      length=length-1;\n    endwhile;\n\n    p=head;\n    while(p!=null)  do\n      write(p.data);\n      p=p.next;\n    endwhile;\n\n    return 1;\n  end\n}\n</code></pre>"},{"location":"testprograms/test-program-09/","title":"Binary Search Tree","text":"<pre><code>type\n  bst{\n  int a;\n  bst left;\n  bst right;\n  }\nendtype\n\ndecl\n  int in,opt;\n  bst insert(bst h, int key);\n  int inOrder(bst h);\n  int preOrder(bst h);\n  int postOrder(bst h);\nenddecl\n\nbst insert(bst h, int key)\n{\n\n  begin\n    if (h == null) then\n    h = alloc();\n    h.a = key;\n    h.left = null;\n    h.right = null;\n\n    else if (key &lt; h.a) then\n            h.left  = insert(h.left, key);\n\n         else if (key &gt; h.a) then\n                 h.right = insert(h.right, key);\n              endif;\n          endif;\n    endif;\n\n    return h;\n  end\n}\n\nint inOrder(bst h){\n\n  begin\n\n  if(h!=null) then\n\n    in=inOrder(h.left);\n    write(h.a);\n    in=inOrder(h.right);\n  endif;\n  return 1;\n  end\n}\n\nint preOrder(bst h){\n\n  begin\n\n  if(h!=null) then\n    write(h.a);\n    in=preOrder(h.left);\n\n    in=preOrder(h.right);\n  endif;\n  return 1;\n  end\n}\n\nint postOrder(bst h){\n\n  begin\n\n  if(h!=null) then\n\n    in=postOrder(h.left);\n\n    in=postOrder(h.right);\n    write(h.a);\n  endif;\n  return 1;\n  end\n}\n\nint main()\n{\n  decl\n  int val,flag;\n  bst Root;\n  enddecl\n\n  begin\n    val = initialize();\n    Root = null;\n\n    read(val);\n\n    while(val!=0) do\n      Root = insert(Root,val);\n      read(val);\n    endwhile;\n\n    in = inOrder(Root);\n    in = preOrder(Root);\n    in = postOrder(Root);\n\n  return 9;\n  end\n}\n</code></pre>"},{"location":"testprograms/test-program-10/","title":"Fibonacci Series","text":"<pre><code>decl\n    int n,fibo(int n);\nenddecl\n\nint fibo(int n){\n    decl\n        int res;\n    enddecl\n    begin\n        if(n==0)then\n            res=0;\n        else\n            if(n==1)then\n                res=1;\n            else\n                res=fibo(n-1)+fibo(n-2);\n            endif;\n        endif;\n        return res;\n    end\n}\nint main(){\n    decl\n        int result;\n    enddecl\n    begin\n        read(n);\n        result = fibo(n);\n        write(result);\n        return 0;\n    end\n}\n</code></pre>"},{"location":"testprograms/test-program-11/","title":"Extended Euclid(Linked List)","text":"<pre><code>type\n  node\n  {\n    int d;\n    int s;\n    int t;\n  }\n  List\n  {\n    int a;\n    int b;\n    node g;\n    List next;\n  }\nendtype\ndecl\n  node y,z;\n  List head;\n  int insert(int a,int b,node g);\n  node gcd(int m,int n);\nenddecl\nint insert(int a,int b,node g)\n{\n  decl\n    List p,q;\n    node temp;\n  enddecl\n  begin\n      p=alloc();\n      p.a=a;\n      p.b=b;\n      temp=alloc();\n      temp.d=g.d;\n      temp.s=g.s;\n      temp.t=g.t;\n      p.g=temp;\n      if (head== null) then\n          p.next=null;\n          head=p;\n      else\n          p.next=head;\n          head=p;\n      endif;\n  return 0;\n  end\n}\n\nnode gcd(int m,int n){\n\n  decl\n    int q,r,temp;\n  enddecl\n\n  begin\n    if(n==0) then\n        y.d = m;\n        y.s = 1;\n        y.t = 0;\n    else\n        q = m/n;\n        r = m-q*n;\n        z = gcd(n,r);\n        temp = z.s;\n        y.s = z.t;\n        y.t = temp - (q*z.t);\n    endif;\n    temp=insert(m,n,y);\n    return y;\n  end\n}\n\nint main()\n{\n  decl\n    int a,b,c;\n    node res;\n  enddecl\n\n  begin\n    c = initialize();\n    y = alloc();\n    read(a);\n    read(b);\n    head=null;\n    res = gcd(a,b);\n    write(res.d);\n    write(res.s);\n    write(res.t);\n    write(\"stack\");\n    while(head!= null) do\n        write(head.a);\n        write(head.b);\n        write(head.g.d);\n        write(head.g.s);\n        write(head.g.t);\n        head=head.next;\n        write(\"next\");\n    endwhile;\n    return 0;\n  end\n}\n</code></pre>"},{"location":"testprograms/test-program-12/","title":"Extended Euclid(iterative)","text":"<pre><code>decl\n    int r1,qi,r0,si,ti,ri;\nenddecl\nint main() {\n    decl\n        int s0,s1,t0,t1;\n    enddecl\n\n    begin\n        read(r0);\n        read(r1);\n        s0 = 1;\n        s1 = 0;\n        t0 = 0;\n        t1 = 1;\n\n        while(r1 != 0) do\n            qi = r0/r1;\n            ri = r0 - (qi*r1);\n            si = s0 - (qi*s1);\n            ti = t0 - (qi*t1);\n            r0 = r1;\n            r1 = ri;\n            s0 = s1;\n            s1 = si;\n            t0 = t1;\n            t1 = ti;\n        endwhile;\n\n        write(r0);\n        write(s0);\n        write(t0);\n\n        return 0;\n    end\n}\n</code></pre>"},{"location":"testprograms/stage4/bubblesort/","title":"Bubble Sort","text":"<pre><code>decl\n   int n,arr[50],i,j,dup;\nenddecl\nread(n);\ni=0;\nwhile(i&lt;n) do\n    read(arr[i]);\n    i = i+1;\nendwhile;\ni=0;\nwhile(i&lt;n) do\n    j=i;\n    while(j&lt;n) do\n        if(arr[i]&gt;arr[j]) then\n            dup = arr[i];\n            arr[i] = arr[j];\n            arr[j] = dup;\n        endif;\n        j = j + 1;\n    endwhile;\n    i = i+1;\nendwhile;\ni=0;\nwhile(i&lt;n) do\n    write(arr[i]);\n    i = i+1;\nendwhile;\n</code></pre>"},{"location":"testprograms/stage4/fibaofn/","title":"Nth Fibanocci","text":"<pre><code>decl\n    int n,f2,f0,f1,i;\nenddecl\nread(n);\nif(n&gt;=2) then\n    f0=0;\n    f1=1;\n    n=n-1;\n    while(n!=0) do\n        f2=f1+f0;\n        f0=f1;\n        f1=f2;\n        n=n-1;\n    endwhile;\n    write(f1);\nelse if(n==1) then\n        write(1);\n    else write(0);\n    endif;\nendif;\n</code></pre>"},{"location":"testprograms/stage4/prime/","title":"Prime or Not","text":"<pre><code>decl\n    int n,i,j;\nenddecl\n    read(n);\n    j=0;\n    if(n%2==0) then\n        j=1;\n    else\n        i=3;\n        while(i&lt;=n/2) do\n            if(n%i==0) then\n                j=1;\n            endif;\n            i=i+2;\n        endwhile;\n    endif;\n    if(j==0) then\n        write(\"Prime\");\n    else \n        write(\"Not Prime\");\n    endif;\n</code></pre>"},{"location":"testprograms/stage4/sum-to-n-fact/","title":"Sum of N factorials","text":"<pre><code>decl\n    int n,i,j,sum,k;\nenddecl\n    read(n);\n    sum=0;\n    k=1;\n    while(k&lt;=n)do\n        if(n&lt;=1) then\n            sum=sum+1;\n        else\n            i=1;\n            j=1;\n            while(i&lt;=k)do\n                j=j*i;\n                i=i+1;\n            endwhile;\n            sum=sum+j;\n        endif;\n        k=k+1;\n    endwhile;\n    write(sum);\n</code></pre>"}]}